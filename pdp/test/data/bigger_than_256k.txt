section: Docs
title: API | IPFS Docs
pagetype: subdoc
url: docs/api
save_as: docs/api/index.html


# API Reference

<sup>Generated on 2018-07-25, from go-ipfs v0.4.15.</sup>

This is the HTTP API specification for IPFS.

IPFS HTTP API is an RPC API which should work across different
IPFS implementations. The most feature-complete of those implementations,
and current reference for this specification is
[go-ipfs](https://github.com/ipfs/go-ipfs).

This document is autogenerated from go-ipfs. For issues and support, check out
the [ipfs-http-api-docs](https://github.com/ipfs/ipfs-http-api-docs)
repository on GitHub.

## Getting started

### Alignment with CLI Commands

[Every command](../commands/) usable from the CLI is also available through
the HTTP API. For example:
```sh
> ipfs swarm peers
/ip4/104.131.131.82/tcp/4001/ipfs/QmaCpDMGvV2BGHeYERUEnRQAwe3N8SzbUtfsmvsqQLuvuJ
/ip4/104.236.151.122/tcp/4001/ipfs/QmSoLju6m7xTh3DuokvT3886QRYqxAzb1kShaanJgW36yx
/ip4/104.236.176.52/tcp/4001/ipfs/QmSoLnSGccFuZQJzRadHn95W2CrSFmZuTdDWP8HXaHca9z

> curl http://127.0.0.1:5001/api/v0/swarm/peers
{
  "Strings": [
    "/ip4/104.131.131.82/tcp/4001/ipfs/QmaCpDMGvV2BGHeYERUEnRQAwe3N8SzbUtfsmvsqQLuvuJ",
    "/ip4/104.236.151.122/tcp/4001/ipfs/QmSoLju6m7xTh3DuokvT3886QRYqxAzb1kShaanJgW36yx",
    "/ip4/104.236.176.52/tcp/4001/ipfs/QmSoLnSGccFuZQJzRadHn95W2CrSFmZuTdDWP8HXaHca9z",
  ]
}
```

### Arguments

Arguments are added through the special query string key "arg":

```
> curl "http://127.0.0.1:5001/api/v0/swarm/disconnect?arg=/ip4/54.93.113.247/tcp/48131/ipfs/QmUDS3nsBD1X4XK5Jo836fed7SErTyTuQzRqWaiQAyBYMP"
{
  "Strings": [
    "disconnect QmUDS3nsBD1X4XK5Jo836fed7SErTyTuQzRqWaiQAyBYMP success",
  ]
}
```

Note that it can be used multiple times to signify multiple arguments.

### Flags

Flags are added through the query string. For example, the `--encoding=json`
flag is the `&encoding=json` query parameter below:

```
> curl "http://127.0.0.1:5001/api/v0/object/get?arg=QmaaqrHyAQm7gALkRW8DcfGX3u8q9rWKnxEMmf7m9z515w&encoding=json"
{
  "Links": [
    {
      "Name": "index.html",
      "Hash": "QmYftndCvcEiuSZRX7njywX2AGSeHY2ASa7VryCq1mKwEw",
      "Size": 1700
    },
    {
      "Name": "static",
      "Hash": "QmdtWFiasJeh2ymW3TD2cLHYxn1ryTuWoNpwieFyJriGTS",
      "Size": 2428803
    }
  ],
  "Data": "CAE="
}
```
## Index

  *  [/add](#api-v0-add)
  *  [/bitswap/ledger](#api-v0-bitswap-ledger)
  *  [/bitswap/reprovide](#api-v0-bitswap-reprovide)
  *  [/bitswap/stat](#api-v0-bitswap-stat)
  *  [/bitswap/unwant](#api-v0-bitswap-unwant)
  *  [/bitswap/wantlist](#api-v0-bitswap-wantlist)
  *  [/block/get](#api-v0-block-get)
  *  [/block/put](#api-v0-block-put)
  *  [/block/rm](#api-v0-block-rm)
  *  [/block/stat](#api-v0-block-stat)
  *  [/bootstrap/add/default](#api-v0-bootstrap-add-default)
  *  [/bootstrap/list](#api-v0-bootstrap-list)
  *  [/bootstrap/rm/all](#api-v0-bootstrap-rm-all)
  *  [/cat](#api-v0-cat)
  *  [/commands](#api-v0-commands)
  *  [/config/edit](#api-v0-config-edit)
  *  [/config/profile/apply](#api-v0-config-profile-apply)
  *  [/config/replace](#api-v0-config-replace)
  *  [/config/show](#api-v0-config-show)
  *  [/dag/get](#api-v0-dag-get)
  *  [/dag/put](#api-v0-dag-put)
  *  [/dag/resolve](#api-v0-dag-resolve)
  *  [/dht/findpeer](#api-v0-dht-findpeer)
  *  [/dht/findprovs](#api-v0-dht-findprovs)
  *  [/dht/get](#api-v0-dht-get)
  *  [/dht/provide](#api-v0-dht-provide)
  *  [/dht/put](#api-v0-dht-put)
  *  [/dht/query](#api-v0-dht-query)
  *  [/diag/cmds/clear](#api-v0-diag-cmds-clear)
  *  [/diag/cmds/set-time](#api-v0-diag-cmds-set-time)
  *  [/diag/sys](#api-v0-diag-sys)
  *  [/dns](#api-v0-dns)
  *  [/file/ls](#api-v0-file-ls)
  *  [/files/chcid](#api-v0-files-chcid)
  *  [/files/cp](#api-v0-files-cp)
  *  [/files/flush](#api-v0-files-flush)
  *  [/files/ls](#api-v0-files-ls)
  *  [/files/mkdir](#api-v0-files-mkdir)
  *  [/files/mv](#api-v0-files-mv)
  *  [/files/read](#api-v0-files-read)
  *  [/files/rm](#api-v0-files-rm)
  *  [/files/stat](#api-v0-files-stat)
  *  [/files/write](#api-v0-files-write)
  *  [/filestore/dups](#api-v0-filestore-dups)
  *  [/filestore/ls](#api-v0-filestore-ls)
  *  [/filestore/verify](#api-v0-filestore-verify)
  *  [/get](#api-v0-get)
  *  [/id](#api-v0-id)
  *  [/key/gen](#api-v0-key-gen)
  *  [/key/list](#api-v0-key-list)
  *  [/key/rename](#api-v0-key-rename)
  *  [/key/rm](#api-v0-key-rm)
  *  [/log/level](#api-v0-log-level)
  *  [/log/ls](#api-v0-log-ls)
  *  [/log/tail](#api-v0-log-tail)
  *  [/ls](#api-v0-ls)
  *  [/mount](#api-v0-mount)
  *  [/name/publish](#api-v0-name-publish)
  *  [/name/pubsub/cancel](#api-v0-name-pubsub-cancel)
  *  [/name/pubsub/state](#api-v0-name-pubsub-state)
  *  [/name/pubsub/subs](#api-v0-name-pubsub-subs)
  *  [/name/resolve](#api-v0-name-resolve)
  *  [/object/data](#api-v0-object-data)
  *  [/object/diff](#api-v0-object-diff)
  *  [/object/get](#api-v0-object-get)
  *  [/object/links](#api-v0-object-links)
  *  [/object/new](#api-v0-object-new)
  *  [/object/patch/add-link](#api-v0-object-patch-add-link)
  *  [/object/patch/append-data](#api-v0-object-patch-append-data)
  *  [/object/patch/rm-link](#api-v0-object-patch-rm-link)
  *  [/object/patch/set-data](#api-v0-object-patch-set-data)
  *  [/object/put](#api-v0-object-put)
  *  [/object/stat](#api-v0-object-stat)
  *  [/p2p/listener/close](#api-v0-p2p-listener-close)
  *  [/p2p/listener/ls](#api-v0-p2p-listener-ls)
  *  [/p2p/listener/open](#api-v0-p2p-listener-open)
  *  [/p2p/stream/close](#api-v0-p2p-stream-close)
  *  [/p2p/stream/dial](#api-v0-p2p-stream-dial)
  *  [/p2p/stream/ls](#api-v0-p2p-stream-ls)
  *  [/pin/add](#api-v0-pin-add)
  *  [/pin/ls](#api-v0-pin-ls)
  *  [/pin/rm](#api-v0-pin-rm)
  *  [/pin/update](#api-v0-pin-update)
  *  [/pin/verify](#api-v0-pin-verify)
  *  [/ping](#api-v0-ping)
  *  [/pubsub/ls](#api-v0-pubsub-ls)
  *  [/pubsub/peers](#api-v0-pubsub-peers)
  *  [/pubsub/pub](#api-v0-pubsub-pub)
  *  [/pubsub/sub](#api-v0-pubsub-sub)
  *  [/refs/local](#api-v0-refs-local)
  *  [/repo/fsck](#api-v0-repo-fsck)
  *  [/repo/gc](#api-v0-repo-gc)
  *  [/repo/stat](#api-v0-repo-stat)
  *  [/repo/verify](#api-v0-repo-verify)
  *  [/repo/version](#api-v0-repo-version)
  *  [/resolve](#api-v0-resolve)
  *  [/shutdown](#api-v0-shutdown)
  *  [/stats/bitswap](#api-v0-stats-bitswap)
  *  [/stats/bw](#api-v0-stats-bw)
  *  [/stats/repo](#api-v0-stats-repo)
  *  [/swarm/addrs/listen](#api-v0-swarm-addrs-listen)
  *  [/swarm/addrs/local](#api-v0-swarm-addrs-local)
  *  [/swarm/connect](#api-v0-swarm-connect)
  *  [/swarm/disconnect](#api-v0-swarm-disconnect)
  *  [/swarm/filters/add](#api-v0-swarm-filters-add)
  *  [/swarm/filters/rm](#api-v0-swarm-filters-rm)
  *  [/swarm/peers](#api-v0-swarm-peers)
  *  [/tar/add](#api-v0-tar-add)
  *  [/tar/cat](#api-v0-tar-cat)
  *  [/update](#api-v0-update)
  *  [/version](#api-v0-version)


## Endpoints


### /api/v0/add

Add a file or directory to ipfs.


#### Arguments

  - `arg` [file]: The path to a file to be added to ipfs. Required: **yes**.
  - `recursive` [bool]: Add directory paths recursively. Default: "false". Required: no.
  - `quiet` [bool]: Write minimal output. Required: no.
  - `quieter` [bool]: Write only final hash. Required: no.
  - `silent` [bool]: Write no output. Required: no.
  - `progress` [bool]: Stream progress data. Required: no.
  - `trickle` [bool]: Use trickle-dag format for dag generation. Required: no.
  - `only-hash` [bool]: Only chunk and hash - do not write to disk. Required: no.
  - `wrap-with-directory` [bool]: Wrap files with a directory object. Required: no.
  - `hidden` [bool]: Include files that are hidden. Only takes effect on recursive add. Required: no.
  - `chunker` [string]: Chunking algorithm, size-[bytes] or rabin-[min]-[avg]-[max]. Default: "size-262144". Required: no.
  - `pin` [bool]: Pin this object when adding. Default: "true". Required: no.
  - `raw-leaves` [bool]: Use raw blocks for leaf nodes. (experimental). Required: no.
  - `nocopy` [bool]: Add the file using filestore. Implies raw-leaves. (experimental). Required: no.
  - `fscache` [bool]: Check the filestore for pre-existing blocks. (experimental). Required: no.
  - `cid-version` [int]: CID version. Defaults to 0 unless an option that depends on CIDv1 is passed. (experimental). Required: no.
  - `hash` [string]: Hash function to use. Implies CIDv1 if not sha2-256. (experimental). Default: "sha2-256". Required: no.


#### Request Body

Argument "path" is of file type. This endpoint expects a file in the body of the request as 'multipart/form-data'.


#### Response

On success, the call to this endpoint will return with 200 and the following body:

```text
{
    "Name": "<string>"
    "Hash": "<string>"
    "Bytes": "<int64>"
    "Size": "<string>"
}

```

#### cURL Example

`curl -F file=@myfile "http://localhost:5001/api/v0/add?recursive=false&quiet=<value>&quieter=<value>&silent=<value>&progress=<value>&trickle=<value>&only-hash=<value>&wrap-with-directory=<value>&hidden=<value>&chunker=size-262144&pin=true&raw-leaves=<value>&nocopy=<value>&fscache=<value>&cid-version=<value>&hash=sha2-256"`

***

### /api/v0/bitswap/ledger

Show the current ledger for a peer.


#### Arguments

  - `arg` [string]: The PeerID (B58) of the ledger to inspect. Required: **yes**.


#### Response

On success, the call to this endpoint will return with 200 and the following body:

```text
{
    "Peer": "<string>"
    "Value": "<float64>"
    "Sent": "<uint64>"
    "Recv": "<uint64>"
    "Exchanged": "<uint64>"
}

```

#### cURL Example

`curl "http://localhost:5001/api/v0/bitswap/ledger?arg=<peer>"`

***

### /api/v0/bitswap/reprovide

Trigger reprovider.


#### Arguments

This endpoint takes no arguments.


#### Response

On success, the call to this endpoint will return with 200 and the following body:

```text
This endpoint returns a `text/plain` response body.
```

#### cURL Example

`curl "http://localhost:5001/api/v0/bitswap/reprovide"`

***

### /api/v0/bitswap/stat

Show some diagnostic information on the bitswap agent.


#### Arguments

This endpoint takes no arguments.


#### Response

On success, the call to this endpoint will return with 200 and the following body:

```text
{
    "ProvideBufLen": "<int>"
    "Wantlist": [
        "<string>"
    ]
    "Peers": [
        "<string>"
    ]
    "BlocksReceived": "<uint64>"
    "DataReceived": "<uint64>"
    "BlocksSent": "<uint64>"
    "DataSent": "<uint64>"
    "DupBlksReceived": "<uint64>"
    "DupDataReceived": "<uint64>"
}

```

#### cURL Example

`curl "http://localhost:5001/api/v0/bitswap/stat"`

***

### /api/v0/bitswap/unwant

Remove a given block from your wantlist.


#### Arguments

  - `arg` [string]: Key(s) to remove from your wantlist. Required: **yes**.


#### Response

On success, the call to this endpoint will return with 200 and the following body:

```text
This endpoint returns a `text/plain` response body.
```

#### cURL Example

`curl "http://localhost:5001/api/v0/bitswap/unwant?arg=<key>"`

***

### /api/v0/bitswap/wantlist

Show blocks currently on the wantlist.


#### Arguments

  - `peer` [string]: Specify which peer to show wantlist for. Required: no.


#### Response

On success, the call to this endpoint will return with 200 and the following body:

```text
{
    "Keys": [
        "<string>"
    ]
}

```

#### cURL Example

`curl "http://localhost:5001/api/v0/bitswap/wantlist?peer=<value>"`

***

### /api/v0/block/get

Get a raw IPFS block.


#### Arguments

  - `arg` [string]: The base58 multihash of an existing block to get. Required: **yes**.


#### Response

On success, the call to this endpoint will return with 200 and the following body:

```text
This endpoint returns a `text/plain` response body.
```

#### cURL Example

`curl "http://localhost:5001/api/v0/block/get?arg=<key>"`

***

### /api/v0/block/put

Store input as an IPFS block.


#### Arguments

  - `arg` [file]: The data to be stored as an IPFS block. Required: **yes**.
  - `format` [string]: cid format for blocks to be created with. Required: no.
  - `mhtype` [string]: multihash hash function. Default: "sha2-256". Required: no.
  - `mhlen` [int]: multihash hash length. Default: "-1". Required: no.


#### Request Body

Argument "data" is of file type. This endpoint expects a file in the body of the request as 'multipart/form-data'.


#### Response

On success, the call to this endpoint will return with 200 and the following body:

```text
{
    "Key": "<string>"
    "Size": "<int>"
}

```

#### cURL Example

`curl -F file=@myfile "http://localhost:5001/api/v0/block/put?format=<value>&mhtype=sha2-256&mhlen=-1"`

***

### /api/v0/block/rm

Remove IPFS block(s).


#### Arguments

  - `arg` [string]: Bash58 encoded multihash of block(s) to remove. Required: **yes**.
  - `force` [bool]: Ignore nonexistent blocks. Required: no.
  - `quiet` [bool]: Write minimal output. Required: no.


#### Response

On success, the call to this endpoint will return with 200 and the following body:

```text
{
    "Hash": "<string>"
    "Error": "<string>"
}

```

#### cURL Example

`curl "http://localhost:5001/api/v0/block/rm?arg=<hash>&force=<value>&quiet=<value>"`

***

### /api/v0/block/stat

Print information of a raw IPFS block.


#### Arguments

  - `arg` [string]: The base58 multihash of an existing block to stat. Required: **yes**.


#### Response

On success, the call to this endpoint will return with 200 and the following body:

```text
{
    "Key": "<string>"
    "Size": "<int>"
}

```

#### cURL Example

`curl "http://localhost:5001/api/v0/block/stat?arg=<key>"`

***

### /api/v0/bootstrap/add/default

Add default peers to the bootstrap list.


#### Arguments

This endpoint takes no arguments.


#### Response

On success, the call to this endpoint will return with 200 and the following body:

```text
{
    "Peers": [
        "<string>"
    ]
}

```

#### cURL Example

`curl "http://localhost:5001/api/v0/bootstrap/add/default"`

***

### /api/v0/bootstrap/list

Show peers in the bootstrap list.


#### Arguments

This endpoint takes no arguments.


#### Response

On success, the call to this endpoint will return with 200 and the following body:

```text
{
    "Peers": [
        "<string>"
    ]
}

```

#### cURL Example

`curl "http://localhost:5001/api/v0/bootstrap/list"`

***

### /api/v0/bootstrap/rm/all

Remove all peers from the bootstrap list.


#### Arguments

This endpoint takes no arguments.


#### Response

On success, the call to this endpoint will return with 200 and the following body:

```text
{
    "Peers": [
        "<string>"
    ]
}

```

#### cURL Example

`curl "http://localhost:5001/api/v0/bootstrap/rm/all"`

***

### /api/v0/cat

Show IPFS object data.


#### Arguments

  - `arg` [string]: The path to the IPFS object(s) to be outputted. Required: **yes**.
  - `offset` [int]: Byte offset to begin reading from. Required: no.
  - `length` [int]: Maximum number of bytes to read. Required: no.


#### Response

On success, the call to this endpoint will return with 200 and the following body:

```text
This endpoint returns a `text/plain` response body.
```

#### cURL Example

`curl "http://localhost:5001/api/v0/cat?arg=<ipfs-path>&offset=<value>&length=<value>"`

***

### /api/v0/commands

List all available commands.


#### Arguments

  - `flags` [bool]: Show command flags. Required: no.


#### Response

On success, the call to this endpoint will return with 200 and the following body:

```text
{
    "Name": "<string>"
    "Subcommands": [
        {
            "Name": "<string>"
            "Subcommands": [
                {
                    "Name": "<string>"
                    "Subcommands": [
                        ...
                    ]
                    "Options": [
                        ...
                    ]
                    "showOpts": "<bool>"
                }
            ]
            "Options": [
                {
                    "Names": [
                        ...
                    ]
                }
            ]
            "showOpts": "<bool>"
        }
    ]
    "Options": [
        {
            "Names": [
                "<string>"
            ]
        }
    ]
    "showOpts": "<bool>"
}

```

#### cURL Example

`curl "http://localhost:5001/api/v0/commands?flags=<value>"`

***

### /api/v0/config/edit

Open the config file for editing in $EDITOR.


#### Arguments

This endpoint takes no arguments.


#### Response

On success, the call to this endpoint will return with 200 and the following body:

```text
This endpoint returns a `text/plain` response body.
```

#### cURL Example

`curl "http://localhost:5001/api/v0/config/edit"`

***

### /api/v0/config/profile/apply

Apply profile to config.


#### Arguments

  - `arg` [string]: The profile to apply to the config. Required: **yes**.


#### Response

On success, the call to this endpoint will return with 200 and the following body:

```text
This endpoint returns a `text/plain` response body.
```

#### cURL Example

`curl "http://localhost:5001/api/v0/config/profile/apply?arg=<profile>"`

***

### /api/v0/config/replace

Replace the config with <file>.


#### Arguments

  - `arg` [file]: The file to use as the new config. Required: **yes**.


#### Request Body

Argument "file" is of file type. This endpoint expects a file in the body of the request as 'multipart/form-data'.


#### Response

On success, the call to this endpoint will return with 200 and the following body:

```text
This endpoint returns a `text/plain` response body.
```

#### cURL Example

`curl -F file=@myfile "http://localhost:5001/api/v0/config/replace"`

***

### /api/v0/config/show

Output config file contents.


#### Arguments

This endpoint takes no arguments.


#### Response

On success, the call to this endpoint will return with 200 and the following body:

```text
This endpoint returns a `text/plain` response body.
```

#### cURL Example

`curl "http://localhost:5001/api/v0/config/show"`

***

### /api/v0/dag/get

Get a dag node from ipfs.


#### Arguments

  - `arg` [string]: The object to get Required: **yes**.


#### Response

On success, the call to this endpoint will return with 200 and the following body:

```text
This endpoint returns a `text/plain` response body.
```

#### cURL Example

`curl "http://localhost:5001/api/v0/dag/get?arg=<ref>"`

***

### /api/v0/dag/put

Add a dag node to ipfs.


#### Arguments

  - `arg` [file]: The object to put Required: **yes**.
  - `format` [string]: Format that the object will be added as. Default: "cbor". Required: no.
  - `input-enc` [string]: Format that the input object will be. Default: "json". Required: no.
  - `pin` [bool]: Pin this object when adding. Required: no.
  - `hash` [string]: Hash function to use. Default: . Required: no.


#### Request Body

Argument "object data" is of file type. This endpoint expects a file in the body of the request as 'multipart/form-data'.


#### Response

On success, the call to this endpoint will return with 200 and the following body:

```text
{
    "Cid": "<string>"
}

```

#### cURL Example

`curl -F file=@myfile "http://localhost:5001/api/v0/dag/put?format=cbor&input-enc=json&pin=<value>&hash=<value>"`

***

### /api/v0/dag/resolve

Resolve ipld block


#### Arguments

  - `arg` [string]: The path to resolve Required: **yes**.


#### Response

On success, the call to this endpoint will return with 200 and the following body:

```text
{
    "Cid": "<string>"
    "RemPath": "<string>"
}

```

#### cURL Example

`curl "http://localhost:5001/api/v0/dag/resolve?arg=<ref>"`

***

### /api/v0/dht/findpeer

Query the DHT for all of the multiaddresses associated with a Peer ID.


#### Arguments

  - `arg` [string]: The ID of the peer to search for. Required: **yes**.
  - `verbose` [bool]: Print extra information. Required: no.


#### Response

On success, the call to this endpoint will return with 200 and the following body:

```text
{
    "ID": "<string>"
    "Type": "<int>"
    "Responses": [
        {
            "ID": "<string>"
            "Addrs": [
                "<object>"
            ]
        }
    ]
    "Extra": "<string>"
}

```

#### cURL Example

`curl "http://localhost:5001/api/v0/dht/findpeer?arg=<peerID>&verbose=<value>"`

***

### /api/v0/dht/findprovs

Find peers in the DHT that can provide a specific value, given a key.


#### Arguments

  - `arg` [string]: The key to find providers for. Required: **yes**.
  - `verbose` [bool]: Print extra information. Required: no.
  - `num-providers` [int]: The number of providers to find. Default: "20". Required: no.


#### Response

On success, the call to this endpoint will return with 200 and the following body:

```text
{
    "ID": "<string>"
    "Type": "<int>"
    "Responses": [
        {
            "ID": "<string>"
            "Addrs": [
                "<object>"
            ]
        }
    ]
    "Extra": "<string>"
}

```

#### cURL Example

`curl "http://localhost:5001/api/v0/dht/findprovs?arg=<key>&verbose=<value>&num-providers=20"`

***

### /api/v0/dht/get

Given a key, query the DHT for its best value.


#### Arguments

  - `arg` [string]: The key to find a value for. Required: **yes**.
  - `verbose` [bool]: Print extra information. Required: no.


#### Response

On success, the call to this endpoint will return with 200 and the following body:

```text
{
    "ID": "<string>"
    "Type": "<int>"
    "Responses": [
        {
            "ID": "<string>"
            "Addrs": [
                "<object>"
            ]
        }
    ]
    "Extra": "<string>"
}

```

#### cURL Example

`curl "http://localhost:5001/api/v0/dht/get?arg=<key>&verbose=<value>"`

***

### /api/v0/dht/provide

Announce to the network that you are providing given values.


#### Arguments

  - `arg` [string]: The key[s] to send provide records for. Required: **yes**.
  - `verbose` [bool]: Print extra information. Required: no.
  - `recursive` [bool]: Recursively provide entire graph. Required: no.


#### Response

On success, the call to this endpoint will return with 200 and the following body:

```text
{
    "ID": "<string>"
    "Type": "<int>"
    "Responses": [
        {
            "ID": "<string>"
            "Addrs": [
                "<object>"
            ]
        }
    ]
    "Extra": "<string>"
}

```

#### cURL Example

`curl "http://localhost:5001/api/v0/dht/provide?arg=<key>&verbose=<value>&recursive=<value>"`

***

### /api/v0/dht/put

Write a key/value pair to the DHT.


#### Arguments

  - `arg` [string]: The key to store the value at. Required: **yes**.
  - `arg` [string]: The value to store. Required: **yes**.
  - `verbose` [bool]: Print extra information. Required: no.


#### Response

On success, the call to this endpoint will return with 200 and the following body:

```text
{
    "ID": "<string>"
    "Type": "<int>"
    "Responses": [
        {
            "ID": "<string>"
            "Addrs": [
                "<object>"
            ]
        }
    ]
    "Extra": "<string>"
}

```

#### cURL Example

`curl "http://localhost:5001/api/v0/dht/put?arg=<key>&arg=<value>&verbose=<value>"`

***

### /api/v0/dht/query

Find the closest Peer IDs to a given Peer ID by querying the DHT.


#### Arguments

  - `arg` [string]: The peerID to run the query against. Required: **yes**.
  - `verbose` [bool]: Print extra information. Required: no.


#### Response

On success, the call to this endpoint will return with 200 and the following body:

```text
{
    "ID": "<string>"
    "Type": "<int>"
    "Responses": [
        {
            "ID": "<string>"
            "Addrs": [
                "<object>"
            ]
        }
    ]
    "Extra": "<string>"
}

```

#### cURL Example

`curl "http://localhost:5001/api/v0/dht/query?arg=<peerID>&verbose=<value>"`

***

### /api/v0/diag/cmds/clear

Clear inactive requests from the log.


#### Arguments

This endpoint takes no arguments.


#### Response

On success, the call to this endpoint will return with 200 and the following body:

```text
This endpoint returns a `text/plain` response body.
```

#### cURL Example

`curl "http://localhost:5001/api/v0/diag/cmds/clear"`

***

### /api/v0/diag/cmds/set-time

Set how long to keep inactive requests in the log.


#### Arguments

  - `arg` [string]: Time to keep inactive requests in log. Required: **yes**.


#### Response

On success, the call to this endpoint will return with 200 and the following body:

```text
This endpoint returns a `text/plain` response body.
```

#### cURL Example

`curl "http://localhost:5001/api/v0/diag/cmds/set-time?arg=<time>"`

***

### /api/v0/diag/sys

Print system diagnostic information.


#### Arguments

This endpoint takes no arguments.


#### Response

On success, the call to this endpoint will return with 200 and the following body:

```text
This endpoint returns a `text/plain` response body.
```

#### cURL Example

`curl "http://localhost:5001/api/v0/diag/sys"`

***

### /api/v0/dns

Resolve DNS links.


#### Arguments

  - `arg` [string]: The domain-name name to resolve. Required: **yes**.
  - `recursive` [bool]: Resolve until the result is not a DNS link. Required: no.


#### Response

On success, the call to this endpoint will return with 200 and the following body:

```text
{
    "Path": "<string>"
}

```

#### cURL Example

`curl "http://localhost:5001/api/v0/dns?arg=<domain-name>&recursive=<value>"`

***

### /api/v0/file/ls

List directory contents for Unix filesystem objects.


#### Arguments

  - `arg` [string]: The path to the IPFS object(s) to list links from. Required: **yes**.


#### Response

On success, the call to this endpoint will return with 200 and the following body:

```text
{
    "Arguments": {
        "<string>": "<string>"
    }
    "Objects": {
        "<string>": {
            "Hash": "<string>"
            "Size": "<uint64>"
            "Type": "<string>"
            "Links": [
                {
                    "Name": "<string>"
                    "Hash": "<string>"
                    "Size": "<uint64>"
                    "Type": "<string>"
                }
            ]
        }
    }
}

```

#### cURL Example

`curl "http://localhost:5001/api/v0/file/ls?arg=<ipfs-path>"`

***

### /api/v0/files/chcid

Change the cid version or hash function of the root node of a given path.


#### Arguments

  - `arg` [string]: Path to change. Default: '/'. Required: no.
  - `cid-version` [int]: Cid version to use. (experimental). Required: no.
  - `hash` [string]: Hash function to use. Will set Cid version to 1 if used. (experimental). Required: no.


#### Response

On success, the call to this endpoint will return with 200 and the following body:

```text
This endpoint returns a `text/plain` response body.
```

#### cURL Example

`curl "http://localhost:5001/api/v0/files/chcid?arg=<path>&cid-version=<value>&hash=<value>"`

***

### /api/v0/files/cp

Copy files into mfs.


#### Arguments

  - `arg` [string]: Source object to copy. Required: **yes**.
  - `arg` [string]: Destination to copy object to. Required: **yes**.


#### Response

On success, the call to this endpoint will return with 200 and the following body:

```text
This endpoint returns a `text/plain` response body.
```

#### cURL Example

`curl "http://localhost:5001/api/v0/files/cp?arg=<source>&arg=<dest>"`

***

### /api/v0/files/flush

Flush a given path's data to disk.


#### Arguments

  - `arg` [string]: Path to flush. Default: '/'. Required: no.


#### Response

On success, the call to this endpoint will return with 200 and the following body:

```text
This endpoint returns a `text/plain` response body.
```

#### cURL Example

`curl "http://localhost:5001/api/v0/files/flush?arg=<path>"`

***

### /api/v0/files/ls

List directories in the local mutable namespace.


#### Arguments

  - `arg` [string]: Path to show listing for. Defaults to '/'. Required: no.
  - `l` [bool]: Use long listing format. Required: no.


#### Response

On success, the call to this endpoint will return with 200 and the following body:

```text
{
    "Entries": [
        {
            "Name": "<string>"
            "Type": "<int>"
            "Size": "<int64>"
            "Hash": "<string>"
        }
    ]
}

```

#### cURL Example

`curl "http://localhost:5001/api/v0/files/ls?arg=<path>&l=<value>"`

***

### /api/v0/files/mkdir

Make directories.


#### Arguments

  - `arg` [string]: Path to dir to make. Required: **yes**.
  - `parents` [bool]: No error if existing, make parent directories as needed. Required: no.
  - `cid-version` [int]: Cid version to use. (experimental). Required: no.
  - `hash` [string]: Hash function to use. Will set Cid version to 1 if used. (experimental). Required: no.


#### Response

On success, the call to this endpoint will return with 200 and the following body:

```text
This endpoint returns a `text/plain` response body.
```

#### cURL Example

`curl "http://localhost:5001/api/v0/files/mkdir?arg=<path>&parents=<value>&cid-version=<value>&hash=<value>"`

***

### /api/v0/files/mv

Move files.


#### Arguments

  - `arg` [string]: Source file to move. Required: **yes**.
  - `arg` [string]: Destination path for file to be moved to. Required: **yes**.


#### Response

On success, the call to this endpoint will return with 200 and the following body:

```text
This endpoint returns a `text/plain` response body.
```

#### cURL Example

`curl "http://localhost:5001/api/v0/files/mv?arg=<source>&arg=<dest>"`

***

### /api/v0/files/read

Read a file in a given mfs.


#### Arguments

  - `arg` [string]: Path to file to be read. Required: **yes**.
  - `offset` [int]: Byte offset to begin reading from. Required: no.
  - `count` [int]: Maximum number of bytes to read. Required: no.


#### Response

On success, the call to this endpoint will return with 200 and the following body:

```text
This endpoint returns a `text/plain` response body.
```

#### cURL Example

`curl "http://localhost:5001/api/v0/files/read?arg=<path>&offset=<value>&count=<value>"`

***

### /api/v0/files/rm

Remove a file.


#### Arguments

  - `arg` [string]: File to remove. Required: **yes**.
  - `recursive` [bool]: Recursively remove directories. Required: no.


#### Response

On success, the call to this endpoint will return with 200 and the following body:

```text
This endpoint returns a `text/plain` response body.
```

#### cURL Example

`curl "http://localhost:5001/api/v0/files/rm?arg=<path>&recursive=<value>"`

***

### /api/v0/files/stat

Display file status.


#### Arguments

  - `arg` [string]: Path to node to stat. Required: **yes**.
  - `format` [string]: Print statistics in given format. Allowed tokens: <hash> <size> <cumulsize> <type> <childs>. Conflicts with other format options. Default: <hash>
Size: <size>
CumulativeSize: <cumulsize>
ChildBlocks: <childs>
Type: <type>. Default: "<hash>
Size: <size>
CumulativeSize: <cumulsize>
ChildBlocks: <childs>
Type: <type>". Required: no.
  - `hash` [bool]: Print only hash. Implies '--format=<hash>'. Conflicts with other format options. Required: no.
  - `size` [bool]: Print only size. Implies '--format=<cumulsize>'. Conflicts with other format options. Required: no.
  - `with-local` [bool]: Compute the amount of the dag that is local, and if possible the total size. Required: no.


#### Response

On success, the call to this endpoint will return with 200 and the following body:

```text
{
    "Hash": "<string>"
    "Size": "<uint64>"
    "CumulativeSize": "<uint64>"
    "Blocks": "<int>"
    "Type": "<string>"
    "WithLocality": "<bool>"
    "Local": "<bool>"
    "SizeLocal": "<uint64>"
}

```

#### cURL Example

`curl "http://localhost:5001/api/v0/files/stat?arg=<path>&format=<hash>
Size: <size>
CumulativeSize: <cumulsize>
ChildBlocks: <childs>
Type: <type>&hash=<value>&size=<value>&with-local=<value>"`

***

### /api/v0/files/write

Write to a mutable file in a given filesystem.


#### Arguments

  - `arg` [string]: Path to write to. Required: **yes**.
  - `arg` [file]: Data to write. Required: **yes**.
  - `offset` [int]: Byte offset to begin writing at. Required: no.
  - `create` [bool]: Create the file if it does not exist. Required: no.
  - `truncate` [bool]: Truncate the file to size zero before writing. Required: no.
  - `count` [int]: Maximum number of bytes to read. Required: no.
  - `raw-leaves` [bool]: Use raw blocks for newly created leaf nodes. (experimental). Required: no.
  - `cid-version` [int]: Cid version to use. (experimental). Required: no.
  - `hash` [string]: Hash function to use. Will set Cid version to 1 if used. (experimental). Required: no.


#### Request Body

Argument "data" is of file type. This endpoint expects a file in the body of the request as 'multipart/form-data'.


#### Response

On success, the call to this endpoint will return with 200 and the following body:

```text
This endpoint returns a `text/plain` response body.
```

#### cURL Example

`curl -F file=@myfile "http://localhost:5001/api/v0/files/write?arg=<path>&offset=<value>&create=<value>&truncate=<value>&count=<value>&raw-leaves=<value>&cid-version=<value>&hash=<value>"`

***

### /api/v0/filestore/dups

List blocks that are both in the filestore and standard block storage.


#### Arguments

This endpoint takes no arguments.


#### Response

On success, the call to this endpoint will return with 200 and the following body:

```text
{
    "Ref": "<string>"
    "Err": "<string>"
}

```

#### cURL Example

`curl "http://localhost:5001/api/v0/filestore/dups"`

***

### /api/v0/filestore/ls

List objects in filestore.


#### Arguments

  - `arg` [string]: Cid of objects to list. Required: no.
  - `file-order` [bool]: sort the results based on the path of the backing file. Required: no.


#### Response

On success, the call to this endpoint will return with 200 and the following body:

```text
{
    "Status": "<int32>"
    "ErrorMsg": "<string>"
    "Key": "<string>"
    "FilePath": "<string>"
    "Offset": "<uint64>"
    "Size": "<uint64>"
}

```

#### cURL Example

`curl "http://localhost:5001/api/v0/filestore/ls?arg=<obj>&file-order=<value>"`

***

### /api/v0/filestore/verify

Verify objects in filestore.


#### Arguments

  - `arg` [string]: Cid of objects to verify. Required: no.
  - `file-order` [bool]: verify the objects based on the order of the backing file. Required: no.


#### Response

On success, the call to this endpoint will return with 200 and the following body:

```text
{
    "Status": "<int32>"
    "ErrorMsg": "<string>"
    "Key": "<string>"
    "FilePath": "<string>"
    "Offset": "<uint64>"
    "Size": "<uint64>"
}

```

#### cURL Example

`curl "http://localhost:5001/api/v0/filestore/verify?arg=<obj>&file-order=<value>"`

***

### /api/v0/get

Download IPFS objects.


#### Arguments

  - `arg` [string]: The path to the IPFS object(s) to be outputted. Required: **yes**.
  - `output` [string]: The path where the output should be stored. Required: no.
  - `archive` [bool]: Output a TAR archive. Required: no.
  - `compress` [bool]: Compress the output with GZIP compression. Required: no.
  - `compression-level` [int]: The level of compression (1-9). Required: no.


#### Response

On success, the call to this endpoint will return with 200 and the following body:

```text
This endpoint returns a `text/plain` response body.
```

#### cURL Example

`curl "http://localhost:5001/api/v0/get?arg=<ipfs-path>&output=<value>&archive=<value>&compress=<value>&compression-level=<value>"`

***

### /api/v0/id

Show ipfs node id info.


#### Arguments

  - `arg` [string]: Peer.ID of node to look up. Required: no.
  - `format` [string]: Optional output format. Required: no.


#### Response

On success, the call to this endpoint will return with 200 and the following body:

```text
{
    "ID": "<string>"
    "PublicKey": "<string>"
    "Addresses": [
        "<string>"
    ]
    "AgentVersion": "<string>"
    "ProtocolVersion": "<string>"
}

```

#### cURL Example

`curl "http://localhost:5001/api/v0/id?arg=<peerid>&format=<value>"`

***

### /api/v0/key/gen

Create a new keypair


#### Arguments

  - `arg` [string]: name of key to create Required: **yes**.
  - `type` [string]: type of the key to create [rsa, ed25519]. Required: no.
  - `size` [int]: size of the key to generate. Required: no.


#### Response

On success, the call to this endpoint will return with 200 and the following body:

```text
{
    "Name": "<string>"
    "Id": "<string>"
}

```

#### cURL Example

`curl "http://localhost:5001/api/v0/key/gen?arg=<name>&type=<value>&size=<value>"`

***

### /api/v0/key/list

List all local keypairs


#### Arguments

  - `l` [bool]: Show extra information about keys. Required: no.


#### Response

On success, the call to this endpoint will return with 200 and the following body:

```text
{
    "Keys": [
        {
            "Name": "<string>"
            "Id": "<string>"
        }
    ]
}

```

#### cURL Example

`curl "http://localhost:5001/api/v0/key/list?l=<value>"`

***

### /api/v0/key/rename

Rename a keypair


#### Arguments

  - `arg` [string]: name of key to rename Required: **yes**.
  - `arg` [string]: new name of the key Required: **yes**.
  - `force` [bool]: Allow to overwrite an existing key. Required: no.


#### Response

On success, the call to this endpoint will return with 200 and the following body:

```text
{
    "Was": "<string>"
    "Now": "<string>"
    "Id": "<string>"
    "Overwrite": "<bool>"
}

```

#### cURL Example

`curl "http://localhost:5001/api/v0/key/rename?arg=<name>&arg=<newName>&force=<value>"`

***

### /api/v0/key/rm

Remove a keypair


#### Arguments

  - `arg` [string]: names of keys to remove Required: **yes**.
  - `l` [bool]: Show extra information about keys. Required: no.


#### Response

On success, the call to this endpoint will return with 200 and the following body:

```text
{
    "Keys": [
        {
            "Name": "<string>"
            "Id": "<string>"
        }
    ]
}

```

#### cURL Example

`curl "http://localhost:5001/api/v0/key/rm?arg=<name>&l=<value>"`

***

### /api/v0/log/level

Change the logging level.


#### Arguments

  - `arg` [string]: The subsystem logging identifier. Use 'all' for all subsystems. Required: **yes**.
  - `arg` [string]: The log level, with 'debug' the most verbose and 'critical' the least verbose.
			One of: debug, info, warning, error, critical.
		 Required: **yes**.


#### Response

On success, the call to this endpoint will return with 200 and the following body:

```text
{
    "Message": "<string>"
}

```

#### cURL Example

`curl "http://localhost:5001/api/v0/log/level?arg=<subsystem>&arg=<level>"`

***

### /api/v0/log/ls

List the logging subsystems.


#### Arguments

This endpoint takes no arguments.


#### Response

On success, the call to this endpoint will return with 200 and the following body:

```text
{
    "Strings": [
        "<string>"
    ]
}

```

#### cURL Example

`curl "http://localhost:5001/api/v0/log/ls"`

***

### /api/v0/log/tail

Read the event log.


#### Arguments

This endpoint takes no arguments.


#### Response

On success, the call to this endpoint will return with 200 and the following body:

```text
This endpoint returns a `text/plain` response body.
```

#### cURL Example

`curl "http://localhost:5001/api/v0/log/tail"`

***

### /api/v0/ls

List directory contents for Unix filesystem objects.


#### Arguments

  - `arg` [string]: The path to the IPFS object(s) to list links from. Required: **yes**.
  - `headers` [bool]: Print table headers (Hash, Size, Name). Required: no.
  - `resolve-type` [bool]: Resolve linked objects to find out their types. Default: "true". Required: no.


#### Response

On success, the call to this endpoint will return with 200 and the following body:

```text
{
    "Objects": [
        {
            "Hash": "<string>"
            "Links": [
                {
                    "Name": "<string>"
                    "Hash": "<string>"
                    "Size": "<uint64>"
                    "Type": "<int32>"
                }
            ]
        }
    ]
}

```

#### cURL Example

`curl "http://localhost:5001/api/v0/ls?arg=<ipfs-path>&headers=<value>&resolve-type=true"`

***

### /api/v0/mount

Mounts IPFS to the filesystem (read-only).


#### Arguments

  - `ipfs-path` [string]: The path where IPFS should be mounted. Required: no.
  - `ipns-path` [string]: The path where IPNS should be mounted. Required: no.


#### Response

On success, the call to this endpoint will return with 200 and the following body:

```text
{
    "IPFS": "<string>"
    "IPNS": "<string>"
    "FuseAllowOther": "<bool>"
}

```

#### cURL Example

`curl "http://localhost:5001/api/v0/mount?ipfs-path=<value>&ipns-path=<value>"`

***

### /api/v0/name/publish

Publish IPNS names.


#### Arguments

  - `arg` [string]: ipfs path of the object to be published. Required: **yes**.
  - `resolve` [bool]: Resolve given path before publishing. Default: "true". Required: no.
  - `lifetime` [string]: Time duration that the record will be valid for.
    This accepts durations such as "300s", "1.5h" or "2h45m". Valid time units are
    "ns", "us" (or "µs"), "ms", "s", "m", "h". Default: "24h". Required: no.
  - `ttl` [string]: Time duration this record should be cached for (caution: experimental). Required: no.
  - `key` [string]: Name of the key to be used or a valid PeerID, as listed by 'ipfs key list -l'. Default:. Default: "self". Required: no.


#### Response

On success, the call to this endpoint will return with 200 and the following body:

```text
{
    "Name": "<string>"
    "Value": "<string>"
}

```

#### cURL Example

`curl "http://localhost:5001/api/v0/name/publish?arg=<ipfs-path>&resolve=true&lifetime=24h&ttl=<value>&key=self"`

***

### /api/v0/name/pubsub/cancel

Cancel a name subscription


#### Arguments

  - `arg` [string]: Name to cancel the subscription for. Required: **yes**.


#### Response

On success, the call to this endpoint will return with 200 and the following body:

```text
{
    "Canceled": "<bool>"
}

```

#### cURL Example

`curl "http://localhost:5001/api/v0/name/pubsub/cancel?arg=<name>"`

***

### /api/v0/name/pubsub/state

Query the state of IPNS pubsub


#### Arguments

This endpoint takes no arguments.


#### Response

On success, the call to this endpoint will return with 200 and the following body:

```text
{
    "Enabled": "<bool>"
}

```

#### cURL Example

`curl "http://localhost:5001/api/v0/name/pubsub/state"`

***

### /api/v0/name/pubsub/subs

Show current name subscriptions


#### Arguments

This endpoint takes no arguments.


#### Response

On success, the call to this endpoint will return with 200 and the following body:

```text
{
    "Strings": [
        "<string>"
    ]
}

```

#### cURL Example

`curl "http://localhost:5001/api/v0/name/pubsub/subs"`

***

### /api/v0/name/resolve

Resolve IPNS names.


#### Arguments

  - `arg` [string]: The IPNS name to resolve. Defaults to your node's peerID. Required: no.
  - `recursive` [bool]: Resolve until the result is not an IPNS name. Required: no.
  - `nocache` [bool]: Do not use cached entries. Required: no.
  - `dht-record-count` [uint]: Number of records to request for DHT resolution. Required: no.
  - `dht-timeout` [string]: Max time to collect values during DHT resolution eg "30s". Pass 0 for no timeout. Required: no.


#### Response

On success, the call to this endpoint will return with 200 and the following body:

```text
{
    "Path": "<string>"
}

```

#### cURL Example

`curl "http://localhost:5001/api/v0/name/resolve?arg=<name>&recursive=<value>&nocache=<value>&dht-record-count=<value>&dht-timeout=<value>"`

***

### /api/v0/object/data

Output the raw bytes of an IPFS object.


#### Arguments

  - `arg` [string]: Key of the object to retrieve, in base58-encoded multihash format. Required: **yes**.


#### Response

On success, the call to this endpoint will return with 200 and the following body:

```text
This endpoint returns a `text/plain` response body.
```

#### cURL Example

`curl "http://localhost:5001/api/v0/object/data?arg=<key>"`

***

### /api/v0/object/diff

Display the diff between two ipfs objects.


#### Arguments

  - `arg` [string]: Object to diff against. Required: **yes**.
  - `arg` [string]: Object to diff. Required: **yes**.
  - `verbose` [bool]: Print extra information. Required: no.


#### Response

On success, the call to this endpoint will return with 200 and the following body:

```text
{
    "Changes": [
        {
            "Type": "<int>"
            "Path": "<string>"
            "Before": "<string>"
            "After": "<string>"
        }
    ]
}

```

#### cURL Example

`curl "http://localhost:5001/api/v0/object/diff?arg=<obj_a>&arg=<obj_b>&verbose=<value>"`

***

### /api/v0/object/get

Get and serialize the DAG node named by <key>.


#### Arguments

  - `arg` [string]: Key of the object to retrieve, in base58-encoded multihash format. Required: **yes**.


#### Response

On success, the call to this endpoint will return with 200 and the following body:

```text
{
    "Links": [
        {
            "Name": "<string>"
            "Hash": "<string>"
            "Size": "<uint64>"
        }
    ]
    "Data": "<string>"
}

```

#### cURL Example

`curl "http://localhost:5001/api/v0/object/get?arg=<key>"`

***

### /api/v0/object/links

Output the links pointed to by the specified object.


#### Arguments

  - `arg` [string]: Key of the object to retrieve, in base58-encoded multihash format. Required: **yes**.
  - `headers` [bool]: Print table headers (Hash, Size, Name). Required: no.


#### Response

On success, the call to this endpoint will return with 200 and the following body:

```text
{
    "Hash": "<string>"
    "Links": [
        {
            "Name": "<string>"
            "Hash": "<string>"
            "Size": "<uint64>"
        }
    ]
}

```

#### cURL Example

`curl "http://localhost:5001/api/v0/object/links?arg=<key>&headers=<value>"`

***

### /api/v0/object/new

Create a new object from an ipfs template.


#### Arguments

  - `arg` [string]: Template to use. Optional. Required: no.


#### Response

On success, the call to this endpoint will return with 200 and the following body:

```text
{
    "Hash": "<string>"
    "Links": [
        {
            "Name": "<string>"
            "Hash": "<string>"
            "Size": "<uint64>"
        }
    ]
}

```

#### cURL Example

`curl "http://localhost:5001/api/v0/object/new?arg=<template>"`

***

### /api/v0/object/patch/add-link

Add a link to a given object.


#### Arguments

  - `arg` [string]: The hash of the node to modify. Required: **yes**.
  - `arg` [string]: Name of link to create. Required: **yes**.
  - `arg` [string]: IPFS object to add link to. Required: **yes**.
  - `create` [bool]: Create intermediary nodes. Required: no.


#### Response

On success, the call to this endpoint will return with 200 and the following body:

```text
{
    "Hash": "<string>"
    "Links": [
        {
            "Name": "<string>"
            "Hash": "<string>"
            "Size": "<uint64>"
        }
    ]
}

```

#### cURL Example

`curl "http://localhost:5001/api/v0/object/patch/add-link?arg=<root>&arg=<name>&arg=<ref>&create=<value>"`

***

### /api/v0/object/patch/append-data

Append data to the data segment of a dag node.


#### Arguments

  - `arg` [string]: The hash of the node to modify. Required: **yes**.
  - `arg` [file]: Data to append. Required: **yes**.


#### Request Body

Argument "data" is of file type. This endpoint expects a file in the body of the request as 'multipart/form-data'.


#### Response

On success, the call to this endpoint will return with 200 and the following body:

```text
{
    "Hash": "<string>"
    "Links": [
        {
            "Name": "<string>"
            "Hash": "<string>"
            "Size": "<uint64>"
        }
    ]
}

```

#### cURL Example

`curl -F file=@myfile "http://localhost:5001/api/v0/object/patch/append-data?arg=<root>"`

***

### /api/v0/object/patch/rm-link

Remove a link from an object.


#### Arguments

  - `arg` [string]: The hash of the node to modify. Required: **yes**.
  - `arg` [string]: Name of the link to remove. Required: **yes**.


#### Response

On success, the call to this endpoint will return with 200 and the following body:

```text
{
    "Hash": "<string>"
    "Links": [
        {
            "Name": "<string>"
            "Hash": "<string>"
            "Size": "<uint64>"
        }
    ]
}

```

#### cURL Example

`curl "http://localhost:5001/api/v0/object/patch/rm-link?arg=<root>&arg=<link>"`

***

### /api/v0/object/patch/set-data

Set the data field of an IPFS object.


#### Arguments

  - `arg` [string]: The hash of the node to modify. Required: **yes**.
  - `arg` [file]: The data to set the object to. Required: **yes**.


#### Request Body

Argument "data" is of file type. This endpoint expects a file in the body of the request as 'multipart/form-data'.


#### Response

On success, the call to this endpoint will return with 200 and the following body:

```text
{
    "Hash": "<string>"
    "Links": [
        {
            "Name": "<string>"
            "Hash": "<string>"
            "Size": "<uint64>"
        }
    ]
}

```

#### cURL Example

`curl -F file=@myfile "http://localhost:5001/api/v0/object/patch/set-data?arg=<root>"`

***

### /api/v0/object/put

Store input as a DAG object, print its key.


#### Arguments

  - `arg` [file]: Data to be stored as a DAG object. Required: **yes**.
  - `inputenc` [string]: Encoding type of input data. One of: {"protobuf", "json"}. Default: "json". Required: no.
  - `datafieldenc` [string]: Encoding type of the data field, either "text" or "base64". Default: "text". Required: no.
  - `pin` [bool]: Pin this object when adding. Required: no.
  - `quiet` [bool]: Write minimal output. Required: no.


#### Request Body

Argument "data" is of file type. This endpoint expects a file in the body of the request as 'multipart/form-data'.


#### Response

On success, the call to this endpoint will return with 200 and the following body:

```text
{
    "Hash": "<string>"
    "Links": [
        {
            "Name": "<string>"
            "Hash": "<string>"
            "Size": "<uint64>"
        }
    ]
}

```

#### cURL Example

`curl -F file=@myfile "http://localhost:5001/api/v0/object/put?inputenc=json&datafieldenc=text&pin=<value>&quiet=<value>"`

***

### /api/v0/object/stat

Get stats for the DAG node named by <key>.


#### Arguments

  - `arg` [string]: Key of the object to retrieve, in base58-encoded multihash format. Required: **yes**.


#### Response

On success, the call to this endpoint will return with 200 and the following body:

```text
{
    "Hash": "<string>"
    "NumLinks": "<int>"
    "BlockSize": "<int>"
    "LinksSize": "<int>"
    "DataSize": "<int>"
    "CumulativeSize": "<int>"
}

```

#### cURL Example

`curl "http://localhost:5001/api/v0/object/stat?arg=<key>"`

***

### /api/v0/p2p/listener/close

Close active p2p listener.


#### Arguments

  - `arg` [string]: P2P listener protocol Required: no.
  - `all` [bool]: Close all listeners. Required: no.


#### Response

On success, the call to this endpoint will return with 200 and the following body:

```text
This endpoint returns a `text/plain` response body.
```

#### cURL Example

`curl "http://localhost:5001/api/v0/p2p/listener/close?arg=<Protocol>&all=<value>"`

***

### /api/v0/p2p/listener/ls

List active p2p listeners.


#### Arguments

  - `headers` [bool]: Print table headers (HandlerID, Protocol, Local, Remote). Required: no.


#### Response

On success, the call to this endpoint will return with 200 and the following body:

```text
{
    "Listeners": [
        {
            "Protocol": "<string>"
            "Address": "<string>"
        }
    ]
}

```

#### cURL Example

`curl "http://localhost:5001/api/v0/p2p/listener/ls?headers=<value>"`

***

### /api/v0/p2p/listener/open

Forward p2p connections to a network multiaddr.


#### Arguments

  - `arg` [string]: Protocol identifier. Required: **yes**.
  - `arg` [string]: Request handling application address. Required: **yes**.


#### Response

On success, the call to this endpoint will return with 200 and the following body:

```text
This endpoint returns a `text/plain` response body.
```

#### cURL Example

`curl "http://localhost:5001/api/v0/p2p/listener/open?arg=<Protocol>&arg=<Address>"`

***

### /api/v0/p2p/stream/close

Close active p2p stream.


#### Arguments

  - `arg` [string]: Stream HandlerID Required: no.
  - `all` [bool]: Close all streams. Required: no.


#### Response

On success, the call to this endpoint will return with 200 and the following body:

```text
This endpoint returns a `text/plain` response body.
```

#### cURL Example

`curl "http://localhost:5001/api/v0/p2p/stream/close?arg=<HandlerID>&all=<value>"`

***

### /api/v0/p2p/stream/dial

Dial to a p2p listener.


#### Arguments

  - `arg` [string]: Remote peer to connect to Required: **yes**.
  - `arg` [string]: Protocol identifier. Required: **yes**.
  - `arg` [string]: Address to listen for connection/s (default: /ip4/127.0.0.1/tcp/0). Required: no.


#### Response

On success, the call to this endpoint will return with 200 and the following body:

```text
This endpoint returns a `text/plain` response body.
```

#### cURL Example

`curl "http://localhost:5001/api/v0/p2p/stream/dial?arg=<Peer>&arg=<Protocol>&arg=<BindAddress>"`

***

### /api/v0/p2p/stream/ls

List active p2p streams.


#### Arguments

  - `headers` [bool]: Print table headers (HagndlerID, Protocol, Local, Remote). Required: no.


#### Response

On success, the call to this endpoint will return with 200 and the following body:

```text
{
    "Streams": [
        {
            "HandlerID": "<string>"
            "Protocol": "<string>"
            "LocalPeer": "<string>"
            "LocalAddress": "<string>"
            "RemotePeer": "<string>"
            "RemoteAddress": "<string>"
        }
    ]
}

```

#### cURL Example

`curl "http://localhost:5001/api/v0/p2p/stream/ls?headers=<value>"`

***

### /api/v0/pin/add

Pin objects to local storage.


#### Arguments

  - `arg` [string]: Path to object(s) to be pinned. Required: **yes**.
  - `recursive` [bool]: Recursively pin the object linked to by the specified object(s). Default: "true". Required: no.
  - `progress` [bool]: Show progress. Required: no.


#### Response

On success, the call to this endpoint will return with 200 and the following body:

```text
{
    "Pins": [
        "<string>"
    ]
    "Progress": "<int>"
}

```

#### cURL Example

`curl "http://localhost:5001/api/v0/pin/add?arg=<ipfs-path>&recursive=true&progress=<value>"`

***

### /api/v0/pin/ls

List objects pinned to local storage.


#### Arguments

  - `arg` [string]: Path to object(s) to be listed. Required: no.
  - `type` [string]: The type of pinned keys to list. Can be "direct", "indirect", "recursive", or "all". Default: "all". Required: no.
  - `quiet` [bool]: Write just hashes of objects. Required: no.


#### Response

On success, the call to this endpoint will return with 200 and the following body:

```text
{
    "Keys": {
        "<string>": {
            "Type": "<string>"
        }
    }
}

```

#### cURL Example

`curl "http://localhost:5001/api/v0/pin/ls?arg=<ipfs-path>&type=all&quiet=<value>"`

***

### /api/v0/pin/rm

Remove pinned objects from local storage.


#### Arguments

  - `arg` [string]: Path to object(s) to be unpinned. Required: **yes**.
  - `recursive` [bool]: Recursively unpin the object linked to by the specified object(s). Default: "true". Required: no.


#### Response

On success, the call to this endpoint will return with 200 and the following body:

```text
{
    "Pins": [
        "<string>"
    ]
}

```

#### cURL Example

`curl "http://localhost:5001/api/v0/pin/rm?arg=<ipfs-path>&recursive=true"`

***

### /api/v0/pin/update

Update a recursive pin


#### Arguments

  - `arg` [string]: Path to old object. Required: **yes**.
  - `arg` [string]: Path to new object to be pinned. Required: **yes**.
  - `unpin` [bool]: Remove the old pin. Default: "true". Required: no.


#### Response

On success, the call to this endpoint will return with 200 and the following body:

```text
{
    "Pins": [
        "<string>"
    ]
}

```

#### cURL Example

`curl "http://localhost:5001/api/v0/pin/update?arg=<from-path>&arg=<to-path>&unpin=true"`

***

### /api/v0/pin/verify

Verify that recursive pins are complete.


#### Arguments

  - `verbose` [bool]: Also write the hashes of non-broken pins. Required: no.
  - `quiet` [bool]: Write just hashes of broken pins. Required: no.


#### Response

On success, the call to this endpoint will return with 200 and the following body:

```text
{
    "Cid": "<string>"
    "PinStatus": {
        "Ok": "<bool>"
        "BadNodes": [
            {
                "Cid": "<string>"
                "Err": "<string>"
            }
        ]
    }
}

```

#### cURL Example

`curl "http://localhost:5001/api/v0/pin/verify?verbose=<value>&quiet=<value>"`

***

### /api/v0/ping

Send echo request packets to IPFS hosts.


#### Arguments

  - `arg` [string]: ID of peer to be pinged. Required: **yes**.
  - `count` [int]: Number of ping messages to send. Default: "10". Required: no.


#### Response

On success, the call to this endpoint will return with 200 and the following body:

```text
{
    "Success": "<bool>"
    "Time": "<int64>"
    "Text": "<string>"
}

```

#### cURL Example

`curl "http://localhost:5001/api/v0/ping?arg=<peer ID>&count=10"`

***

### /api/v0/pubsub/ls

List subscribed topics by name.


#### Arguments

This endpoint takes no arguments.


#### Response

On success, the call to this endpoint will return with 200 and the following body:

```text
{
    "Strings": [
        "<string>"
    ]
}

```

#### cURL Example

`curl "http://localhost:5001/api/v0/pubsub/ls"`

***

### /api/v0/pubsub/peers

List peers we are currently pubsubbing with.


#### Arguments

  - `arg` [string]: topic to list connected peers of Required: no.


#### Response

On success, the call to this endpoint will return with 200 and the following body:

```text
{
    "Strings": [
        "<string>"
    ]
}

```

#### cURL Example

`curl "http://localhost:5001/api/v0/pubsub/peers?arg=<topic>"`

***

### /api/v0/pubsub/pub

Publish a message to a given pubsub topic.


#### Arguments

  - `arg` [string]: Topic to publish to. Required: **yes**.
  - `arg` [string]: Payload of message to publish. Required: **yes**.


#### Response

On success, the call to this endpoint will return with 200 and the following body:

```text
This endpoint returns a `text/plain` response body.
```

#### cURL Example

`curl "http://localhost:5001/api/v0/pubsub/pub?arg=<topic>&arg=<data>"`

***

### /api/v0/pubsub/sub

Subscribe to messages on a given topic.


#### Arguments

  - `arg` [string]: String name of topic to subscribe to. Required: **yes**.
  - `discover` [bool]: try to discover other peers subscribed to the same topic. Required: no.


#### Response

On success, the call to this endpoint will return with 200 and the following body:

```text
{
    "Message": {
        "From": [
            "<uint8>"
        ]
        "Data": [
            "<uint8>"
        ]
        "Seqno": [
            "<uint8>"
        ]
        "TopicIDs": [
            "<string>"
        ]
        "XXX_unrecognized": [
            "<uint8>"
        ]
    }
}

```

#### cURL Example

`curl "http://localhost:5001/api/v0/pubsub/sub?arg=<topic>&discover=<value>"`

***

### /api/v0/refs/local

List all local references.


#### Arguments

This endpoint takes no arguments.


#### Response

On success, the call to this endpoint will return with 200 and the following body:

```text
{
    "Ref": "<string>"
    "Err": "<string>"
}

```

#### cURL Example

`curl "http://localhost:5001/api/v0/refs/local"`

***

### /api/v0/repo/fsck

Remove repo lockfiles.


#### Arguments

This endpoint takes no arguments.


#### Response

On success, the call to this endpoint will return with 200 and the following body:

```text
{
    "Message": "<string>"
}

```

#### cURL Example

`curl "http://localhost:5001/api/v0/repo/fsck"`

***

### /api/v0/repo/gc

Perform a garbage collection sweep on the repo.


#### Arguments

  - `stream-errors` [bool]: Stream errors. Required: no.
  - `quiet` [bool]: Write minimal output. Required: no.


#### Response

On success, the call to this endpoint will return with 200 and the following body:

```text
{
    "Key": "<string>"
    "Error": "<string>"
}

```

#### cURL Example

`curl "http://localhost:5001/api/v0/repo/gc?stream-errors=<value>&quiet=<value>"`

***

### /api/v0/repo/stat

Get stats for the currently used repo.


#### Arguments

  - `human` [bool]: Output RepoSize in MiB. Required: no.


#### Response

On success, the call to this endpoint will return with 200 and the following body:

```text
{
    "NumObjects": "<uint64>"
    "RepoSize": "<uint64>"
    "RepoPath": "<string>"
    "Version": "<string>"
    "StorageMax": "<uint64>"
}

```

#### cURL Example

`curl "http://localhost:5001/api/v0/repo/stat?human=<value>"`

***

### /api/v0/repo/verify

Verify all blocks in repo are not corrupted.


#### Arguments

This endpoint takes no arguments.


#### Response

On success, the call to this endpoint will return with 200 and the following body:

```text
{
    "Msg": "<string>"
    "Progress": "<int>"
}

```

#### cURL Example

`curl "http://localhost:5001/api/v0/repo/verify"`

***

### /api/v0/repo/version

Show the repo version.


#### Arguments

  - `quiet` [bool]: Write minimal output. Required: no.


#### Response

On success, the call to this endpoint will return with 200 and the following body:

```text
{
    "Version": "<string>"
}

```

#### cURL Example

`curl "http://localhost:5001/api/v0/repo/version?quiet=<value>"`

***

### /api/v0/resolve

Resolve the value of names to IPFS.


#### Arguments

  - `arg` [string]: The name to resolve. Required: **yes**.
  - `recursive` [bool]: Resolve until the result is an IPFS name. Required: no.
  - `dht-record-count` [uint]: Number of records to request for DHT resolution. Required: no.
  - `dht-timeout` [string]: Max time to collect values during DHT resolution eg "30s". Pass 0 for no timeout. Required: no.


#### Response

On success, the call to this endpoint will return with 200 and the following body:

```text
{
    "Path": "<string>"
}

```

#### cURL Example

`curl "http://localhost:5001/api/v0/resolve?arg=<name>&recursive=<value>&dht-record-count=<value>&dht-timeout=<value>"`

***

### /api/v0/shutdown

Shut down the ipfs daemon


#### Arguments

This endpoint takes no arguments.


#### Response

On success, the call to this endpoint will return with 200 and the following body:

```text
This endpoint returns a `text/plain` response body.
```

#### cURL Example

`curl "http://localhost:5001/api/v0/shutdown"`

***

### /api/v0/stats/bitswap

Show some diagnostic information on the bitswap agent.


#### Arguments

This endpoint takes no arguments.


#### Response

On success, the call to this endpoint will return with 200 and the following body:

```text
{
    "ProvideBufLen": "<int>"
    "Wantlist": [
        "<string>"
    ]
    "Peers": [
        "<string>"
    ]
    "BlocksReceived": "<uint64>"
    "DataReceived": "<uint64>"
    "BlocksSent": "<uint64>"
    "DataSent": "<uint64>"
    "DupBlksReceived": "<uint64>"
    "DupDataReceived": "<uint64>"
}

```

#### cURL Example

`curl "http://localhost:5001/api/v0/stats/bitswap"`

***

### /api/v0/stats/bw

Print ipfs bandwidth information.


#### Arguments

  - `peer` [string]: Specify a peer to print bandwidth for. Required: no.
  - `proto` [string]: Specify a protocol to print bandwidth for. Required: no.
  - `poll` [bool]: Print bandwidth at an interval. Required: no.
  - `interval` [string]: Time interval to wait between updating output, if 'poll' is true.

    This accepts durations such as "300s", "1.5h" or "2h45m". Valid time units are:
    "ns", "us" (or "µs"), "ms", "s", "m", "h". Default: "1s". Required: no.


#### Response

On success, the call to this endpoint will return with 200 and the following body:

```text
{
    "TotalIn": "<int64>"
    "TotalOut": "<int64>"
    "RateIn": "<float64>"
    "RateOut": "<float64>"
}

```

#### cURL Example

`curl "http://localhost:5001/api/v0/stats/bw?peer=<value>&proto=<value>&poll=<value>&interval=1s"`

***

### /api/v0/stats/repo

Get stats for the currently used repo.


#### Arguments

  - `human` [bool]: Output RepoSize in MiB. Required: no.


#### Response

On success, the call to this endpoint will return with 200 and the following body:

```text
{
    "NumObjects": "<uint64>"
    "RepoSize": "<uint64>"
    "RepoPath": "<string>"
    "Version": "<string>"
    "StorageMax": "<uint64>"
}

```

#### cURL Example

`curl "http://localhost:5001/api/v0/stats/repo?human=<value>"`

***

### /api/v0/swarm/addrs/listen

List interface listening addresses.


#### Arguments

This endpoint takes no arguments.


#### Response

On success, the call to this endpoint will return with 200 and the following body:

```text
{
    "Strings": [
        "<string>"
    ]
}

```

#### cURL Example

`curl "http://localhost:5001/api/v0/swarm/addrs/listen"`

***

### /api/v0/swarm/addrs/local

List local addresses.


#### Arguments

  - `id` [bool]: Show peer ID in addresses. Required: no.


#### Response

On success, the call to this endpoint will return with 200 and the following body:

```text
{
    "Strings": [
        "<string>"
    ]
}

```

#### cURL Example

`curl "http://localhost:5001/api/v0/swarm/addrs/local?id=<value>"`

***

### /api/v0/swarm/connect

Open connection to a given address.


#### Arguments

  - `arg` [string]: Address of peer to connect to. Required: **yes**.


#### Response

On success, the call to this endpoint will return with 200 and the following body:

```text
{
    "Strings": [
        "<string>"
    ]
}

```

#### cURL Example

`curl "http://localhost:5001/api/v0/swarm/connect?arg=<address>"`

***

### /api/v0/swarm/disconnect

Close connection to a given address.


#### Arguments

  - `arg` [string]: Address of peer to disconnect from. Required: **yes**.


#### Response

On success, the call to this endpoint will return with 200 and the following body:

```text
{
    "Strings": [
        "<string>"
    ]
}

```

#### cURL Example

`curl "http://localhost:5001/api/v0/swarm/disconnect?arg=<address>"`

***

### /api/v0/swarm/filters/add

Add an address filter.


#### Arguments

  - `arg` [string]: Multiaddr to filter. Required: **yes**.


#### Response

On success, the call to this endpoint will return with 200 and the following body:

```text
{
    "Strings": [
        "<string>"
    ]
}

```

#### cURL Example

`curl "http://localhost:5001/api/v0/swarm/filters/add?arg=<address>"`

***

### /api/v0/swarm/filters/rm

Remove an address filter.


#### Arguments

  - `arg` [string]: Multiaddr filter to remove. Required: **yes**.


#### Response

On success, the call to this endpoint will return with 200 and the following body:

```text
{
    "Strings": [
        "<string>"
    ]
}

```

#### cURL Example

`curl "http://localhost:5001/api/v0/swarm/filters/rm?arg=<address>"`

***

### /api/v0/swarm/peers

List peers with open connections.


#### Arguments

  - `verbose` [bool]: display all extra information. Required: no.
  - `streams` [bool]: Also list information about open streams for each peer. Required: no.
  - `latency` [bool]: Also list information about latency to each peer. Required: no.


#### Response

On success, the call to this endpoint will return with 200 and the following body:

```text
{
    "Peers": [
        {
            "Addr": "<string>"
            "Peer": "<string>"
            "Latency": "<string>"
            "Muxer": "<string>"
            "Streams": [
                {
                    "Protocol": "<string>"
                }
            ]
        }
    ]
}

```

#### cURL Example

`curl "http://localhost:5001/api/v0/swarm/peers?verbose=<value>&streams=<value>&latency=<value>"`

***

### /api/v0/tar/add

Import a tar file into ipfs.


#### Arguments

  - `arg` [file]: Tar file to add. Required: **yes**.


#### Request Body

Argument "file" is of file type. This endpoint expects a file in the body of the request as 'multipart/form-data'.


#### Response

On success, the call to this endpoint will return with 200 and the following body:

```text
{
    "Name": "<string>"
    "Hash": "<string>"
    "Bytes": "<int64>"
    "Size": "<string>"
}

```

#### cURL Example

`curl -F file=@myfile "http://localhost:5001/api/v0/tar/add"`

***

### /api/v0/tar/cat

Export a tar file from IPFS.


#### Arguments

  - `arg` [string]: ipfs path of archive to export. Required: **yes**.


#### Response

On success, the call to this endpoint will return with 200 and the following body:

```text
This endpoint returns a `text/plain` response body.
```

#### cURL Example

`curl "http://localhost:5001/api/v0/tar/cat?arg=<path>"`

***

### /api/v0/update




#### Arguments

  - `arg` [string]: Arguments for subcommand. Required: no.


#### Response

On success, the call to this endpoint will return with 200 and the following body:

```text
This endpoint returns a `text/plain` response body.
```

#### cURL Example

`curl "http://localhost:5001/api/v0/update?arg=<args>"`

***

### /api/v0/version

Show ipfs version information.


#### Arguments

  - `number` [bool]: Only show the version number. Required: no.
  - `commit` [bool]: Show the commit hash. Required: no.
  - `repo` [bool]: Show repo version. Required: no.
  - `all` [bool]: Show all version information. Required: no.


#### Response

On success, the call to this endpoint will return with 200 and the following body:

```text
{
    "Version": "<string>"
    "Commit": "<string>"
    "Repo": "<string>"
    "System": "<string>"
    "Golang": "<string>"
}

```

#### cURL Example

`curl "http://localhost:5001/api/v0/version?number=<value>&commit=<value>&repo=<value>&all=<value>"`

***

![img](https://gguoss.github.io/img/orchildprotocol.png)

### 摘要

互联网的飞速发展， 越来越多的方法和途径可以很有效的快速发现和查找个人及组织的隐私， 因此， 大众对匿名化保护隐私的需求越来越迫切。 虽然现在有些方法(如I2P和洋葱网络)被广泛采用，但是这些网络只有几千名志愿者愿意加入中继和出口节点， 这样会导致攻击者可以用很少数量的节点轻易的监视整个加密网络。我们提出基于市场的“带宽挖矿“的方法， 来激励大家加入中继和出口节点。
本文旨在描述一个一直在开发的系统。因此会实时的更新该文内容，用以描述在实施当中遇到问题而对系统的调整； 并且该系统可以灵活的使用库组件和特定的加密算法。然而， 不管怎样调整系统，系统的本质会保持目标和目的不变。
我们的设计内容包括：

- 基于区块链(具有顺序打包交易的数据)的随机支付机制
- 带宽销售规格的商品说明书
- 归纳证明一个在对等分布式系统中使得Eclipse攻击非常困难的方法
- 在攻击者可能会将其出价作为攻击的一部分的情况下，适用于销售带宽的高效安全硬化拍卖机制
- 完全分布式的匿名带宽市场

### 1. 介绍

兰花协议将带宽卖家组织成一个刚性结构化的对等（P2P）网络，称为兰花市场。客户连接到兰花市场，并向多个带宽卖家做支付，形成特定网络服务器的代理链。 代理链允许客户从全球互联网发送和接收数据。
![img](https://gguoss.github.io/img/Orchid_connect.png)
与从全球互联网发送和接收数据的更常见的方法不同，兰花市场中的代理链自然地将关于数据的来源和目的信息分离;没有一个中继或代理同时持有两条信息，或者知道某人的身份。兰花市场的刚性结构进一步支持信息分离，提供强大的抵抗串通攻击的能力 — 一组带宽卖家克服知识分离的能力。不同于互联网数据常用的传输方法，兰花市场提供固定速率中继，以防止流量分析，并通过代币激励大家发现检举隐藏或者信息无关的参与的参与节点。在我们描述系统的细节之前，我们将简要回顾一下解决的核心问题，以及我们为系统基础选择的一般解决方案。

#### 1.1. 信息加密传送问题

**问题陈述**：想象一下，你在一个充满数学家的食堂里，希望在没有任何人知道这个事实的情况下，向你的朋友发送消息。 您尚未通过指定协议传递消息，因此所有实施细节都必须向所有人公开声明。 可以怎么做呢？
Chaum在1981年提出的这个问题的一个特别优雅的解决方案是让每个人都作为一个中继和一个接收者。 在这个方案中，参与者准备加密的消息，它们是数字等效的“包含信封的信封” - 向Alice发送消息，你会计算

```
Enc(“T oBob 00 ||Enc(“T oAlice 00 ||Enc(message, Alice), Bob), Carol)
```

并将该消息发送给Carol，他们将其解密并发送给Bob，Bob将其解密并发送给Alice。 为了防止流量分析，每个周期都会发送固定数量的消息。 为了处理返回地址，我们可以让Bob和Carol记住一个唯一的消息标识符，然后沿着这一条链路发送消息。
对使用上述方法的系统特别重要的是共谋的可能性。 如果Bob和Carol合作，他们可能会决定谁发送给定的消息以及发送给谁的消息。

#### 1.2. 女巫问题

上述食堂问题陈述使用每个人本身来防止女巫攻击 - 一个参与者可能假装是任意大量的用户的情况。 不幸的是，在数字系统中，这种方法是不能使用的。
**问题陈述**：我们如何知道某人在纯数字环境中是“真实的”？
这个问题的解决方案可以在Hashcash [81]中找到。如果我们要求声称是“真实的”来消耗计算资源的话，那么我们可以把女巫攻击者置于只有拥有不可思议的计算资源才有能力攻击的位置。

#### 1.3. 随机选择问题

上述食堂问题陈述假定了一种向系统的每个其他用户发送消息的简单方法（例如，横跨自助餐厅）。为了实现最大限度地抵抗“共谋攻击”的Chaumian组合，我们需要能够从那些“真实”的中继节点中随机选择。无论何时加入或离开网络，都需要收到通知。不幸的是，在现实世界的P2P网络中，每个用户维护这样的列表将导致不可接受的网络流量（O（n 2）通知）。
**问题描述** ：我们如何维护所有当前“真实”中继节点的分布式列表，以最大限度地减少网络开销，并支持高效率的随机选择对等体？
Chord [81]分布式哈希表（DHT）中可以找到一个特别优雅的解决方案。 在该方案中，对等体在大空间中分配唯一的地址，然后以在O（log（n））时间内执行查找的方式连接。 添加或删除用户只需要通知O（log（n））对等体。

#### 1.4. 系统总览

“兰花协议”的核心是上述解决方案的组合。在我们的方法中，同行们需要制作奖章来证明他们的“真实性”，然后被组织成一个称为兰花市场的分布式P2P网络。为了保持兰花市场的参与者诚实，每个同行都会检查其邻居行为的正确性。客户然后使用兰花市场为Chaumian消息转发选择随机对等体。为了激励参与，我们的客户以每转发字节为单位向中继节点支付报酬。
这想法虽然简单，但依然需要魔鬼的细节。系统要完全分散，完全自主，完全匿名，并且能做金融交易。因此，本设计文件的大部分内容集中在防止对客户安全，系统性能和系统经济性的攻击稳健。虽然攻击分析是重要的，并且将占用我们大部分时间，但最终只不过是市场运行背景下的必要条件; 如果你发现自己“迷失在森林里”，我们希望你将使用前面的总览作为你的北极星 - 系统的设计细节都是为了实现上述三个问题的真实解决方案。

### 2. 攻击

本文的大部分内容都是针对攻击预防，我们首先回顾一下关于这些攻击的文献对P2P网络尤其常见。

#### 2.1. 攻击目标

2.1.1. 信息收集
兰花协议必须保卫的最大的攻击类型是 揭示有关其用户的信息。因为兰花被实现为现有互联网上的叠加层，一些信息不可避免地与一些同行共享。 在下面的列表中，这样的信息被标记为“*”。任何未被明确列出的信息在本文档中不可避免地共享，但是发现了一种方法来发现信息被称为信息攻击，并被Orchid的White Hat Bug Bounty所覆盖。有关共享内容的更多信息，请参见第8节中的协议规范和第9.2节中的串通讨论以及网络参考实现[1]。
被认为是攻击者感兴趣的数据的类型（永恒的）：

- 现实世界的身份信息。 如用户的姓名， SSN， 地址等。

- 网站帐户信息。用户帐户在特定的网站。 注意这可以查找不同现实世界身份信息。

- *IP信息。 用户访问兰花网络的IP地址。 请注意，在某些使用场景中，这可能等同于知道“真实世界身份信息”。

- *ethereum信息。 与用户钱包相关联的*公钥和私钥。 请注意，在某些使用场景中，这可能等同于知道“真实世界身份信息”。

- *兰花网络信息。 与兰花网络上的节点当前业务相关联的密钥（*公钥或私钥）。
  被认为是攻击者感兴趣的行为信息的类型（时间和链相关联数据）：

- *客户识别。 攻击者探悉客户的IP地址。

- *中继识别。 攻击者探悉中继的IP地址。

- *代理识别。 攻击者探悉代理的IP地址。

- *链接识别。 攻击者探悉到在链中使用了两个IP地址。

- *网站访问。 攻击者探悉到兰花网络进行了outbound连接到一个特定的网站。

- *Web服务器访问。攻击者了解到，从兰花网络到特定的网络服务器（可能会托管多个网站）进行了出站连接。

- *以太坊联系。 攻击者了解到，一个兰花用户持有一个Ethereum公钥。

- *购买联系。 攻击者了解到两个交易共享一个付款人。

- *购买信息。 攻击者了解通过链发送的带宽的数量和时间。

  ​

  尽管上述行为信息在正常操作期间与兰花网络上的其他节点共享，如下所述，在大多数情况下，假设用户只有在行为信息收集时才会受到直接的伤害，如果攻击者可以快速探悉几条信息。例如，要说用户X访问了网站Y，攻击者将需要：买方识别，网站访问信息和几条链接标识。 因此，遵循参考规格的同行不会存储或共享上述任何信息，除非提供客户购买的服务所需。

  #### 2.2. 经济攻击

  与相关系统不同， 兰花协议必须关心支付机制的攻击。本文归纳两大类如下：

  ​

  -1. 经济利益。 有利的不良行为，例如用户提供“免费样品”带宽，允许用户专门使用免费样品带宽。

  ​

  -2. 经济拒绝服务（EDoS）。 使用付款来淹没兰花网络上的另一个节点进行购买，从而使其脱机。

  #### 2.3. 服务质量攻击

  一些对手可能会通过放慢兰花网络用户的系统性能来满足，从而潜在地减少使用。

  #### 2.4. 中间人攻击

  只有在两个互动方之间插入自己才能执行的操作统称为中间人攻击。可以记录加密的信息用于分析元数据（第2.8节），而非加密数据可能另外被更改为控制行为。如果密钥交换没有得到保障，中间人也可能会欺骗双方使其错误地认为攻击者的密钥是对方的密钥。

  #### 2.5. 女巫攻击

  伪装成多个用户执行恶意行为称为Sybil攻击，使被攻击者承受多方伪装用户的假冒数据。这种攻击的应用包括：

- 向Yelp, Amazon 等平台提供多个reviews。

- 通过假装是多个倾听者来实现BitTorrent从而可以快速下载[72]。

  #### 2.6. 日蚀攻击

  在日蚀攻击中，攻击者的目标是隐藏系统的一部分。 采用的方法是一般网络相当于特权升级攻击：获得网络位置的控制权更多地控制网络，然后使用该控制来获取更多的控制权。

- 比特币的p2p，所有节点都是平等地位，端口数是有限制的，需要”51%”攻击的比特币网络把临近节点的端口数全被攻击者给占用，以致用小于51%的算力通过欺骗临近节点加入自己的网络，对比特币形成“51%“攻击。

- 通过接管与磁链接相关联的地址空间，从BitTorrent DHT中删除文件[83]。

  #### 2.7. 拒绝服务攻击

  拒绝服务攻击即是攻击者想办法让目标机器停止提供服务。 “意外”情况下的系统行为通常指定和测试不足。 DoS攻击对P2P网络中的节点进行去匿名化是非常有用的。

- 对特定目标DoS攻击结合女巫攻击来监测Tor的流量从而获悉匿名化的信息[53]。

- 只需要20个女巫节点，Dos就能 完全可以泛滥式攻击I2P的数据库使其脱机，从而对网络上的所有流量进行归档。

  #### 2.8. 推理攻击

  源于系统行为的统计建模的去匿名化被称为推理攻击或监视攻击。这些通常与精心制作或定时的“探测动作”相结合请求或其他攻击，例如DoS将特定对等体脱离网络并观察流量模式

  ​

  响应。

- 从SSL加密的Web流量推断医疗疾病、家庭收入和最终用户的投资选择[ 58 ]。

- 来自全球传输日志的Tor，I2P和兰花流量的分析去除匿名[60]。

- 通过时序分析学习OpenSSL服务器的私钥[55]。

  #### 2.9. 黑客

  通过将历史上可信赖的对等体转换为攻击向量，激励的攻击者可能会直接危及网络上的节点。当使用链部署带宽时，迭代黑客可能最终允许攻击者“回溯”连接。这种攻击具有重要的安全隐患，但不符合兰花网络的范围。 如果兰花网的设计达到目标，这将是对系统用户的主要攻击。

  ### 3. 可替代的方法

  #### 3.1. 不受保护的互联网访问

  在没有保护的情况下访问互联网的用户将其完整的浏览历史记录和网站使用情况提供给ISP，然后他们可以共享或出售该数据。

  #### 3.2. 虚拟专用网络（VPN）服务

  虚拟专用网（VPN）使用加密技术将VPN用户的流量安全地传输到更大的不安全网络。 一旦VPN接收到流量，它将被解密并通过不同的大型不安全网络重新传输。 重传可以帮助用户规避网站的访问限制，并在较小的程度上减少对他们网站浏览习惯的跟踪。加密防止用户的ISP看到他们的流量，从而防止监视攻击。 这是通过使VPN成为用户的新ISP来实现的。 以前ISP可以执行的任何攻击都可以由VPN提供商轻松执行。

  ​

  VPN用户不应该认为他们的VPN提供商是值得信赖的。 尽管VPN服务提供商面临比ISP更多的竞争，但他们最终从相同的来源获得人才，并且具有类似的带宽 - 强制型商业模式。 VPN提供商不可能不会受到导致用户不信任他们的ISP的同样的激励。 另外，在VPN设置中重复使用IP地址来中继流量，可以相对容易地阻止商业网站的使用[13]。

  #### 3.3. TOR

  Tor [61]是一个免费软件项目，以向更广泛的受众介绍洋葱路由的思想而闻名。 在这个系统中，用户下载一个中继和出口节点的全局列表，随机从列表中选择，并从他们的选择形成洋葱路线。 洋葱路线是中继的有序列表; 为每个对等体轮流发送的数据包依次加密，确保每个节点都必须收到一个数据包才能被出口节点理解。结果是，除非有多个节点被同一个用户入侵或运行，否则两个中继都不知道谁发送了一个数据包，也不知道它到了哪里。

  ### 4. 扩展库

  兰花的功能是建立在几个重要的组件上。 由于一些读者可能不熟悉这些原语，或者不熟悉兰花网络中使用的特定属性，我们在这里简要总结一下。

  #### 4.1. WEBRTC

  WebRTC [48]是最初设计用来促进Web浏览器之间实时通信的系统。 它提供了优秀的NAT和防火墙穿越方法，包括STUN，ICE，TURN和RTP-over-TCP。 通过选择WebRTC作为我们网络协议的基础，而不是定制编码的TCP和UDP网络代码，我们都获得了这些技术的世界级实施，并且（在一定程度上）将用户的流量掩盖为一般的网络流量。

  #### 4.2. NACL

  NaCL [49]（发音为“salt”）是Daniel J.Bernstein等人的一个密码学库，专注于构建构建高级加密工具所需的核心操作。 它被选为这个项目的密码原语的来源，因为它和它的作者的英镑声誉。 下面介绍的所有加密操作都是使用NaCL实现的，除了以太坊智能合约加密代码。

  #### 4.3. 以太坊

  以太坊[56]是一个分散的区块链平台，包括一个本地货币（ETH）和Turingcomplete智能合约。 这些智能合约对于Orchid的设计非常有用，使我们能够减轻与追踪付款余额有关的大量设计问题，以及Orchid付款门票的验证和公正性。

  ### 5. 奖章

  完全分散的，完匿名的数字系统遭受单个恶意用户假装成千上万用户（Sybil攻击）的攻击。

  ​

  为了打击这类攻击，兰花协议使用奖章 - 数据表明给定的公钥在给定时间拥有相当数量的计算。 由于计算是一种昂贵的资源，因此使用奖章会对给定的攻击者假冒多个用户的能力造成预算限制。

  #### 5.1. 奖章规则

  为了生成奖章，对等体采用公钥K，并且最近的以太坊块哈希E，然后（迭代地或并行地）定位盐S，使得H（K，E，S）≥ N，其中N是一些 难度缩放因子。

  ​

  因为它是特定的密钥，所以不能用来模拟多个公钥。 因为它被绑在一个以太坊块哈希，不能预先计算。

  #### 5.2. 证明类型的选择

  熟悉其他基于分布式市场的网络的读者将会认可Medallion在工作证明系统（比特币等）的前提下是相似的，并且可能会倾向于问：为什么不使用权益证明（proof-of-stake）， 空闲证明(proof-of-idle)，还是其他不那么有力的浪费方法来证明“真实性”？

  ​

  权益证明取决于没有攻击者将控制大多数代币的假设。 由于我们的攻击模式包括压迫政府，这是不能指望的。 即使比特币的惊人的市值也远远低于一个中等规模国家的国内生产总值。更为复杂的是，在不久的将来，我们打算将这个系统扩大到支持匿名支付，这将使得发现这种“敌意收购”变得更加困难。简而言之：我们并没有使用权益证明，因为我们不想设计一个系统，让我们的用户的隐私权可以出售给出价最高的人。

  ​

  空间证明(proof-of-space)看起来更有趣。尽管我们不确定将找到合适的方法，但我们会在即将到来的兰花协议版本中使用空间证明。 例如，这将允许用户在家中安装旧的智能电话作为中继和代理。有关这个想法的更多信息，请参见15.1节。

  ​

  空闲证明基于额外的假设，即周期性同步工作证明足以证明用户对全局计算能力的分享。

  ​

  遗憾的是，在网络尚处于起步阶段（少于1,000万传播者）的情况下，任何一家控制超级计算中心的公司都只要牺牲1％的计算能力就能控制网络。正如我们所指出的，在我们没有拥有足够数量的传播者之前，我们不会使用空闲证明。

  ### 6. 奖章式工作证明

  奖章构成了我们核心安全假设与整个网络之间的桥梁。由于我们的基本安全目标是限制激励攻击者获得对兰花网络的控制权，因此我们选择的奖章创作必须符合以下条件：

1. 对于非恶意节点来说，创建奖章必须非常容易。
2. 奖章必须很容易验证。
3. 奖章必须难以批量创建。
   有了这些条件，我们将难度定义为在时间和金钱上的高度可伸缩性。 简而言之，我们需要一个工作证明系统，在这个系统中，一个正常的节点很容易进入网络，但攻击者难以进入网络。 我们将讨论我们选择的工作证明，而不是其他方法，例如权益证明或者空间证明。
   目前存在两种主要的方法来满足上述要求：质询-响应协议和加密难题。不幸的是，质询- 响应协议可能不能在兰花模型中提供足够的安全性，因为攻击者可能通过合谋预先计算质询并作出响应。这留下了今天有很多存在的加密难题[51,76]，每个难题都有自己的权衡。同样，为了满足兰花的要求，只有这些密码拼图的一个子集是合适的。也就是说，平行化的密码拼图，制作成ASIC，或平凡地缩放这样的手段是非常困难的。最近，研究人员发现了一些算法，可以产生易于验证的结果，这些结果具有可调的创建难度[51]。这些算法集合利用了内存和总硅片面积昂贵的趋势[46,62]。这类算法被称为不对称记忆硬功能，我们用它们来创建奖章。这些功能有几种类型[51,73,82]，但我们选择使用Equihash。Equihash基于k-XOR生日问题，通过时空折衷方案提供记忆硬度。由于Equihash是可调的，简单的，基于NP问题，并且已经在加密货币社区中被接受，所以我们相信使用这样的函数作为我们的工作证明基础提供了可接受的安全性和面向未来的水平。
   为了产生奖章，一个同伴拿一个公钥K，以前的以太坊块散列E，然后进行一系列的计算，以便定位一个盐S，使得F（K，E，S，…）≥N 其中N是一些难度缩放因子。 当一个新的以太坊块被添加到链中时，必须计算一个新的S来保持当前的奖章。

### 7. 支付

#### 7.1. 兰花支付需求

支付带宽是一个相当独特的挑战。 在大多数其他支付系统中，物品的成本远远高于发送包的成本，因此联网成本可能被安全成本忽略，被包括在交易成本中。然而，在兰花网络中，一个包的成本就是支付的价格，所以即使支付的交易成本低于一个包，它们的购买成本也是相同的。
因此，我们要求交易费用足够低，以便用户可以（自动通过Orchid客户端）支付任意数量的中继流量，直至单个数据包。除了低交易费用之外，支付机制必须足够精细，以至于可以进行微支付甚至纳支付。这不仅要求支付机制的效率，而且要求支付基础物品或可核实记录的可分性。
由于兰花网络的目的是为了摆脱网络监控和审查制度，支付机制的其他要求还包括不可靠，匿名，不依赖于可信任的第三方。即使底层网络不受监视和审查，如果付款机制不是，那么它就将使得用户可以被审查和跟踪。同样，可信赖的第三方可能在影响支付提供商的国家行为体和其他强大实体的干涉之下暴露兰花网络暴。
因此，兰花网络的支付需求包括：
*1. 不可伪造性，只有拥有付款接受的抵押物品或可核实记录的所有者才能够使用它进行付款。* 2. 可用性，意味着没有人可以阻止用户发送兰花付款，也没有人可以阻止收款人收到付款。
*3. 不可逆转性，即使是付款方，也不可能扭转过去的付款。* 4. 匿名，定义为发件人和收件人的不可链接性，无论是按帐户地址，金额还是时间，都找不到用户信息走过的痕迹。 理想情况下，匿名会达到如下的效果： 不仅是在恶意的观察者的攻击下，还是发送者或接收者的恶意攻击下，都能是匿名的。
在下面的章节中，我们将讨论支付的潜在解决方案，牢记这些要求。我们会辩证的去讨论，兰花支付（7.12节）完成除匿名要求以外的所有内容。下面，我们继续讨论支付匿名，效率的扩展和改进。

#### 7.2. 数据包的成本

为了讨论的目的，假设一个数据包长度为1×103个字节。 为了计算上限，我们观察到亚马逊网络服务的新加坡CloudFront是最昂贵的云服务之一，每1×109字节收费0.14美元。 这产生了每个数据包的成本为1.4×10-5（$ 0.00000014）。由于带宽是一种浪费（任何未售出的带宽永远丢失），实际价格可能会明显低于这个上限。

#### 7.3. 传统支付

在目前的金融支付系统中，交易是通过两个或两个以上的实体（如银行或支付服务提供商[2]）之间的谈判来解决的，支付卡采用ISO / IEC 7816 [3]，银行支付采用EBICS [4]。这些协议运行在SWIFT [5]和NYCE [6]等网络上，以支持国内和国际交易。组成这些网络的实体每个都保留自己的分类账，并不断从电子支付收据和手动调解中更新它们[7]。
连接到传统的支付网络通常需要大多数司法管辖区的特殊许可以及连接实体之间的逐案业务协议。由此产生的全球金融网络可以被看作是连接企业和协议和网络混合的一个许可的临时网络。每一个分类账都代表一个单一的失败点，缺乏密码的完整性，并可以随意的控制业务实体。
虽然传统的支付协议通常不会自行定义交易费用，但是运行协议的实体却增加了收费。 每笔交易费用可以从支付卡交易的几美分[8]到国际电汇[75]的75美元不等。 许多系统反过来又收取了一笔交易金额的百分比费用，对于银行转账支付可能高达13％[10]，对支付卡支付则为3.5％[11]。
由于传统付款取决于可信任的各方，因此在不牺牲我们所需的性能的情况下，实际上不可能使用兰花网络。特别是，可逆性是以逆转交易的形式设计出来的[75]。 交易通常很难伪造，但信用卡欺诈是常见的，身份盗窃或黑客攻击可能导致用户帐户被盗用。此外，这些支付系统仅提供部分可用性，因为它们往往在不方便的时候发生故障并定期遭受停机。由于管理支付的可信方通常不仅有发送者，接收者，支付金额和时间的记录，而且经常还有关于发送者的身份信息，所以缺乏匿名性。 最后，我们将在下面的章节中看到，传统支付的交易费用相对于兰花市场来说，将非常昂贵。

#### 7.4. 区块链支付

比特币彻底改变了传统支付系统的现状，并继续扰乱全球支付和国际转移市场。比特币是一个全球性的网络和协议，不知道地理边界。 应用公钥密码术，交易在用户自己生成的地址之间转移比特币金额，而不需要任何可信任的方。 用户生成密钥对，其中公钥的散列可以用作支付地址，要求私钥签名从地址传输[12]。 比特币支付是不可伪造的，不可逆转的[77]（在合理的时间内以计算区块确认）。 比特币网络自成立以来停机时间最短，而矿工（除了第7.6节进一步讨论的）不太可能出现活跃的审查情况，因此可以将其视为普遍可用。比特币支付是伪匿名的，匿名程度在很大程度上取决于 如何使用网络[68]。
一般来说，分散式加密货币允许人类和计算机系统在历史上第一次在没有可信赖的第三方的情况下进行价值交易 - 激励的分布式覆盖网络（如兰花）。
比特币的交易费用不是由交易金额决定的，而是由交易数据结构的大小乘以发件人配置的因子决定的。 直到2017年，平均交易费仍远低于1美元，但随着比特币网络达到最大交易容量，2017年2月费用迅速上涨。 平均费用上涨了13美元，高达8美元，使得依靠比特币网络上的低费用的应用程序成为可能。
以太坊网络也植根于公钥密码学，并通过像比特币这样的工作证明进行保护，从而获得了不可伪造性，可用性和（非经典）不可逆性的相同属性。 以太坊拥有更高的动态可调整的交易容量，自2015年推出以来，网络的收费水平一直很低。但是，由于交易数量增加以及以太坊基础本地代币Ether的交易费用（称为gas ）已经增长[14]，平均为0.20美元，最高达到1.00美元。 执行智能合同代码的交易成本更高，与执行多少计算成比例。
流行的公共区块链网络中的交易费用的增长，阻碍了他们直接处理小额支付的潜力，将小额支付推向支付通道等第二层解决方案。

#### 7.5. 以太坊交易成本

以太坊智能合约允许创建复杂的支付机制，利用以太坊虚拟机[85]（EVM）的能力和灵活性，在经济范围内提供图灵完整的执行环境。 以太坊智能合约执行的每条指令都会增加原始交易的交易费用。
每个EVM指令花费一定量的gas，以太坊交易费用定义为交易所花费的总gas量乘以发送方设置的gas价格。 矿工选择任何有效的交易纳入其开采块，可以包括交易与任何gas价格，包括零。 选择gas价较高的交易可能导致更多的利润，因为每个区块都有可以包含多少交易的限制。 同样，接受较低的gas价格也可能导致更多的利润，因为如果网络没有以最大容量运行，它可以允许矿工填满他们的区块。 这种机制创造了一个不断变化但稳定的博弈理论平衡，这个平衡被以太坊加油站这样的网站跟踪[15]。
截至2017年10月，在几个区块内获得高概率的交易成本为0.026美元。 要在15分钟内确认，$ 0.006就足够了。 这些估计是交易的基本成本 - 21,000gas，无需执行任何明智的合同代码即可进行简单的以太币转移交易。 如果交易执行智能合约代码，则每个EVM指令都会增加额外的gas成本。 例如，在智能合约存储中永久存储新的256位值需要花费20,000个gas，更新现有值需要花费5,000个gas。
作为Ethereum ERC20分类账本仅仅是账户地址到余额的映射，ERC20代币转账的成本应该是：新账户需要21,000 + 20,000gas，随后老账户转账需要21,000 + 5,000gas（因为收款人账户已经有了 代币分类帐本）。 观察现场[16] ERC20交易，我们看到gas成本稍高，约52,000和37,000gas转移到新的和现有的帐户。 不同之处在于智能合同代码执行不变式验证，例如发件人是否具有足够的余额以及其他实现细节（如付款收据的记录）。 50,000gas需要交易费用0.014美元至0.062美元之间，这取决于我们希望交易确认的速度。

#### 7.6. 兰花代币

兰花网络使用基于以太坊的ERC20代币，以满足不可伪造性，可用性和不可逆性的支付要求。 以下部分将讨论我们如何降低ERC20转帐的交易费用以实现任意小的代币数额。 匿名在7.17节中讨论。
兰花代币（OCT）用于兰花网络内的支付。 兰花代币是基于以太坊发行的固定供应量的ERC20代币。 供给固定在1×10^8个， 每个代币有1×10^18个不可分割的子单元（与Ether相同的可分解性）。
乍一看，以下部分详细介绍的兰花支付系统可以配置为使用Ether或任何ERC20代币。 事实上，使用以太币将简化票务合同，稍微降低交易费成本，提高可用性，因为用户只需要Ether，而不必同时购买兰花代币和Ether（交易费用）。
然而，以太坊计划未来的协议升级，允许交易费用由任意机制支付，包括ERC20代币[17] [18]。 这将消除使用新代币的大部分缺点; gas成本没有任何差别，用户只需要购买一个代币。 也可以将gas价格设置为零，并在合约执行中向采矿者添加ERC20代币付款（使用EVM COINBASE [85]操作码）[19]。 这需要矿工的明确支持，因为他们需要将其采矿策略配置为接受零gas价格，并验证交易执行包括将ERC20代币转移到coinbase地址。
但是，引入新的代币而不是简单地使用Ether的决定是出于社会经济而非技术原因。 通过创建一个新的代币，并使其成为兰花网络中唯一有效的支付选项，我们设计出了我们认为足够重要的社会经济效应，以保证增加的复杂性。

##### 7.6.1. 激励

激励是通过赋予人们对网络的部分所有权来引导新的协议和网络的一种方式[20]。
像兰花这样的新型去中心化网络受到鸡和鸡蛋的困扰。 代理和中继节点越多，网络为用户提供的实用程序就越多。 而用户越多，运行代理或中继节点就越有价值。 通过部署一个新的网络代币，可以加速网络效应，因为所有潜在的用户都被激励来尽早使用网络。

##### 7.6.2. 解耦

在去中心化系统中做去中心化系统，新的代币将新系统的市场价值从基础系统中分离出来。 例如，截至2017年10月，Ether的市值约为300亿美元，日均全球交易量为5亿美元[21]。 以太网的价格受多种因素影响，如加密货币的整体猜测，以太坊矿工的哈希能力以及以太坊建立的数百个项目的成败。 然而，单个项目的失败或成功可能不会对以太网的价格产生重大影响，但会对所涉及的项目具有显着的影响。 使用新的代币解耦市场价值，创造了一个更好的项目和系统的规模和健康的指标，有效地预测该市场的未来。

##### 7.6.3. 流动市场

对于系统特定的代币而言，流动性市场可以使严重依赖系统的用户通过做空仓位来对冲潜在的系统故障。 如果这看起来很远，我们应该注意到，金融衍生工具的初衷是允许企业对不幸的未来事件进行对冲。随着0x [22]和etherdelta [23]等去中心化交易以及Augur [24]和Gnosis [25]等预测市场的出现，基于以太坊的代币和系统的衍生品也不算太远。 事实上，这样的衍生工具可能比传统的金融衍生工具更有效[26]，因为前者没有信任方，没有权限，甚至可能是匿名的。

##### 7.6.4. 新代币

新的代币也可以更容易地为利益相关者设计具体的激励措施; 因为代币完全是从新系统中获得价值的，所以它们对任何为了系统成功而努力的人都是强有力的激励。 以太坊智能合约可以实现代币的自主锁定，以确保代币持有者只能根据定义的时间表访问其代币。 这种激励措施随着时间的推移而调整，并将代币持有者的重点放在系统的长期成功上，而不是像特定团队或相关公司这样的社会结构。 如果兰花网络使用了Ether，并且利益相关者被锁定了Ether，他们实际上会更加激励地为以太坊的整体成功而努力，而不是使用以太坊的任何特定系统。 可以认为，这样的结果将不是一个兰花网络和项目的最佳激励调整。

#### 7.7. 以太坊审查制度的抵制

与大多数公链类似，除非验证者（以太坊网络中的矿工）选择不将兰花交易打包，否则一定会对以太坊交易进行审查验证。由于所有矿工都是随机打包出块，与哈希能力成正比，这就要求大部分矿工主动审查兰花付款来保护兰花网络。例如，即使90％的算力选择不打包兰花相关的交易，兰花网络仍然会运作，只是交易所需的平均时间是正常的十倍。如果一大群51％的矿工选择通过拒绝包括他们在内的区块来审查兰花相关交易，那么更严格的审查形式就是如此[71]。根据以太坊协议规则，这是有效的，并有效地创建一个软分叉。但是，组织大规模的矿工勾结制造这样一个软叉有很大的利润损失风险;如果软叉未能获得足够的哈希能力，那么勾结的矿工就会错过他们的区块奖励。除了利润风险之外，考虑到以太坊矿工的去中心化性和对区块链采矿策略的法律和法规限制，我们认为这种可能性极小。

#### 7.8. 在宏支付上建立微支付

现在讨论交易成本和支付令牌的选择，现在让我们看看可行的支付方式。 以区块链为基础的小额支付面临的一个根本性挑战是如何避免交易费用。 想象一下，如果我们发送一分钱作为一个简单的以太坊ERC20交易，我们会支付1.4美分 - 140％的交易费每次支付！ 有效的小额支付要求降低交易费几个数量级。
在MojoNation [27]中采用的一个潜在有趣的方法是在每对节点之间建立一个“贸易平衡”。 当带宽在它们之间流动时，等交易费从0达到了一定的值时，它们会定期结算。 但是，正如我们所看到的，使用以太坊交易结算付款的交易成本至少会导致0.014美元的交易费用。 根据之前讨论的上限，我们可以看到这个价格大约等于140兆字节的带宽。 这种方法的第二个问题是，恶意邻近节点会知道这个事实，并试图断开连接并创建一个新的身份，而不是支付费用。

#### 7.9. 支付通道

在比特币网络上首次出现的区块链应用中流行的技术是支付通道[28]。由中本聪[66]部分描述，后来由Hearn和Spilman [29]定义和实施，支付通道后来由Poon和Dryja [ 30]把它应用在比特币闪电网络。支付通道允许发送者和接收者在彼此之间发送任意数量的交易，并且仅支付两笔交易的交易费 - 一个用于设置支付通道，另一个用于关闭它。这是通过首先让发送者发送一笔交易来锁定一些代币，这些代币可以被发送给收件人或发回给发送者。通常，代币只能在将来的某个时间T被发回给发送者。同时，代币可以（递增或全部）发送给接受者。发送者持续签署的交易花费越来越多的代币给收件人，并直接发送给收款人，无需发布在区块链上。收款人可以在任何时候，向区块链发布他们最后收到的交易要求汇总的金额， 直到时间T后，发送者没有意义，正式确定了他们多次协商后的交易。
支付通道为发款人提供一个有效的方式，为收款人提供连续付款的密码证据。 由于中间付款不会产生任何交易费用，所以可以随意小额付款，任意发送。 在实践中，瓶颈成为验证交易的计算开销以及发送它们的带宽要求。
尽管支付通道有效地为任意数量的中间支付提供了不变的交易费用复杂性，但不是在所有的情况下，这些支付通道效率有这么高。 特别是在有大量发送者和接收者的系统中，他们经常与他们互动，他们不断创建新的支付渠道可能太昂贵了。 同样，对于提供的非常小的或短期的服务（如单个HTTP请求或10秒的视频流），所需链上交易的交易费用可能太高。

#### 7.10. 概率支付

如果我们无法避免必须在区块链上做支付结算并产生交易手续费，那么理论上的最低成本就是单个交易的成本，因为区块链需要至少一个交易来执行状态转换。 为了解决一些（微）支付，我们至少需要一笔交易。
如果我们可以取消支付通道所需的设置交易（也就是为了建立通道而产生的第一笔交易），并且仍然能够向收件人证明他们正在获得付款，那该怎么办？
幸运的是，在区块链行业有一个类似的解决问题：矿池算力共享[31]。 随着像比特币这样的网络工作的工作难度的增加，矿工们开始将他们的计算能力集中在一起，以避免单个矿工花费数年的时间寻找块解决方案（也就是挖矿合适的nonce查找）来产生块。 矿池按矿工算力占矿池比率给予奖励，个别矿工通过哈希证明他们的哈希能力不断发送解决方[32]，在相同的区块上做哈希计算，但会选择一个较低的难度。 该技术使得矿池能够以密码方式验证每个池成员的哈希能力，而不管该池成员是否找到满足实际工作证明目标的解决方案。
如果我们将相同的思想应用于支付通道，我们可以构建概率支付方案，发件人不断向受方证明他们是平均支付的，而不管实际支付是否发生。 这使我们能够创建概率性的微支付，而不需要设置交易（闪电网络和雷电网络需要在建立通道时向区块链发送第一笔交易用于锁定定量的代币），接收者只需在“兑现”时支付交易费用。
在我们研究如何使用以太坊智能合约来构建这样的概率微支付之前，让我们退一步观察一下，概率支付的最初概念早于区块链技术，并于1996年由David Wheeler [84]首次发表。Wheeler描述了核心 概率支付的概念以及如何将其应用于使用随机数字承诺的电子协议，使得发件人和收件人（论文的术语中的买方和卖方）都不能操纵概率事件的结果，同时也证明他们之间的获胜的概率是多少。
有几篇论文跟随惠勒的想法，1997年Ronald Rivest [79]发表了一篇论文，描述了如何在电子微支付中应用概率支付。 2015年，Pass和Shelat [78]描述了如何将可能性微支付应用于比特币等去中心化货币，并指出先前的方案都依赖于可信的第三方。 第二年，Chiesa，Green，Liu，Miao，Miers和Mishra [59]将这项研究扩展到零知识证明，提供适用于加密货币协议的去中心化和匿名微支付。
鉴于最近在以太坊系统中支付通道的兴趣和普遍性，从支付通道的角度来看待可能的支付可能是有价值的。 为了省略第一次设置交易，我们失去了保证发送确切金额的能力，取而代之的只是一个概率保证。 然而，我们将通过调整支付概率，支付金额和支付频率来展示可能的小额支付，以便它们能够取代几类基于区块链的应用的支付通道，而不存在明显的缺陷。
从本质上讲，我们可以避免初始设置交易，我们可以从同一个发送者帐户中为任意数量的收件者支付任意小的服务会话，同时还向每个人证明支付金额的确切概率。假设服务提供商（兰花网络中的一个中继或代理节点）提供了足够的服务量，那么概率支出的变化就会很快达到平衡。

#### 7.11. 基于区块链的概率微支付

为了更容易地传达如何将概率支付应用于区块链协议的核心思想，我们将在这里详述几个细节。 在引用的原文中提供了对MICROPAY1方案的正式描述，而兰花的概率支付方案在7.12节。
Pass和Shelat描述了MICROPAY1 [78]，组合了数字签名和承诺方案，来达到发布精确概率的随机结果的条件。发件人首先通过将比特币转移到新生成的密钥的托管地址来进行“存款”。 然后，收款人（MICROPAY1条款中的商家）挑选一个随机数字，并将此号码的承诺发送给发款人。除了承诺，收款人还提供了一个新的比特币地址。发款人也挑选一个随机数字，并对这个数字（明文的形式），收款人的承诺和其他付款数据（如收件人提供的付款目的地地址）等一系列数据签名。
验证所产生的票据包括检查收款人的承诺是否符合他所披露的数字，以及验证发款人的签名是否与比特币存款的地址相符。如果来自发款人和收款人的随机数字的XOR的最后两位数字是00，那么票据通过验证，并且可以由收款人使用。
直觉上，我们可以把这个方案中的“抛硬币”看作是没有偏见的，除非发送方可以打破承诺的约束性（或伪造签名），或者用户可以打破承诺的隐藏性。
请注意，发款人可以通过向多个收款人并行的发行票据来“双花”其存款，通过在收款人看到票据声明前广播花费，达到在收款人之前发费该存款的目的。MICROPAY1的作者讨论了如何通过“惩罚托管”来解决这个问题，由发款人存入的第二笔金额做抵押，可以在未来某个时间点返回给发款人，但这笔抵押可以被任何可以为同一付款托管提交两张有效票据的人“削减”或“烧毁”。这可以防止发款人与收款人勾结或作为自己的收件人。
MICROPAY1的作者在MICROPAY2和MICROPAY3中构造了迭代改进，其中引入了一个可信方，在票据上执行一些计算验证步骤，并在计算正确的情况下释放签名。

#### 7.12. 兰花支付方案

现在我们已经为我们的支付找到了合适的抽象， 接下来是该如何去实施？
除了第7.1节中讨论的要求外，我们还要满足：

- 可重用性，构建每张新票据时不需要每一张票据都产生交易费或必须上链交易，否则交易费将再次成为问题。

- 必须防止双花， 否则会给收款人造成损失。

- 就计算成本而言，系统必须具有足够的性能，以免超出数据包的成本。

  ​

  在这些要求中，最后一个要素可能是最麻烦的。 据我们所知，不存在不需要按照验证ECDSA签名的顺序进行计算的方法在以太坊上构建彩票的dapp。正如本节所详细描述的，从发件人的要求来看，不仅要证明收件人的票据金额和获胜的可能性，而且还要求发件人的以太坊账户有足够数量被锁定的兰花代币作为发送的门票。

  ​

  出于这个原因，虽然单靠使用还不够，但我们不得不采用与上述类似的贸易平衡方法。这反过来导致了一个新的要求，即“贸易平衡必须保持足够小，以免在贸易过程中造成激励断开”。由于这是一个由实现实际问题而引起的机制设计问题，现在让我们通过假设一个解决方案来关注实现，并推迟到7.15节进一步的讨论。

  ​

  兰花支付方案受MICROPAY1和相关构造的启发，是一个伪造的匿名，概率微支付方案，。通过利用以太坊智能合约和代币锁定抵押惩罚机制，它可以减少运行前和并行（包括双花）支出攻击，而不需要可信任的第三方。兰花支付的伪匿名等同于在以太坊定期交易中可以实现的功能（尽管兰花客户使用额外的隐私技术，例如一次性地址和节点身份与支付地址之间的关键分离以实现有限的匿名）。

  ​

  MICROPAY2和MICROPAY3中引入的信任方可以被Ethereum智能合约代码有效替代。EVM允许在验证微支付票据时实现任意逻辑（在计算的经济范围内），并为ECDSA [70]恢复操作以及加密哈希函数提供原语[85]。

  ##### 7.12.1. 支付票据的定义

  兰花支付票据有如下字段：

  ```
  H(function) --- 哈希函数（更多细节在7.12.2）
  timestamp(uint32) --- Unix时间表示票据的值何时开始呈指数下降
  rand(uint256) --- 收件人选择的随机整数
  nonce(uint256) --- 票据发送者的随机整数
  faceValue(uint256) --- 赢得票据的值
  minValueMarket(uint256) --- 基于带宽市场的票据值
  minValueAccepted(uint256) ---  基于收件人所接受的内容的预期值
  winProb(uint256) --- 特定票据赢取发送者面值的概率
  recipient(uint160) --- 票据接收者在以太坊上160位以太坊账户地址
  randHash(uint256) --- 随机数哈希摘要
  ticketHash(uint256) --- randHash,recipient,faceValue,winProb,nonce的哈希摘要
  (v1,r1,s1)(tuple) --- 票据发送者的ECDSA签名元素
  (v2,r2,s2)(tuple) --- 接收者的ECDSA签名元素
  ```

##### 7.12.2. 支付票据加密库选择

为了降低兰花小额支付的成本，我们选择了某些密码功能，因为与其他任意函数相比，以太坊的gas成本降低了。
H — - Keccak-256 - 由于具有最低的gas成本（用于哈希32个字节需要花费36个gas[85]），所以在EVM中可用的所有哈希函数中花费是最低的。
ECDSA — secp256k1与Keccak-256，由于EVM支持ECDSA恢复此曲线以及兼容现有区块链软件库和工具。

##### 7.12.3. 生成支付票据

Alice 作为接收者，Bob 做为发送者。
-1. Alice挑选一个随机的256位数rand，计算randHash，并将摘要发送给Bob
-2. Bob 初始化参数（nonce, faceValue, winProb,recipient）
-3. Bob 计算票据哈希
-4. Bob 产生签名(私钥，票据hash)
-5. 票据定义后产生的内容：

```
(a) randHash
(b) recipient
(c) faceValue
(d) winProb
(e) nonce
(f) ticketHash
(g) creator (签名ticketHash的发件人密钥的地址)
(h) creatorSig (发件人对tickerHash的签名)
```

请注意，虽然此票据只要收件人可以完全验证就是有效的，但收件人需要对其签名（请参见下文），以便能够在以太坊上的兰花支付合约中声明。

##### 7.12.4. 支付合约的验证

Alice (带宽销售者) 可以执行下面的操作，

```
Verify:
(a) randHash == H(rand)
(b) faceValue >= minValueMarket
(c) winProb >= minValueAccepted
(d) recipient == {接收者公布的以太坊帐号地址}
(e) creator == {发送者公布的以太坊帐号地址}
Validate:
(a) Validate: 用公钥验证是否是该公钥对应的私钥所做的签名
Check:
(a)Validate: 交易发送者在兰花支付合约中锁定了足够的兰花代币
```

现在票据被证明是有效的，并且可能是一张中奖票

##### 7.12.5. 领取票据中的付款

虽然接收者可以在本地充分验证票据是否有效，并且如果它是中奖票据，中奖票据中代币的实际支付是通过兰花支付智能合约完成的。
这个智能合约公开了一个以输入为参数的Solidity API：

```
1. rand
2. nonce
3. faceValue
4. winProb
5. receipient
6. recipientSig (接收者对票据hash的签名)
7. creatorSig (发送者对ticketHash的签名)
```

##### 7.12.6. 合约的执行

假设Alice是希望购买带宽的用户。 Alice必须有一个以太坊帐户地址addressAlice和兰花代币。 请注意，该地址将具有关联的公钥PubKeyAlice。Alice还必须将兰花代币锁定在以前部分定义的以太坊智能合约中，并使用PubKeyAlice锁定。 在上一节中，Alice的地址就是以太坊帐户地址，等于从ticketHash上creatorSig恢复的公钥。
假设SLASH是一个临时布尔值，它被设置为FALSE，PubKey是通过ticketHash从recipientSig恢复的公钥，

```
计算：(a) ticketHash
验证：
(a) randHash; 如果不是， 结束执行。
(b) PubKey == recipient address; 如果不是，结束执行。
(c) addressAlice将代币锁在罚金托管账户。如果不是，结束执行。
(d) addressAlice已经有足够的兰花代币被锁定在门票帐户中以支付门票。 如果不是，则将SLASH设置为TRUE并继续执行。
(e) H(ticketHash, rand) <= winProb。 如果不是，结束执行。
判断:
(a) 如果SLASH == FALSE，则支付票款：faceValue从创建者的票据转移到收件人。
(b) 如果SLASH = TRUE，则创建者锁定的代币中扣减。
结算：
(a) 发送创建者的票据资金（如果有的话）给收件人（这是来自之前的验证，保证小于faceValue）。
(b) 将创建者的惩罚托管帐户设置为零（销毁/删除这些代币）。
```

请注意，虽然惩罚抵押机制消除了发送者潜在的双花作恶，但票据发送者仍然有大规模超支的危险。为了解决这个问题，获胜票据的额度应该在时间戳上呈指数下降，从而为获胜者立即兑现提供了强有力的激励。接收者可以使用这种直接性来计算发送者的兰花代币余额的“浪费率”。

#### 7.13. 兰花GAS成本

我们已经从上述方案的可靠性原型实施中测量了约87,000的gas成本。这个成本消耗在对获胜票据声明的API调用中。对票据合约的执行过程包括对兰花代币转账API的子调用。所有兰花智能合约在密码审查和外部安全审计之后， 会部署到以太坊主网并开源。

#### 7.14. 可验证的随机函数

通过用可验证的随机函数（VRF）替换接收者的随机数字承诺，可以减少前面部分中描述的支付票据的交互性。 由Micali，Rabin和Vadhan [80]于1999年首次发表，IETF VRF草案最近由Goldberg和Papadopoulos [33]提出。该草案规定了两种对VRF的构造，一个使用RSA，一个使用椭圆曲线（EC-VRF）。
使用VRF，兰花支付票据的发件人将能够在无需得到每个票据接收者的承诺。 相反，发件人只需要知道收件人的公钥。 发件人将用此公钥替换之前描述的票据方案中的随机数哈希。 为了提高效率，这可以是接收票据中已经存在的资金的接收方公钥，但要坚持密钥分离的密码原理，可能需要第二个密钥。
然而，验证兰花支付合约中的EC-VRF将需要明确的EVM加速椭圆曲线操作，因为直接以solidity语言或EVM 代码组装方式实施它们在gas成本方面将是非常昂贵的。
幸运的是，在以太坊 Byzantium [34]版本中，以太坊网络增加了对椭圆曲线标量加法和乘法的EVM支持[35]以及alt bn128曲线的配对检查[36]。 EC-VRF结构是针对任何椭圆曲线而定义的，IETF草案特别将EC-VRFP256-SHA256定义为EC-VRF密码组（其中P256是NIST-P256曲线[54]）。 但是，似乎没有理由 在同样足够安全的级别下，不去使用alt bn128曲线。 而且，SHA256可以用Keccak-256来代替。 这将允许在以太坊智能合约中进行VRF验证，从而与兰花智能合约进行整合。
然而，尽管在zcash中使用了alt bn128曲线，但是与P256相比，这是一个更年轻的曲线，并且没有被研究。 也许更重要的是，EC-VRF的构建是一个早期草案，正在等待审查，EVM拜占庭升级发生在撰写本文时，并且尚未在现场系统中证明具有重大价值。 因此，在兰花概率微支付中使用EC-VRF并不是立即可行的，兰花项目的目标是进一步研究使用，例如 可以先试用EVM验证的EC-VRF-ALTBN128-KECCAK256结构。

#### 7.15. 贸易平衡

如前所述，对称加密性能的现实阻碍了我们每个数据包的支付，所以我们需要很好地理解采用“贸易平衡”方法所固有的风险。 我们这样做的一般情况是：想象一下Alice和Bob希望以完全匿名的方式进行交易。 Bob要执行一些他所要求的任务，而Alice每工作一次就要付一次钱。 不幸的是，匿名的性质是这样的，没有事先交易，Alice和Bob没有机制互相信任。 他们能合作吗？
如果Alice和Bob的关系有一些启动成本（SAlice，SBob s.t. SAlice> xy，SBob> xy），答案是肯定的：逃避金钱或工作不再是经济上的理性，除非（1）Alice所要求的总工作量≤xy或（2）Bob能够完成的工作总量≤xy。正如我们在讨论兰花市场时（第11节）所看到的那样，兰花网上存在的启动成本超过1×103数据包就会贸易不平衡。因为兰花市场的卖家一般比买家支付更高的启动成本，而且由于客户不对称地知道需要多少工作，兰花网络有客户预付款。

#### 7.16. 改良

#### 7.17. 匿名

前面几节讨论的兰花支付与普通以太坊交易一样是伪匿名的; 所有交易都是公开的，包括金额以及发件人和收件人帐户。兰花客户旨在通过现代钱包技术（如一次性地址[37]和使用分层钱包[38]）来改进公共区块链交易的默认伪匿名性，并使用分层钱包[38]来提供尽管使用单个根密钥的支付地址的不可链接性。
随着以太坊拜占廷版本的发布，现在可以通过利用新的EVM椭圆曲线原语操作码来实现具有合理gas成本的可链接环签名[39]。 将以太坊智能合约与隐藏地址（如HD钱包和可链接环签名提供的地址）相结合，可实现一类混合技术，如M¨obius [74]混合服务。如M¨obius提供了强大的匿名性保证，通过使用基于博弈的安全模型对混合服务进行密码验证。然而，与以前的混合技术不同的是，它提供了针对恶意观察者和发送者的匿名，而不是针对恶意接收者。 将M¨obius等服务与兰花概率小额支付相结合，使我们更接近于我们对付款的最终要求 - 匿名。
为了实现完全匿名保证，防止任何恶意行为者，无论是观察员，发送者还是接收者，我们都要依靠零知识证明技术。
在zcash网络[40]中应用的zk-SNARK [47]技术与环签名相比可以提供更强的匿名性保证。 在zcash中，屏蔽地址之间的交易提供了发送者，接收者和金额的完全匿名。

#### 7.18. 非交互式

在7.14节中，我们表明，通过用VRF替换兰花付款方案中的随机数承诺，通过去除与随机数承诺相关联的通信步骤使得该方案更加非互动。 接收方不必在发送者构造票据之前将承诺传达给发送者，而只需从公开的接收方信息中立即构建票据单。
每个接收者将生成一个专门用于VRF的新密钥对，并将公钥与其他公共接收者信息一起发布，详见11.1节。发送者只需在票据中配置该公钥，而收件人将使用相应的私钥对收到的票据进行签名。在7.12.4节中定义的票据验证逻辑将把接收者VRF签名解释为它与获胜概率阈值进行比较的值。
正如7.14节所讨论的那样，虽然这将是对支付方案的相对简单的修改，但在EVM中验证VRF的可行性需要进一步的研究。

#### 7.19. 性能

虽然兰花智能合约是不可变的，但是他们可以通过部署新的合约和升级兰花客户端软件来指向他们（如果有需要的话也可以向后兼容旧合约）来有效地进行升级。以太坊智能合约支持多层优化以降低gas成本，我们预计兰花支付智能合约的未来版本将使用 例如EVM 原语[41]（也就是预编译的代码）来优化gas成本，类似于常规软件系统常常用内联组装代替昂贵的子程序。
然而，兰花支付票据的验证瓶颈是诸如ECDSA recovery 等密码学相关操作的执行以及兰花代币发送者和接收者的以太坊账户的状态更新。在这里，一个改进可能是两次使用接收者对有效数据交易的签名。 目前，由于兰花客户灵活性的原因，兰花计划在那里定义了两个签名，并且使得在不依赖以太坊细节的情况下更容易指定和推理付款方案。 更简单的优化包括紧密包装票据字段并将单个256位字中的多个内部变量进行编码，以与EVM堆栈字和永久契约存储插槽（均为256位）对齐。
另一方面，为了实现更大的匿名性，可选或甚至强制使用混合技术可能会大大增加兰花支付合约的gas成本。 使用基于可链接环签名的混合服务很容易导致大约高出一个数量级的交易费用[39]。但是，这能提供给用户强有力的匿名保证，用户可能会觉得这是值得的。 因为我们可以很容易地调整兰花支付的概率变量 - 票据频率，获胜概率和获胜金额 - 我们可以调整票证之间的平均时间来减少交易费用（特别是对于长期运行的节点，可以隔个几天才做结算一次）。
最后，零知识技术如zk-SNARKs的一个非常有趣的属性是大大减少任意计算的计算开销，如以太坊智能合约执行[42]。虽然生成zk-SNARK证明是昂贵的，但验证更便宜 - 甚至与原始代码相比。 由于只有验证需要在链上执行，所以在兰花票据中采用零知识证明比原始验证码更便宜。
进一步来说，递归SNARKs [52]有可能将一组SNAK证明集合成一个证明。虽然它们可能更适用于区块链共识协议[43]，但它们也可能对兰花协议有用，例如 将多个票据索赔批量化为单个智能合约交易，同时避免线性gas成本叠加。

### 8. 带宽挖矿

![ ](https://gguoss.github.io/img/%E5%B8%A6%E5%AE%BD%E6%8C%96%E7%9F%BF.png)
在这章我们将描述中继的规则和代理的行为，以及讨论这些无法审查的，匿名网页浏览的节点如何“连接在一起的“

#### 8.1. 带宽销售规范

中继节点实现相对简单的行为模式如下：

- 保持一个或多个连接，每个都有自己的加密密钥。

- 检查收到的任何票据和获得的入账。

- 监控交易的平衡，如果超过预先确定的额度，则断开连接。

- 从任何打开的连接接收数据，并在消息边界执行解密。

- 处理解密消息如下:

  ​

  —将任何非控制段转发到消息中指定的连接。

  ​

  —处理控制字段如下：

  ```
  * 空数据。 指示中继丢弃这个字段。
  * 数据转发速率。指示中继以固定速率通过链接发送数据，根据需要对数据包进行排队并生成数据以保持速率。
  * 棘轮票据。指示中继将一个票据传递给一个对等节， 该对等节点是原来数据来源点。
  * 初始化链接。 指示当建立和断开链接的过程时，中继建立一个新链接。
  * 初始化网页链接。（仅限代理）指示代理打开指定主机的SSL连接。为了支持白名单，这不能是一个原生IP地址。
  ```

上述行为中的一个重要考虑是需要中继节点持续不断地的工作证明。当与我们所有的WebRTC链接结合起来时，网站就可能通过运行纯粹的JavaScript中继代码来获利。
有关通过控制字段扩展应用程序的讨论，请参见第15节。

#### 8.2. 节点保护和“带宽燃烧“

客户连接的中继有一个非常重要的信息：客户的IP地址。 我们假设客户希望尽可能保持私密性，所以默认的客户端会长时间作为第一跳对等节点。
另一个关于第一跳节点的问题，我们在讨论由共谋（9.2节）引起的信息攻击方面进行了深入的讨论，他们坐在一个理想的位置来执行定时攻击。为了防止这些攻击，我们建议有隐私意识的用户采用一种称为“带宽燃烧”的方法，向第二跳节点支付金额来获得固定数量的带宽。由于这种方法使用的数据会和网络使用的数据完全不相关，从而可以防止攻击者无法看到中继3的入站流量。
为了给寻求逃避的用户提供帮助（第12节），带宽燃烧也将支持由流行的非兰花WebRTC协议的统计特性确定的非固定速率。

#### 8.3. 链路

对使用中继进行匿名访问感兴趣的客户将使用上述规范来创建中继的“链路”。

### 9. 链路串谋攻击

在本节中，我们将探讨攻击者可以通过控制或监视多个中继和/或互联网服务提供商（ISP) 来推断或推导哪些类型的信息。假定中继和代理是随机选择（ISP也同样做此假定），我们建立了一个给定攻击可能以不同链长进行的概率模型。

#### 9.1. 个人中继和代理有用的信息

由于基于IP的网络固有结构以及兰花协议使用基于以太坊的支付，中继和代理节点及其入侵防御系统可以访问以下信息

- 他们所连接的所有计算机的IP地址。

- 他们转发的数据包的大小，时间和数量。

- 控制支付代币的公钥。

- 针对它们的数据包控制字段的内容。
  此外，代理节点及入侵防御系统可以访问以下信息：

- Web服务器的主机名和SSL / TLS会话协商的明文部分。

  #### 9.2. 潜在的合谋者

  在兰花网络中， 以下的角色可能被攻击者监视或者串谋：

- 互联网服务提供商以客户，中继，代理，web服务器的角色加入兰花网络。不可靠概率用s表示。

- 网站。 链接到代理的网站服务器。 不可靠概率用w表示。

- Relayn。 链路中的第n个中继节点。 不可靠概率用r/n 表示。

- 代理。 有流量通过中继到网站服务器的代理。不可靠概率用x/n 表示。

  ​

  我们已经分离出上面的r和x，原因是：虽然攻击者无法控制他们可用于计算工作量计算的总计算量，但他们可以控制如何在中继和代理节点之间分配计算。

  #### 9.3. 攻击类型

  共谋攻击的核心目标是将特定的兰花客户与特定的SSL连接相链接。 主要可以采用如下方法：

- 关系。攻击者可以通过观察消息路由过程中的节点来推断出一个客户正在和一个给定的网站通话。

- 记时。 攻击者可以通过控制并观察数据包的时间规律来推断客户正在与给定网站通话。

- 未燃烧的带宽花费。 尽管客户可以使用带宽燃烧的方式掩盖自己的流量，但攻击者仍然可以执行定时攻击。

  #### 9.4. “常规”互联网访问：零中继，零代理

  虽然当客户直接连接网站时，兰花系统不被使用，但我们在接下来的类容会分析在客户启动中存在的风险。

  ![img](https://gguoss.github.io/img/OrchidAccess.png)

  在上表中，“X”表示参与共谋，互联网服务商 有x的概率采用关系攻击类型。网站有w的概率采用关系攻击类型。

  #### 9.5. VPN: 零中继， 零代理

  为了进行分析，我们也提出了VPN访问固有的合谋风险

  g是VPN提供商被监控或者与对手勾结的可能性。 请注意，g可能会随着时间的推移而变化导致难以建模，例如，由于您的VPN使用情况。

  #### 9.6. 零中继，一个代理

  毫无疑问，这种情况下的风险与VPN使用的风险很相似。 不使用中继的链相当于在每个浏览会话之前随机选择新的VPN提供商的VPN，并且VPN提供商不存储个人信息。

  #### 9.7. 一个中继，一个代理

  如果在这种配置中使用带宽燃烧，所有的定时攻击都会被缓解。

### 15. 未来的工作

本节中的内容分为两类：好的方面和我们像公众展示的内部矛盾特征。不够我们相信这种矛盾都是很普遍的——虽然几乎所有人都有一个自己最喜欢的将权利用作歧途的例子，但是同样也有无数的将权利用作正途的例子。兰花这种协议是没有自己的判断力，无法告知它被自由战士，还是被恐怖分子，坏人还是英雄所用。

#### 15.1. 空间证明

如第5节所述，我们非常有兴趣探索其他证明类型。这是一个重要的问题，因为工作证明系统的环境影响，以及我们目前的工作证明算法要求全面的计算机充当网络路由器。
我们很高兴能够探索使用磁盘空间成为我们安全核心的稀缺资源的可能性，这可能会让旧手机或类似硬件有利地参与到兰花网络中。

#### 15.2. 内容主机的保护

许多先前的方法（第3节）发现内容主机寻求与网络用户类似的保护。我们在这方面内部是有矛盾的，因为我们确实认为有一些内容不符合公共利益（例如有关制造核武器的信息）。但是，如果情况不符合要求，兰花可以扩展到支持这种“无限制的，未受到威胁的主机”，如下图所示：
![img](https://gguoss.github.io/home/gavin/work/shell/blog/themes/yilia/source/img/OrichidFigure3.png)

#### 15.3. 以太坊支付模块的安全保证

正如我们在防火墙规避部分（第12节）中所讨论的，客户端的以太坊网络流量很可能是安全的薄弱环节。因为所有的节点都必须维护这个信息，所以使用兰花协议来
分发以太坊信息似乎是天作之合。
不幸的是，依靠那些你正在付钱的信息会导致棘手的问题。我们希望在不久的将来添加处理这个问题的功能，但不会在我们最初发布的版本加入此功能。

#### 15.4. 兰花平台

尽管我们预计核心系统的设计将在不久的将来占用我们大部分的时间，我们也会添加以下用例的相关的功能， 因为这样做， 可以为兰花网络增加大量的流量。

- 1.直接访问网络的API接口加入代币服务。
- 2.网络上的文件存储和静态网站托管。
- 3.文件共享。
- 4.电子邮件/消息服务。
- 5.仲裁/调解服务。



[TOC]

## **0 摘要**

当前互联网正处于一场革命中：集中式专有服务正在被去中心化开放服务所代替；信任式参与被可验证式计算所代替；脆弱的位置寻址被弹性的内容寻址所代替；低效率的整体式服务被点对点算法市场所代替；比特币、以太坊和其他的区块链网络已经证明了去中心化交易账本的有效性。这些公共账本处理复杂的智能合约应用程序和交易价值数百亿美金的加密资产。这些系统的参与者们形成去中心化的、没有中心管理机构或者可信任党派的网络提供了有用的支付服务，这是广泛互联网开放服务的第一个实例。IPFS通过分散的网页自身已经证明了内容寻址的有效性，它提供了全球点对点网络数十亿文件使用。它解放了孤岛数据，网络分区存活，离线工作，审查制度路线，产生了持久的数字信息。

Filecoin是一个去中心化存储网络，它让云存储变成一个算法市场。这个市场运行在有着本地协议令牌（也叫做Filecoin）的区块链。区块链中的旷工可以通过为客户提供存储来获取Filecoin,相反的，客户可以通过花费Filecoin来雇佣旷工来存储或分发数据。和比特币一样，Filecoin的旷工们为了巨大的奖励而竞争式挖区块，但Filecoin的挖矿效率是与存储活跃度成比例的，这直接为客户提供了有用的服务（不像比特币的挖矿仅是为了维护区块链的共识）。这种方式给旷工们创造了强大的激励，激励他们尽可能多的聚集存储器并且把它们出租给客户们。Filecoin协议将这些聚集的资源编织成世界上任何人都能依赖的自我修复的存储网络。该网络通过复制和分散内容实现鲁棒性，同时自动检测和修复副本失败。客户可以选择复制参数来防范不同的威胁模型。该协议的云存储网络还提供了安全性，因为内容是在客户端端对端加密的，而存储提供者不能访问到解密秘钥。Filecoin的成果作为可以为任何数据提供存储基础架构的IPFS最上面的激励层。它对去中心化数据，构建和运行分布式应用程序，以及实现智能合同都非常有用。

这些工作包括以下几部分内容：

（a)介绍Filecoin网络，概述这个协议以及详细介绍几个组件。

（b)形式化去中心化存储网络（DSN)的计划与内容，然后构建Filecoin作为一个DSN。

（c)介绍一种叫“复制证明”的新型存储证明方案，它允许验证任何数据副本都存储在物理上独立的存储器中。

（d)介绍一种新型的以基于顺序复制和存储作为激励度量的有用工作共识。

（e)形成可验证市场，并构建两个市场，存储市场和检索市场，它们分别管理如何从Filecoin写入和读取数据。

（f)讨论用例，如何连接其他系统以及如何使用这个协议。

*注意：Filecoin是一项正在进行的工作。正在进行积极的研究，本文的新版本将会出现在https://filecoin.io*

*如有意见和建议，请通过research@filecoin.io与我们联系*



## **1 介绍**

Filecoin是一种协议令牌，其区块链运行在一种叫“时空证明”的新型证明机制上，其区块被存储数据的矿工所挖。Filecoin协议通过不依赖于单个协调员的独立存储提供商组成的网络提供数据存储服务和数据检索服务。其中：

1. 用户为数据存储和检索支付令牌
2. 存储矿工通过提供存储空间赚取令牌
3. 检索矿工通过提供数据服务赚取令牌



### **1.1 基本组件**

Filecoin协议由四个新型组件组成

1. 去中心化存储网络(Decentralized Storage Network)(DSN)：我们提供一个由提供存储和检索服务的独立服务商网络的抽象（在第二节）。接着我们提出了Filecoin协议作为激励，可审计和可验证的DSN构建（在第4节）。
2. 新型的存储证明：我们提出了两种新型存储证明方案（在第三节）：（1）“复制证明”（Proof-of-Replication）允许存储提供商证明数据已经被复制到了他自己唯一专用的物理存储设备上了。执行唯一的物理副本使验证者能够检查证明者是否不存在将多个数据副本重复拷贝到同一存储空间。（2）“时空证明”（Proof-of-Spacetime）允许存储提供商证明在指定的时间内存储了某些数据。
3. 可验证市场：我们将存储请求和检索需求作为两个由Filecoin网络操作的去中心化可验证市场的订单进行建模（在第五节）。验证市场确保了当一个服务被正确提供的时候能执行付款。我们介绍了客户和矿工可以分别提交存储和检索订单的存储市场和检索市场。
4. 有效的工作量证明（Proof-of-Work）：我们展示了如何基于“时空证明”来构建有效的工作量证明来应用于共识协议。旷工们不需要花费不必要的计算来挖矿，但相反的必须存储数据于网络中。

### **1.2 协议概述**

- Filecoin协议是构建于区块链和带有原生令牌的去中心化存储网络。客户花费令牌来存储数据和检索数据，而矿工们通过提供存储和检索数据来赚取令牌。
- Filecoin DSN 分别通过两个可验证市场来处理存储请求和检索请求：存储市场和检索市场。客户和矿工设定所要求服务的价格和提供服务的价格，并将其订单提交到市场。
- 市场由Filecoin网络来操作，该网络采用了“时空证明”和“复制证明”来确保矿工们正确存储他们承诺存储的数据。
- 最后，矿工们能参与到区块链新区块的锻造。矿工对下一个区块链的影响与他们在网络中当前存储使用量成正比。

*图一是使用了术语定义之后的Filecoin协议草图，伴随着一个例子如图2所示*

![filecoin-图1.png](http://chainx.org/Uploads/Editor/Picture/2017-08-22/599bd972e4cc5.png)

![filecoin-图2.png](http://chainx.org/Uploads/Editor/Picture/2017-08-22/599bd98383339.png)

### **1.3 论文组织**

本文的其余部分安排如下：我们在第二节中介绍了对一个理论上的DNS方案的定义和需求。在第三节中我们定义和介绍我们的“复制证明”和“时空证明”协议，以及Filecoin将其用于加密地验证数据按照订单的要求被持续不断的存储。第四节描述了Filecoin DSN的具体实例，描述了数据结构，协议，以及参与者之间的交互。第5节定义和描述可验证市场的概念，还有存储市场和检索市场的实施。第6节描述了使用“时空证明”协议进行演示，并且评估矿工对网络的贡献，这对扩展区块链块和区块奖励是必要的。第7节简要介绍了Filecoin中的智能合约。在第8节中讨论了未来的工作作为结束。



## **2 去中心化存储网络的定义**

我们介绍了去中心化存储网络（DSN）方案的概念。DSNs聚集了由多个独立存储提供商提供的存储，并且能自我协调的提供存储数据和检索数据服务给客户。这种协调是去中心化的、无需信任的：通过协议的协调与个体参与者能实施验证操作，系统可以获得安全性操作。DSNs可以使用不同的协调策略，包括拜占庭协议，gossip协议或者CRDTs，这取决于系统的需求。在后面，第四节，我们提供Filecoin DSN的的一个构建。

**定义 2.1**

*DSN方案(Π)是由存储提供商和客户运行的协议元组: (Put, Get, Manage)*

- Put(data) → key: 客户端执行Put协议以将数据存储在唯一的标识符秘钥下。

- Get(key) → data: 客户端执行Get协议来检索当前使用秘钥存储的数据。

- Manage(): 网络的参与者通过管理协议来协调：控制可用的存储，审核提供商提供的服务并修复可能的故障、

  管理协议由存储提供商来运行，并且经常与客户或者审计网络结合（在管理协议依赖区块链的情况下，我们认为矿工是审计人员，因为他们验证和协调存储提供商）。

DSN方案(Π)必须保证数据的完整性和可恢复性，并且能够容忍在后面章节中所定义的管理和存储故障。

### **2.1 故障容错**

#### **2.1.1 管理故障**

我们将管理故障定义为管理协议的参与者引起的拜占庭故障。一个DSN方案依赖于它的基础管理协议的故障容错。违反故障容错的管理故障假设可能会影响系统的活跃度和安全性。

例如，考虑一个DSN方案，其中管理协议要求拜占庭容错来审核存储提供商。在这样的协议中，网络收集到来自存储提供商的存储证明，并运行拜占庭容错对这些证明的有效性达成共识。如果在总共n个节点中，拜占庭容错最多容忍f个故障节点。那么我们的DSN可以容忍f<n/2 个故障节点。在违反了这些假设的情况下，审计上就要做出妥协。

#### **2.1.2 存储故障**

我们将存储故障定位为拜占庭故障，阻止了客户检索数据。例如存储矿工丢失了他们的数据，检索矿工停止了他们的服务。一个成功的Put操作的定义是(f,m),既是它的输入数据被存储在m个独立的存储提供商（总共有n个）中，并且它可以容忍最多f个拜占庭存储提供商。参数f和m取决于协议的实现。协议设计者可以固定f和m，或者留给用户自己选择。将Put(data) 扩展为Put(data,f,m)。如果有小于f个故障存储提供商，则对存储数据的Get操作是成功的。

例如，考虑一个简单的方案。它的Put协议设计为每个存储提供商存储所有的数据。在这个方案里，m=n,并且f=m-1。但总是f=m-1吗，不一定的，有些方案可能采用可擦除式设计，其中每个存储供应商存储数据的特定部分，这样使得m个存储供应商中的x个需要检索数据，在这种场景下f=m-x。

### **2.2 属性**

我们描述DSN方案所必须的两个属性，然后提出Filecoin DSN所需要的其他属性。

#### **2.2.1 数据完整性**

该属性要求没有有限的对手A可以让客户在Get操作结束的时候接受被更改或者伪造的数据。

**定义 2.2**

*一个DSN方案(Π)提供了数据完整性：如果有任意成功的Put操作将数据d设置在键k下，那不存在计算有限的对手A能使得客户在对键k执行Get操作结束的时候接受d‘，其中d' 不等于d。*

#### **2.2.2 可恢复性**

该属性满足了以下要求：考虑到我们的Π的容错假设，如果有些数据已经成功存储在Π并且存储提供商继续遵循协议，那么客户最终能够检索到数据。

**定义2.3**

*一个DSN方案(Π)提供了可恢复性：如果有任意成功的Put操作将数据d设置在键k下，且存在一个成功的客户Get操作通过对键K执行检索得到数据（这个定义并不保证每次Get操作都能成功，如果每次Get操作最终都能返回数据，那这个方案是公平的）。*

### **2.3 其他属性**

DSNs可以提供特定于其应用程序的其他属性。我们定义了Filecoin DSN所需要的三个关键属性：公开可验证性、可审查性和激励兼容性。

**定义2.4**

*一个DSN方案(Π)是公开可验证的：对于每个成功的Put操作，存储网络的供应商可以生成数据当前正在被存储的证明。这个存储证明必须说服任何只知道键但并不能访问键所对应的数据的有效验证者。*

**定义2.5**

*一个DSN方案(Π)是可审查的：如果它产生了可验证的操作轨迹，并且在未来能被检查在正确的时间上数据确实被存储了。*

**定义2.6**

*一个DSN方案(Π)是激励可兼容的：如果存储提供商由于成功提供了存储数据和检索数据的服务而获得激励，或者因为作弊而得到惩罚。所有存储提供商的优势策略是存储数据。*



## **3 复制证明与时空证明**

在Filecoin协议中，存储供应商必须让他们的客户相信，客户所付费的数据已经被他们存储。在实践中，存储供应商将生成"存储证明"(POS)给区块链网络（或客户自己）来验证。

在本节中，我们介绍和概述在Filecoin中所使用的“复制证明”n (PoRep)和“时空证明”(PoSt)实现方案。

### **3.1 动机**

存储证明(POS)方案类似“数据持有性验证”(PDP)[2]和“可恢复性证明”(PoR)[3,4]方案。它允许一个将数据外包给服务器（既证明人P)的用户（既验证者V)可以反复检查服务器是否依然存储数据D。用户可以用比下载数据还高效的方式来验证他外包给服务器的数据的完整性。服务器通过对一组随机数据块进行采样和提交小量数据来生成拥有的概率证明作为给用户的响应协议。

PDP和PoR方案只保证了证明人在响应的时候拥有某些数据。在Filecoin中，我们需要更强大的保障能阻止作恶矿工利用不提供存储却获得奖励的三种类型攻击：女巫攻击(Sybil attack)、外包攻击(outsourcing attacks)、代攻击？（generation attacks）。

- 女巫攻击：作恶矿工可能通过创建多个女巫身份假装物理存储很多副本（从中获取奖励），但实际上只存储一次。
- 外包攻击：依赖于可以快速从其他存储提供商获取数据，作恶矿工可能承诺能存储比他们实际物理存储容量更大的数据。
- 代攻击：作恶矿工可能宣称要存储大量的数据，相反的他们使用小程序有效地生成请求。如果这个小程序小于所宣称要存储的数据，则作恶矿工在Filecoin获取区块奖励的可能性增加了，因为这是和矿工当前使用量成正比的。

### **3.2 复制证明**

“复制证明”(PoRep)是一个新型的存储证明。它允许服务器（既证明人P)说服用户（既验证者V）一些数据D已被复制到它唯一的专用物理存储上了。我们的方案是一种交互式协议。当证明人P:（a）承诺存储某数据D的n个不同的副本（独立物理副本），然后（b）通过响应协议来说服验证者V，P确实已经存储了每个副本。据我们所知PoRep改善了PDP和PoR方案，阻止了女巫攻击、外包攻击、代攻击。

*请注意，正式的定义，它的属性描述，和PoRep的深入研究，我们参考了[5]*

**定义3.1**

*PoRep方案使得有效的证明人P能说服验证者V，数据D的一个P专用的独立物理副本R已被存储。PoRep协议其特征是多项式时间算法的元组：* *(Setup, Prove, Verify)*

- PoRep.Setup(1λ, D) → R, SP , SV , 其中SP和SV是P和V的特点方案的设置变量，λ是一个安全参数。PoRep.Setup用来生成副本R，并且给予P和V必要的信息来运行PoRep.Prove 和 PoRep.Verify。一些方案可能要求证明人或者是有互动的第三方去运算PoRep.Setup。
- PoRep.Prove(SP , R, c) → πc，其中c是验证人V发出的随机验证， πc是证明人产生的可以访问数据D的特定副本R的证明。PoRep.Prove由P（证明人）为V（验证者）运行生成πc。
- PoRep.Verify(Sv , c, πc) → {0, 1}，用来检测证明是否是正确。PoRep.Verify由V运行和说服V相信P已经存储了R。

### **3.3 时空证明**

存储证明方案允许用户请求检查存储提供商当时是否已经存储了外包数据。我们如何使用PoS方案来证明数据在一段时间内都已经被存储了？这个问题的一个自然的答案是要求用户重复（例如每分钟）对存储提供商发送请求。然而每次交互所需要的通信复杂度会成为类似Filecoin这样的系统的瓶颈，因为存储提供商被要求提交他们的证明到区块链网络。

为了回答这个问题，我们介绍了新的证明，“时空证明”，它可以让验证者检查存储提供商是否在一段时间内存储了他/她的外包数据。这对提供商的直接要求是：（1）生成顺序的存储证明（在我们的例子里是“复制证明”）来作为确定时间的一种方法 （2）组成递归执行来生成简单的证明。

**定义3.2**

*（时空证明）Post方案使得有效的证明人P能够说服一个验证者V相信P在一段时间内已经存储了一些数据D。PoSt其特征是多项式时间算法的元组： *(Setup, Prove, Verify)*

- PoSt.Setup(1λ,D)->Sp，Sv，其中SP和SV是P和V的特点方案的设置变量，λ是一个安全参数。PoSt.Setup用来给予P和V必要的信息来运行PoSt.Prove 和 PoSt.Prove。一些方案可能要求证明人或者是有互动的第三方去运算PoSt.Setup。
- PoSt.Prove(Sp , D, c, t) → πc，其中c是验证人V发出的随机验证， πc是证明人在一段时间内可以访问数据D的的证明。PoSt.Prove由P（证明人）为V（验证者）运行生成πc。
- PoSt.Verify(Sv , c, t, πc) → {0, 1}，用来检测证明是否是正确。PoSt.Verify由V运行和说服V相信P在一段时间内已经存储了R。

### **3.4 PoRep和PoSt实际应用**

​    我们感兴趣的是PoRep和PoSt的应用构建，可以应用于现存系统并且不依赖于可信任的第三方或者硬件。我们给出了PoRep的一个构建（请参见基于密封的复制证明[5]),它在Setup过程中需要一个非常慢的顺序计算密封的执行来生成副本。PoRep和PoSt的协议草图在图4给出，Post的底层机制的证明步骤在图3中。

![filecoin-图3.png](http://chainx.org/Uploads/Editor/Picture/2017-08-22/599bda2a16ed6.png)

![filecoin-图4.png](http://chainx.org/Uploads/Editor/Picture/2017-08-22/599bda34b254b.png)

#### **3.4.1 构建加密区块**

**防碰撞散列** 我们使用一个防碰撞的散列函数：CRH : {0, 1}* → {0, 1}O(λ)。我们还使用了一个防碰撞散列函数MerkleCRH，它将字符串分割成多个部分，构造出二叉树并递归应用CRH，然后输出树根。

**zk-SNARKs** 我们的PoRep和PoSt的实际实现依赖于零知识证明的简洁的非交互式知识论（zk-SNARKs)[6,7,8]。因为zk-SNARKs是简洁的，所以证明很短并且很容易验证。更正式地，让L为NP语言，C为L的决策电路。受信任的一方进行一次设置阶段，产生两个公共密钥：证明密钥pk和验证密钥vk。证明密钥pk使任何（不可信）的证明者都能产生证明证明π，对于她选择的实例x，x∈L。非交互式证明π是零知识和知识证明。任何人都可以使用验证密钥vk验证证明π。特别是zk-SNARK的证明可公开验证：任何人都可以验证π，而不与产生π的证明者进行交互。证明π具有恒定的大小，并且可以在| x |中线性的时间内验证。

可满足电路可靠？的zk-SNARKs是多项式时间算法的元组：*(KeyGen, Prove, Verify)*

- KeyGen(1λ,C)→ (pk, vk)，输入安全参数λ和电路C，KeyGen产生概率样本pk和vk。这两个键作为公共参数发布，可在Lc上用于证明/验证。
- Prove(pk, x, w) → π 在输入pk、输入x和NP声明w的见证时，证明人为语句x∈LC输出非交互式证明π。
- Verify(vk, x, π) → {0, 1} 当输入vk，输入x和证明 π，验证者验证输出1是否满足x ∈ LC。

我们建议感兴趣的读者参看[6，7，8]对zk-SNARK系统的正式介绍和实现。

通常而言这些系统要求KeyGen是由可信任参与方来运行。创新的可扩展计算完整性和隐私（SCIP）系统[9]展示了在假设信任的前提下，一个有希望的方向来避免这个初始化步骤。

#### **3.4.2 密封操作**

密封操作的作用是（1）通过要求证明人存储对于他们公钥唯一的数据D的伪随机排列副本成为物理的独立复制，使得提交存储n个副本导致了n个独立的磁盘空间（因此是副本存储大小的n倍）和（2）在PoRep.Setup的时候强制生成副本实质上会花费比预计响应请求更多的时间。有关密封操作的更正式定义，请参见[5]。上述的操作可以用SealτAES−256来实现，并且τ使得SealτAES−256需要花费比诚实的证明验证请求序列多10-100倍的时间。请注意，对τ的选择是重要的，这使得运行SealτBC比证明人随机访问R花费更多时间显得更加明显。

#### **3.4.3 PoRep构建实践**

这节描述PoRep协议的构建并已在图4包括了一个简单协议草图。实现和优化的细节略过了。

**创建副本** Setup算法通过密封算法生成一个副本并提供证明。证明人生成副本并将输出（不包括R)发送给验证者。

Setup

- inputs:

  – prover key pair (pkP ,skP )

  – prover SEAL key pkSEAL

  – data D

- outputs: replica R, Merkle root rt of R, proof πSEAL

**证明存储** Prove算法生成副本的存储证明。证明人收到来自验证者的随机挑战，要求在树根为rt的Merkle树R中确认特定的叶子节点Rc。证明人生成关于从树根rt到叶子Rc的路径的知识证明。

Prove

- inputs:

  – prover Proof-of-Storage key pkPOS

  – replica R

  – random challenge c

- outputs: a proof πPOS

**验证证明** Verify算法检查所给的源数据的哈希和副本的Merkle树根的存储证明的有效性。证明是公开可验证的：分布式系统的节点维护账本和对特定数据感兴趣的可以验证这些证明。

Verify

- inputs:

  – prover public key, pkP

  – verifier SEAL and POS keys vkSEAL, vkPOS

  – hash of data D, hD

  – Merkle root of replica R, rt

  – random challenge, c

  – tuple of proofs, (πSEAL, πPOS)

- outputs: bit b, equals 1 if proofs are valid

#### **3.4.4 PoSt构建实践**

这节描述Post协议的构建并已在图4中包含了一个简单协议草图。实现和优化的细节略过了。

Setup和Verify算法和上面的PoRep构建是一样的。所以我们这里值描述Prove。

**空间和空间的证明** Prove算法为副本生成“时空证明”。证明人接收到来自于验证者的随机挑战，并顺序生成”复制证明“，然后使用证明的输出作为另一个输入做指定t次迭代（见图3）。

Prove

- inputs:

  – prover PoSt key pkPOST

  – replica R

  – random challenge c

  – time parameter t

- outputs: a proof πPOST

### **3.5 在Filecoin的应用**

Filecoin协议采用”时空证明“来审核矿工提供的存储。为了在Filecoin中使用PoSt，因为没有指定的验证者，并且我们想要任何网络成员都能够验证，所以我们把方案改成了非交互式。因为我们的验证者是在public-coin模型中运行，所以我们可以从区块链中提取随机性来发出挑战。



## **4 Filecoin:DSN构建**

Filecoin DSN是可升级，可公开验证和激励式设计的去中心化的存储网络。客户为了存储数据和检索数据向矿工网络付费。矿工提供磁盘空间和带宽来赚取费用。矿工只有在网络可以审计他们的服务是否正确提供的时候才会收到付款。

在本节中，我们介绍基于DSN的定义和”时空证明“的Filecoin DSN构建。

### **4.1 环境**

#### **4.1.1 参与者**

任何用户都可以作为客户端、存储矿工和/或检索矿工来参与Filecoin网络。

- 客户在DSN中通过Put和Get请求存储数据或者检索数据，并为此付费。
- 存储矿工为网络提供数据存储。存储矿工通过提供他们的磁盘空间和响应Pug请求来参与Filecoin。要想成为存储矿工，用户必须用与存储空间成比例的抵押品来抵押。存储矿工通过在特定时间存储数据来响应用户的Put请求。存储矿工生成"时空证明”，并提交到区块链网络来证明他们在特定时间内存储了数据。假如证明无效或丢失，那存储矿工将被罚没他们的部分抵押品。存储矿工也有资格挖取新区块，如果挖到了新块，矿工就能得到挖取新块的奖励和包含在块中的交易费。
- 检索矿工为网络提供数据检索服务。检索矿工通过提供用户Get请求所需要的数据来参与Filecoin。和存储矿工不同，他们不需要抵押，不需要提交存储数据，不需要提供存储证明。存储矿工可以同时也作为检索矿工参与网络。检索矿工可以直接从客户或者从检索市场赚取收益。

#### **4.1.2 网络 N**

我们将运行所有运行Filecoin全节点的所有用户细化为一个抽象实体：网络。该网络作为运行管理协议的中介。简单的说，Filecoin区块链的每个新块,全节点管理可用的存储，验证抵押品，审核存储证明已经修复可能的故障。

#### **4.1.3 账本**

我们的协议适用于基于账本的货币。为了通用，我们称之为“账本” L。在任何给定的时间t(称为时期)，所有的用户都能访问Lt。当处于时期t的时候，账本是追加式的，它由顺序的一系列交易组成。Filecoin DSN协议可以在运行验证Filecoin的证明的任意账本上实现。在第六节中我们展示了我们如何基于有用的工作构建一个账本。

#### **4.1.4 市场**

存储需求和供给组成了两个Filecoin市场：存储市场和检索市场。这两个市场是两个去中心化交易所，这会在第5节中详细解释。简而言之，客户和矿工们通过向各自的市场提交订单来设定他们请求服务或者提供服务的订单的价格。交易所为客户和矿工们提供了一种方式来查看匹配出价并执行订单。如果服务请求被成功满足，通过运行管理协议，网络保证了矿工得到报酬，客户将被收取费用。

### **4.2 数据结构**

**碎片** 碎片是客户在DSN所存储数据的一部分。例如，数据是可以任意划分为许多片，并且每片都可以有不同集合的存储矿工来存储。

**扇区** 扇区是存款矿工向网络提供的一些磁盘空间。矿工将客户数据的碎片存储到扇区，并通过他们的服务来赚取令牌。为了存储碎片，矿工们必须向网络抵押他们的扇区。

**分配表** 分配表是一个数据结构，可以跟踪碎片和其分配的扇区。分配表在账本的每个区块都会更新，Merkle根存储在最新的区块中。在实践中，该表用来保持DSN的状态，它使得在证明验证的过程中可以快速查找。更详细的信息，请参看图5。

**订单** 订单是请求或提供服务的意向声明。客户向市场提交投标订单来请求服务（存储数据的存储市场和检索数据的检索市场），矿工们提交报价订单来提供服务。订单数据结构如图10所示。市场协议将在第5节详细介绍。

**订单簿** 订单簿是订单的集合。请查看第5.2.2节的存储市场订单簿和第5.3.3节的检索市场订单簿。

**抵押** 抵押是像网络提供存储（特别是扇区）的承诺。存储矿工必须将抵押提交给账本，以便能在存储市场接受订单。抵押包括了抵押扇区的大小和存储矿工的存放的抵押品。

![filecoin-图5.png](http://chainx.org/Uploads/Editor/Picture/2017-08-22/599be6f7887cd.png)

### **4.3 协议**

在本节中，我们通过描述客户端、矿工和网络执行的操作来概述Filecoin DSN。我们在图7中介绍了Get和Put协议的方法，和在图8中的管理协议。一个协议执行的示例如图6所示。图1是Filecoin协议概览。

#### **4.3.1 客户生命周期**

我们给出客户生命周期的概览：在第5节接下来的协议会做深度的解析。

1. Put：客户将数据存储于Filecoin

   客户可以通过向Filecoin中的矿工支付令牌来存储他们的数据。第5.2节详细介绍了Put协议。

   客户通过Put协议向存储市场的订单簿提交投标订单。当找到矿工的匹配报价订单的时候，客户会将数据发给矿工，并且双方签署交易订单将其提交到存储市场订单簿。客户可以通过提交的订单来决定数据的物理副本数量。更高的冗余度会有更高的存储故障容忍度。

2. Get：客户从Filecoin检索数据。客户可以通过使用Filecoin 令牌向存储矿工付费来检索任何数据。Get协议在第5.3节有详细描述。客户端通过执行Get协议向检索市场订单簿提交投标订单。当找到匹配的矿工报价订单后，客户会收到来自矿工的碎片。当收到的时候，双方对交易订单进行签名提交到区块链来确认交易成功。

#### 4.3.2 挖矿周期（对于存储矿工）

我们给出一个非正式的挖矿周期概述。

1. 抵押：存储矿工向网络抵押存储。

   存储矿工通过在抵押交易中存放抵押品来保证向区块链提供存储。通过 **Manage.PledgeSector** ，抵押品被抵押一段期限是为了提供服务，如果矿工为他们所承诺提交存储的数据生成存储证明，抵押品就会返还给他们。如果存储证明失败了，一定数量的抵押品就会损失。他们设定价格并向市场订单簿提交报价订单，一旦抵押交易在区块链中出现，矿工就能在存储市场中提供他们的存储。

   **Manage.PledgeSector** • inputs:

   – current allocation table allocTable

   – pledge request pledge

   • outputs: allocTable'

2. 接收订单：存储矿工从存储市场获取存储请求。他们设定价格并通关过**Put.AddOrders**向市场订单簿提交报价订单，一旦抵押交易出现在区块链中，矿工就能在存储市场中提供他们的存储。

   Put.AddOrders

   • inputs: list of orders O1..On

   • outputs: bit b, equals 1 if successful

   通过**Put.MatchOrders** 来检查是否和客户的报价订单匹配一致。

   Put.MatchOrders

   • inputs:

   – the current Storage Market OrderBook – query order to match Oq

   • outputs: matching orders O1..On

   一定订单匹配，客户会讲他们的数据发给存储矿工。存储矿工接收到数据的时候，运行**Put.ReceivePiece** 。数据被接收完之后，矿工和客户签收订单并将其提交到区块链。

   Put.ReceivePiece

   • inputs: – signing key for Mj

   – current orderbook OrderBook

   – ask order Oask

   – bid order Obid

   – piece p

   • outputs: deal order Odeal signed by Ci and Mj

3. 密封：存储矿工为未来的证明准备碎片。

   存储矿工的存储切分为扇区，每个扇区包括了分配给矿工的碎片。网络通过分配表来跟踪每个存储矿工的扇区。当存储矿工的扇区填满了，这个扇区就被密封起来。密封是一种缓慢的顺序操作。将扇区中的数据转换成为副本，然后将数据的唯一物理副本与存储矿工的公钥相关联。在“复制证明”期间密封式必须的操作。如下所述在第3.4节。

   **Manage.SealSector** • inputs:

   – miner public/private key pair M

   – sector index j

   – allocation table allocTable

   • outputs: a proof πSEAL, a root hash rt

4. 证明：存储矿工证明他们正在存储所承诺的碎片（数据）。

   当存储矿工分配数据时，必须重复生成复制证明以保证他们正在存储数据（有关更多详细信息，请参看第3节）证明发布在区块链中，并由网络来验证。

   **Manage.ProveSector**

   • inputs:

   – miner public/private key pair M

   – sector index j

   – challenge c

   • outputs: a proof πPOS

#### **4.3.3 挖矿周期（对于检索矿工）**

我们给出一个非正式的挖矿周期概述。

1. 收到订单：检索矿工从检索市场得到获取数据的请求。

   检索矿工设置价格并向市场订单簿增加报价订单，并通过向网络发送报价单来提供数据。

   **Get.AddOrders**

   • inputs: list of orders O1..On

   • outputs: none

   然后检索矿工检查是否与客户的报价订单匹配一致。

   **Get.MatchOrders**

   • inputs:

   – the current Retrieval Market OrderBook

   – query order to match Oq

   • outputs: matching orders O1..On

2. 发送：检索矿工向客户发送数据碎片。

   一旦订单匹配，检索矿工就将数据发送给客户（第5.3节有详细描述）。当数据被接收完成，矿工和客户就签署交易并提交到区块链。

   **Put.SendPieces**

   • inputs: – an ask order Oask

   – a bid order Obid

   – a piece p

   • outputs: a deal order Odeal signed by Mi

#### **4.3.4 网络周期**

我们给出一个非正式的网络操作概述。

1.分配：网络将客户的碎片分配给存储矿工的扇区。

客户通过向存储市场提交报价订单来启动Put协议。当询价单和报价单匹配的时候，参与的各方共同承诺交易并向市场提交成交的订单。此时，网络将数据分配给矿工，并将其记录到分配表中。

**Manage.AssignOrders**

• inputs:

– deal orders O1deal..Ondeal

– allocation table allocTable

• outputs: updated allocation table allocTable'

1. 修复：网络发现故障并试图进行修复

   所有的存储分配对于网络中的每个参与者都是公开的。对于每个块，网络会检查每个需要的证明都存在，检查它们是否有效，因此采取行动：

   **Manage.RepairOrders**

   • inputs:

   – current time t

   – current ledger L

   – table of storage allocations allocTable

   • outputs: orders to repair O1deal..Ondeal, updated allocation table allocTable

2. - 如果有任何证明的丢失或无效，网络会通过扣除部分抵押品的方式来惩罚存储矿工。
   - 如果大量证明丢失或无效（由系统参数Δfault定义），网络会认定存储矿工存在故障，将订单设定为失败，并为同样的数据引入新订单进入市场。
   - 如果所有存储该数据的存储矿工都有故障，则该数据丢失，客户获得退款。

![filecoin-图6.png](http://chainx.org/Uploads/Editor/Picture/2017-08-22/599bea53caabe.png)

### **4.4 担保和要求**

以下是Filecoin DSN如何实现完整性、可检索性，公开可验证性和激励兼容性。

- 实现完整性 数据碎片以加密哈希命名。一个Put请求后，客户只需要存储哈希即可通过Get操作来检索数据，并可以验证收到的数据的完整性。
- 实现可恢复性 在Put请求中，客户指定副本因子和代码期望擦除类型。假设给定的m个存储矿工存储数据，可以容忍最多f个故障，则该方式是(f, m)-tolerant存储。通过在不同的存储提供商存储数据，客户端可以增加恢复的机会，以防存储矿工下线或者消失。
- 实现公开可验证和可审核性 存储矿工需要提交其存储 (πSEAL, πPOST)的证明到区块链。网络中的任意用户都可以在不访问外包数据的情况下验证这些证明的有效性。另外由于这些证明都是存储在区块链上的，所以操作痕迹可以随时审核。
- 实现激励兼容性 不正式的说，矿工通过提供存储而获得奖励。当矿工承诺存储一些数据的时候，它们需要生成证明。如果矿工忽略了证明就会被惩罚（通过损失部分抵押品），并且不会收到存储的奖励。
- 实现保密性 如果客户希望他们的数据被隐私存储，那客户必须在数据提交到网络之前先进行加密。

![filecoin-图7.png](http://chainx.org/Uploads/Editor/Picture/2017-08-22/599bea72170c6.png)

![filecoin-图8.png](http://chainx.org/Uploads/Editor/Picture/2017-08-22/599bea7ef1f4c.png)



## **5 Filecoin的存储和检索市场**

Filecoin有两个市场：存储市场和检索市场。这两个市场有同样的结构但不同的设计。存储市场允许客户为矿工存储数据而付费。检索数据允许客户为矿工提供检索数据传递而付费。在这两种情况下，客户和矿工可以设置报价和需求价格或者接受当前报价。这个交易是由网络来运行的-Filecoin中全节点是拟人化的。网络保证矿工在提供服务时可以得到客户的奖励。

> 读到这里，感觉filecoin更像一个去中心化的分布式交易所；

### **5.1 验证市场**

交易市场是促进特定商品和服务交换的协议。它们使得买家和买家促成交易。对于我们而言，我们要求交易是可验证的：去中心化网络的参与者必须能够在买家和卖家间验证交易。我们提出验证市场的概念。它没有单一的实体来管理交易，交易是透明的，任何人都可以匿名参与。可验证市场协议使得服务的交易去中心化：订单簿的一致性，订单结算和服务的正确执行是可以由参与者独立验证的-在Filecoin里面的矿工和全节点。我们简化可验证市场来进行以下构建：

**定义5.1**

可验证市场是一个有两个阶段的协议：订单匹配和结算。订单是购买意图或者出售商品或服务安全性的表述，订单簿就是所有可用订单的列表。![WX20180523-165539@2x](../PIC/WX20180523-165539@2x.png)

### **5.2 存储市场**

存储市场是可验证的市场，它允许客户（即买家）请求他们的存储数据和存储矿工（即卖家）提供他们的存储空间。

#### **5.2.1 需求cheng'fa**

我们根据以下需求来设计存储市场协议：

- 链式订单簿 重要的是（1）存储空格的订单是公开的，所以最低价格的订单总是网络知名的，客户可以对订单做出明智的决定（2）客户订单必须始终提交给订单，即使他们接受最低的价格，这样市场就可以对新的报价做出反应。因此我们要求订单添加到Filecoin区块链，为的时能被加入订单簿。
- 参与者投入资源：我们要求参与双方承诺他们的资源作为避免损害的一种方式。为了避免存储矿工不提供服务和避免客户没有可用的资金。为了参与存储市场，存储矿工必须保证在DSN中存入与其存储量成比例的抵押品（更多详细信息请参看第4.3.3节）。通过这种方式，网络可以惩罚那些承诺存储数据但又不提供存储证明的存储矿工。同样的，客户必须向订单充入特定数量的资金，以这种方式保证在结算期间的资金可用性。
- 故障自处理 只有在存储矿工反复证明他们已经在约定的时间内存储了数据的情况下，订单才会结算给矿工。网络必须能够验证这些证明的存在性和正确性并且它们是按照规则来处理的。在4.3.4节有修复部分的概述。

#### **5.2.2 数据结构**

**Put订单** 有三种类型的订单：出价订单，询价订单和交易订单。存储矿工创建询价订单添加存储，客户创建出价订单请求存储，当双方对价格达成一致时，他们共同创建处理订单。订单的数据结构和订单参数的明确定义如图10所示。

**Put订单簿** 存储市场的订单簿是目前有效和开放的询价，出价和 交易订单的集合。用户可以通过Put协议中定义的方法与订单簿进行交互：AddOrders,MatchOrders如图7所示。

订单簿是公开的，并且每个诚实的用户都有同样的订单簿视图。在每个周期，如果新的订单交易出现在新的区块中那它将被添加到订单簿中。如果订单被取消，取消或者结算，则会被删除。订单将被添加到区块链中，因此在订单簿中如果是有效的：

**定义5.2** 我们定义出价，询价，交易订单的有效性：

*（有效出价单）* 从客户端发出的投标单Ci,Obid:= (hsize, funds[, price,time, coll, coding])>Ci,如果满足下面的条件就是有效的：

- Ci 在他们的账户里面至少有可用的资金
- 时间没有超时
- 订单必须保证最少的存储周期（这是个系统参数）

*（有效询价单）* 从存储矿工发出的询价单Mi，Oask:= (hspace, pricei)Mi，如果满足下面的条件就是有效的：

- Mi承诺为矿工，并且质押期不会在订单周期之前到期
- 空间必须小于Mi的可用存储。Mi在订单中减去承诺的存储（在询价订单和交易订单中）

*（有效交易订单）* 交易订单Odeal:= (hask, bid,ts)Ci,Mj，如果满足下面的条件就是有效的：

- 询问参考订单Oask，使得：它由Ci签署，且在存储市场的订单簿中没有其他订单涉及它。
- 出价订单参考订单Obid，使得：它由Mj签署，且在存储市场的订单簿中没有其他订单涉及它。
- ts 不能设置为将来时间或者太早的时间

如果作恶客户端从存储矿工出收到了签名的交易，但从来没有将其添加到订单簿，那么存储矿工就无法重新使用订单中提交的存储。这个字段ts就可以防止这种攻击，因为，在超过ts之后，订单变得无效，将无法在订单簿中提交。

![filecoin-图10.png](http://chainx.org/Uploads/Editor/Picture/2017-08-22/599becba28c09.png)

#### **5.2.3 存储市场协议**

简而言之，存储市场协议分为两个阶段：订单匹配和结算：

- 订单匹配：客户端和存储矿工通过提交交易到区块链来将订单提交到订单簿（步骤1）。当订单匹配时，客户端发送数据碎片给存储矿工，双方签署交易并提交到订单簿（步骤2）。
- 结算： 存储矿工密封扇区（步骤3a），生成扇区所包含的碎片的存储证明，并将其定期提交到区块链（步骤3b)；同时，其余的网络必须验证矿工生成的证明并修复可能的故障（步骤3c）。

存储市场协议在图11中详细描述。

### **5.3 检索市场**

检索市场允许客户端请求检索特定的数据，由检索矿工提供这个服务。与存储矿工不同，检索矿工不要求在特定时间周期内存储数据或者生成存储证明。在网络中的任何用户都可以成为检索矿工，通过提供提供检索服务来赚取Filecoin令牌。检索矿工可以直接从客户端或者检索接收数据碎片，也可以存储它们成为存储矿工。

#### **5.3.1 需求**

我们根据以下的需求来设计检索市场协议：

- **链下订单簿** 客户端必须能够找到提供所需要数据碎片的检索矿工，并且在定价之后直接交换。这意味着订单簿不能通过区块链来运行-因为这将成为快速检索请求的瓶颈。相反的，参与者只能看到订单簿的部分视图。我们要求双方传播自己的订单。
- **无信任方检索** 公平交换的不可能性[10]提醒我们双方不可能没有信任方的进行交流。在存储市场中，区块链网络作为去中心化信任方来验证存储矿工提供的存储。在检索市场，检索矿工和客户端在没有网络见证所交换文件的情况下来交换数据。我们通过要求检查矿工将数据分割成多个部分并将每个部分发送给客户端来达到这个目的，矿工们将收到付款。在这种方式中，如果客户端停止付款，或者矿工停止发送数据，任何一方都可以终止这个交易。注意的是，我们必须总是假设总是有一个诚实的检索矿工。
- **支付通道** 客户端当提交付款的时候可以立即进行检索感兴趣的碎片。检索矿工只有在确认收到付款的时候才会提供数据碎片。通过公共账本来确认交易可能会成为检索请求的瓶颈，所以，我们必须依靠有效的链下支付。Filecoin区块链必须支持快速的支付通道，只有乐观交易和仅在出现纠纷的情况下才使用区块链。通过这种方式，检索矿工和客户端可以快速发送Filecoin协议所要求的小额支付。未来的工作里包含了创建一个如[11,12]所述的支付通道网络。

#### **5.3.2 数据结构**

**获取订单** 检索市场中包含有三种类型的订单：客户端创建的出价单 Obid，检索矿工创建的询价单Oask，和存储矿工和客户端达成的交易订单Odeal。订单的数据结构如图10所示。

**获取订单簿** 检索市场的订单簿是有效的和公开出价订单，询价订单和交易订单的集合。与存储市场不同，每个用户有不同的订单簿试图，因为订单是在网络中传播的，每个矿工和客户端只会跟踪他们所感兴趣的订单。

![filecoin-图11.png](http://chainx.org/Uploads/Editor/Picture/2017-08-22/599bed0718a75.png)

#### **5.3.3 检索市场协议**

简而言之，检索市场协议分为两个阶段：订单匹配和结算：

**订单匹配** 客户端和检索矿工通过广播将订单提交给订单簿（步骤1）。当订单匹配的时候，客户端和检索矿工建立小额支付通道（步骤2）。

**结算** 检索矿工发送小部分的碎片给到客户端，然后对每个碎片客户端会向矿工发送收妥的收据（步骤3）。检索矿工向区块链出示收据从而获得奖励（步骤4）。

该协议在图12中详细解释。

![filecoin-图12.png](http://chainx.org/Uploads/Editor/Picture/2017-08-22/599bed2f74ca0.png)

## **6 有用工作共识**

Filecoin DSN协议可以在允许验证的任何共识协议之上实现Filecoin的证明。在本节中，我们将结算如何基于有用来引导共识协议。Filecoin矿工生成“时空证明”来参与共识，而不是浪费的POW。

**有用** 如果计算的输出对网络来说是有价值的，而不仅仅是为了保证区块链的安全。我们认为矿工在共识协议中所作的工作是有用的。

### **6.1 动机**

确保区块链的安全是至关重要的。POW的证明方案往往要求不能重复使用的或者需要大量的浪费计算才能找到难题的解决方案。

**不可重复利用的工作：** 大多数无许可型的区块链要求矿工解决硬计算难题，譬如反转哈希函数。通常情况下这些解决方案都是无用的，除了保护网络安全之外，没有其他任何价值。我们可以重新设计让这件事有用吗？

**尝试重复使用的工作**：已经有几个尝试重复使用挖矿电路进行有用的计算。有些尝试是要求矿工与标准的POW同时进行一些特殊计算，其他一些尝试用有用问题替代POW的依然难以解决。例如，Primecoin重新使用矿工的计算能力来找到新的素数，以太坊要求矿工与工作证明一起执行小程序，同时证明某些数据正在归档。虽然这些尝试中的大多数都执行有用的工作，但在这些计算中浪费的工作量仍然很普遍的。

**浪费的工作**： 解决难题在机器成本和能力消耗方面是非常昂贵的，特别是如果这些难题完全依赖计算能力。当挖矿算法不能并发的时候，那解决难题的普通因素就是计算的功率。我们可以减少浪费的工作吗？

**试图减少浪费**：理想情况下，大部分网络资源应该花费在有用的工作上。一些尝试是要求矿工使用更节能的解决方案。例如，“空间挖矿”（？Spacemint）要求矿工致力于磁盘空间而不是计算；虽然更加节能，但磁盘空间依然”浪费“，因为它们被随时的数据填满了。其他的尝试是用基于权益证明的传统拜占庭协议来代替难题的解决，其中利益相关方在下一个块的投票与其在系统中所占有的货币份额成正比。

我们着手设计一个基于用户数据存储的有用工作的共识协议。

### **6.2 Filecoin 共识**

#### 6.2.1 挖矿功率

**功率容错** 在我们的技术报告[13]中，我们提出了功率容错，这是对在参与者对协议结果的影响方面重新构建拜占庭故障的抽象。每个参与者控制了网络总功率n中的一部分功率，其中f是故障节点或作恶节点所控制的功率占比。

**Filecoin功率** 在Filecoin中，在时刻t，矿工Mi的功率Pt>i是Mi总和的存储任务。Mi的 Iti是网络中Mi总功率的影响因子。

在Filecoin中，功率有以下属性：

- 公开：网络中当前正在使用的存储总量是公开的。通过读取区块链，任何人都可以计算每个矿工的存储任务-因此任何人都可以计算出在任意时间点的每个矿工的功率和总功率。
- 可公开验证的：对于每个存储任务，矿工都需要生成”时空证明“，证明持续提供服务。通过读取区块链，任何人都可以验证矿工的功率声明是否是正确的。
- 变量： 在任意时间点，矿工都可以通过增加新增扇区和扇区补充的抵押来增加新的存储。这样矿工就能变更他们能提供的功率。

#### **6.2.2 功率会计与时空证明**

每个∆proof 区块（∆proof 是系统参数），矿工们都必须向网络提交“时空证明”，只有网络中大多数功率认为它们是有效的，才会被成功添加到区块链。在每个区块中，每个全节点会更新分配表（AllocTable），添加新的存储分配、删除过期的和标记缺少证明的记录。可以通过对分配表的记录来对矿工Mi的功率进行计算和验证。这些可以通过两种方式来完成：

- 全节点验证：如果节点拥有完整的区块链记录，则可以从创始块开始运行网络协议直到当前区块，这个过程中验证每一个分配给Mi的“时空证明”。
- 简单存储验证：假设轻客户端可以访问广播最新区块的信任源。请客户端可以从网络中的节点请求（1）Mi在当前分配表中的记录 （2）该记录被包含在最新区块的状态树中的Merkle路径（3）从创世块到当前区块的区块头。这样请客户端就可以将“时空证明”的验证委托给网络。

功率计算的安全性来自于“时空证明”的安全性。在这个设置里面，Post保证了矿工无法对他们所分配的存储数量说谎。事实上，他们不能声称能够存储超过他们的存储空间的数据，因为这会花费时间来运行PoSt.Setup，另外PoSt.Prove是串行的计算，并不能并行化的快速生成证明。

#### **6.2.3 使用功率达成共识**

我们预计通过扩展现在（和未来）的权益证明共识协议来实现Filecoin共识的多种策略，其中权益被替换为分配的存储。我们预计了权益证明协议的改进，我们提出了一个基于我们前期工作，称为预期共识的构建[14]。我们的策略是在每一轮选举一个（或多个）矿工，使得赢得选举的概率与每个矿工分配的存储成比例。

**预期共识** 预期共识的基本直觉是确定性的，不可预测的。并在每个周期内秘密选举一个小的Leader集合。预期的期望是每个周期内当选的Leader是1，但一些周期内可能有0个或者许多的Leader。Leader们通过创建新区块并广播来扩展区块链网络。在每个周期，每个区块链被延伸一个或多个区块。在某个无Leader的周期内，空区块被添加到区块链中。虽然链中的区块可以线性排序，其数据结构是有向无环图。EC是一个概率共识，每个周期都使得比前面的区块更加确定，最终达到了足够的确定性，且出现不同的历史块链的可能性是足够小的。如果大多数的参与者都通过签署区块链来扩展区块链，加大这个区块所属链的权重，那么这个区块就被确认了。

**选举矿工** 在每个周期，每个矿工检查他们是否被选为Leader，这类似于完成前面的协议:CoA[15],白皮书[16]，和算法[17]。

*译者注：下面的公式表达式请参考英文原版为佳*

**定义6.1** 如果下面的条件是满足的，则在时刻t 矿工Mi 是Leader：

![define-6.1.png](http://chainx.org/Uploads/Editor/Picture/2017-08-22/599bedbb54d5c.png)

其中rand(t)是在时刻t，可以从区块链中提取出来的公开的随机变量，Pt>i是Mi的功率。考虑对于任意的m，L是H(m)的大小，H是一种安全的加密散列函数，其中（m)Mi是Mi对消息m的签名，使得：

![define-6.1-2.png](http://chainx.org/Uploads/Editor/Picture/2017-08-22/599bedceda485.png)

在图13中，我们描述了矿工（ProveElect）和网络节点（VerifyElect）之间的协议。这种选举方案提供了三个属性：公平，保密和公开的可验证性。

**公平**： 每个参与者每次选举只有一次试验，因为签名是确定性的，而且t和rand(t)是固定的。假设H是安全的加密散列函数，则H(

Mi)/2L必须是从（0，1）均匀选择的实数，因此，可能使得方程等式为true必须是Pti/Σjptj，这等于矿工在在网络中的部分功率。因为这个概率在功率上是线性的，这种可能性在分裂或者汇集功率情况下被保留。注意随机值rand(t)在时刻t之前是未知的。

**保密**： 由于有能力的攻击者不拥有Mi用来计算签名的秘钥，考虑到数字签名的假设，这个是可以忽略不计的。

**公开可验证**： 当选Leader i ∈ Lt 可以通过给出t，rand(t)，H(

i)/2L，来说服一个有效的验证者。鉴于前面的观点，有能力的攻击者在不拥有获胜秘密秘钥的情况下不能生成证明。

![filecoin-图13.png](http://chainx.org/Uploads/Editor/Picture/2017-08-22/599bedeee732c.png)



## 7 智能合约

### **7.1 Filecoin智能合约**

智能合约使得Filecoin的用户可以编写有状态的程序，来花费令牌向市场请求存储J/检索数据和验证存储证明。用户可以通过将交易发送到账本触发合约中的功能函数来与智能合约交互。我们扩展了智能合约系统来支持Filecoin的特定操作（如市场操作，证明验证）。

- 文件合约： 我们允许用户对他们提供的存储服务进行条件编程。有几个例子值得一提：（1）承包矿工：客户可以提前指定矿工提供服务而不参与市场 （2）付款策略：客户可以为矿工设计不同的奖励策略，例如合约可以给矿工支付随着时间的推移越来高的费用 ，另一个合约可以由值得信任的Oracle的通知来设置存储的价格。（3）票务服务：合约可以允许矿工存放令牌和用于代表用户的存储/检索的支付 （4）更复杂的操作：客户可以创建合约来运行数据更新。
- 智能合约：用户可以将程序关联到其他系统（如以太坊[18]）他们的交易上,他们不直接依赖存储的使用。我们预见了以下的应用程序：去中心化命名服务，资产跟踪和预售平台。

### **7.2 与其他系统的集成**

桥是旨在连接不同区块链的工具；现在正在处理中的，我们计划支持跨链交互，以便能将Filecoin存储带入其他基于区块链的平台，同时也将其他平台的功能带入Filecoin。

- Filecoin进入其他平台：其他的区块链系统，如比特币[19]，Zcash [20]，特别是Ethereum [18]和Tezos，允许开发人员写智能合约；然而，这些平台只提供很少的存储能力和非常高的成本。我们计划提供桥将存储和检索支持带入这些平台。我们注意到，IPFS已经被作为几个智能合约（和协议令牌）引用和分发内容的一种方式来使用。增加到Filecoin的支持将允许这些系统以交换Filecoin令牌的方式来保证IPFS存储内容。
- 其他平台进入Filecoin：我们计划提供Filecoin连接其他区块链服务的桥。例如，与Zcash的集成将支持发送隐私数据的存储请求。

## **8 未来的工作**

这项工作为Filecoin网络的建设提供了一个清晰和凝聚的道路;但是，我们也认为这项工作将成为今后研究去中心化存储系统的起点。在这个我们识别和填充三类未来 工作。这包括已经完成只是等待描述和发布的工作，提出改进当前协议的开放式问题，和协议的形式化。

### **8.1 正在进行的工作**

以下主题代表正在进行的工作。

- •每个块中的Filecoin状态树的规范。
- Filecoin及其组件的详细绩效估计和基准。
- 完全可实现的Filecoin协议规范。
- 赞助检索票务模型，其中通过分配每个可持票花费的令牌，任何客户端C1可以赞助另一个客户端C2的下载。
- 分层共识协议，其中Filecoin子网可以在临时或永久分区进行分区并继续处理事务。
- 使用SNARK / STARK增量区块链快照。
- FileCoin-Ethereum合约接口和协议。
- 使用编织（Braid？）进行区块链归档和区块链间冲压。
- 只有在区块链解决冲突的时候才发布"时空证明”。
- 正式证明实现了Filecoin DSN和新型存储证明。

### **8.2 开放式问题**

作为一个整体，有一些公开的问题，其答案有可能可以大大改善网络。尽管事实上，在正式启动之前并不是必须必须解决的问题。

- 一个更好的原始的"复制证明“密封功能，理想情况下是O（n）解码（不是O（nm）），可公开验证，无需SNARK / STARK。
- “复制证明”功能的一个更好的原语，可以公开验证和透明没有SNARK / STARK。
- 一个透明，可公开验证的可检索证明或其他存储证明。
- 在检索市场中进行检索的新策略（例如，基于概率支付，零知识条件支付）。
- “预期共识”更好的秘密Leader选举，在每个周期，只有一位当选Leader。
- 更好的可信赖的SNARK设置方案，允许增加扩展公共参数（可以运行MPC序列的方案，其中每个附加的MPC严格降低故障概率，并且每个MPC的输出可用于系统）。

### **8.3 证明和正式的验证**

由于证明和正式验证的明确价值，我们计划证明Filecoin网络的许多属性，并在未来几个月和几年内开发正式验证的协议规范。几个证明正在进行中还有些正在思考中。但注意，要证明Filecoin的许多属性（如伸缩，离线）将是艰难的，长期的工作。

- 预期共识和变体的正确性证明。
- 功率故障容错正确性的证明，异步1/2不可能导致分叉。
- 在通用组合框架中制定Filecoin DSN，描述Get，Put和Manage作为理想的功能，并证明我们的实现。
- 自动自愈保证的正式模型和证明。
- 正式验证协议描述（例如TLA +或Verdi）。
- 正式验证实现（例如Verdi）。
- Filecoin激励的游戏理论分析。

## **致谢**

这项工作是Protocol Labs团队中多个人的累积努力，如果没有实验室的合作者和顾问的帮助、评论和审查这是不可能完成的。 Juan Benet在2014年写了原始的Filecoin白皮书，为这项工作奠定了基础。他和尼古拉·格雷科（Nicola Greco）开发了新的协议，并与提供了有用的贡献，评论，审查意见的团队其他人合作编写了这份白皮书。特别是大卫“大卫”Dalrymple提出了订单范例和其他想法，Matt Zumwalt改进了在这篇论文中的结构，伊万·米亚佐诺（Evan Miyazono）创建了插图，并完成了这篇论文，在设计协议时，Jeromy Johnson提出了深刻的见解，Steven Allen提供了深刻的问题和清晰的说明。我们也感谢所有的合作者和顾问进行有用的对话;尤其是Andrew Miller和Eli Ben-Sasson。

以前版本：QmVcyYg2qLBS2fNhdeaNN1HvdEpLwpitesbsQwneYXwrKV

译者：郭世清（toxotguo@gmail.com)

**以太坊打赏地址：0xc65085cE0e9890383b4cbD4028d1C14d6ce56F9c**

**参考文献**

[1] Juan Benet. IPFS - Content Addressed, Versioned, P2P File System. 2014.

[2] Giuseppe Ateniese, Randal Burns, Reza Curtmola, Joseph Herring, Lea Kissner, Zachary Peterson, and Dawn Song. Provable data possession at untrusted stores. In Proceedings of the 14th ACM conference on Computer and communications security, pages 598–609. Acm, 2007.

[3] Ari Juels and Burton S Kaliski Jr. Pors: Proofs of retrievability for large files. In Proceedings of the 14th ACM conference on Computer and communications security, pages 584–597. Acm, 2007.

[4] Hovav Shacham and Brent Waters. Compact proofs of retrievability. In International Conference on the Theory and Application of Cryptology and Information Security, pages 90–107. Springer, 2008.

[5] Protocol Labs. Technical Report: Proof-of-Replication. 2017.

[6] Rosario Gennaro, Craig Gentry, Bryan Parno, and Mariana Raykova. Quadratic span programs and succinct nizks without pcps. In Annual International Conference on the Theory and Applications of Cryptographic Techniques, pages 626–645. Springer, 2013.

[7] Nir Bitansky, Alessandro Chiesa, and Yuval Ishai. Succinct non-interactive arguments via linear interactive proofs. Springer, 2013.

 [8] Eli Ben-Sasson, Alessandro Chiesa, Daniel Genkin, Eran Tromer, and Madars Virza. Snarks for c: Verifying program executions succinctly and in zero knowledge. In Advances in Cryptology–CRYPTO 2013, pages 90–108. Springer, 2013.

[9] Eli Ben-Sasson, Iddo Bentov, Alessandro Chiesa, Ariel Gabizon, Daniel Genkin, Matan Hamilis, Evgenya Pergament, Michael Riabzev, Mark Silberstein, Eran Tromer, et al. Computational integrity with a public random string from quasi-linear pcps. In Annual International Conference on the Theory and Applications of Cryptographic Techniques, pages 551–579. Springer, 2017.

[10] Henning Pagnia and Felix C G¨artner. On the impossibility of fair exchange without a trusted third party. Technical report, Technical Report TUD-BS-1999-02, Darmstadt University of Technology, Department of Computer Science, Darmstadt, Germany, 1999.

[11] Joseph Poon and Thaddeus Dryja. The bitcoin lightning network: Scalable off-chain instant payments. 2015.

[12] Andrew Miller, Iddo Bentov, Ranjit Kumaresan, and Patrick McCorry. Sprites: Payment channels that go faster than lightning. arXiv preprint arXiv:1702.05812, 2017.

[13] Protocol Labs. Technical Report: Power Fault Tolerance. 2017.

[14] Protocol Labs. Technical Report: Expected Consensus. 2017.

[15] Iddo Bentov, Charles Lee, Alex Mizrahi, and Meni Rosenfeld. Proof of activity: Extending bitcoin’s proof of work via proof of stake [extended abstract] y. ACM SIGMETRICS Performance Evaluation Review, 42(3):34–37, 2014.

[16] Iddo Bentov, Rafael Pass, and Elaine Shi. Snow white: Provably secure proofs of stake. 2016.

[17] Silvio Micali. Algorand: The efficient and democratic ledger. arXiv preprint arXiv:1607.01341, 2016.

[18] Vitalik Buterin. Ethereum , April 2014. URL https://ethereum.org/.

[19] Satoshi Nakamoto. Bitcoin: A peer-to-peer electronic cash system, 2008.

[20] Eli Ben Sasson, Alessandro Chiesa, Christina Garman, Matthew Green, Ian Miers, Eran Tromer, and Madars Virza. Zerocash: Decentralized anonymous payments from bitcoin. In Security and Privacy (SP), 2014 IEEE Symposium on, pages 459–474. IEEE, 2014.

[TOC]

##  0. 摘要

星际文件系统是一种点对点的分布式文件系统， 旨在连接所有有相同的文件系统的计算机设备。在某些方面， IPFS类似于web, 但web 是中心化的，而IPFS是一个单一的Bittorrent 群集， 用git 仓库分布式存储。换句话说， IPFS 提供了高吞吐量的内容寻址块存储模型， 具有内容寻址的超链接。这形成了一个广义的Merkle DAG 数据结构，可以用这个数据结构构建版本文件系统，区块链，甚至是永久性网站。IPFS 结合了分布式哈希表， 带有激励机制的块交换和自我认证命名空间。IPFS 没有单故障点， 节点不需要相互信任。

> 总结及说明：
>
> 1.  IPFS核心就是一个 `Bittorrent` 加上`Git` ;Bittorrent决定了其具有中心化的特性；而Git决定了其具有文件版本管理能力；
> 2.  高吞吐量是由其底层网络模型的CDN决定的；



## 1. 介绍

在全球分布式文件系统这领域， 已经有许多人的尝试。一些系统已经取得了重大的成功， 而很多却完全失败了。在学术尝试中， AFS【6】就是成功的例子，如今已经得到广泛的应用， 然而，其他的却没有得到相同的结果。在学术界之外，应用最广泛的是面向音视频媒体的点对点文件共享系统。 最值得注意的是， Napster, KaZaA 和BitTorrent[2]部署的文件分发系统支持1亿用户的同时在线。即使在今天， BitTorrent 也维持着每天千万节点的活跃数。 基于这些学术文件系统理论而实现的应用程序有很多的用户量， 然而，这些系统理论是在应用层，而没有放在基础层。以致没有出现通用的文件系统基础框架， 给全球提供低延迟的分发。
也许是因为HTTP这样“足够好“的系统已经存在。到目前为止，HTTP已经作为“分布式文件系统“的协议，并且已经大量部署，再与浏览器相结合，具有巨大的技术和社会影响力。在现在， 它已经成为互联网传输文件的事实标准。然而，他没有采用最近15年的发明的数十种先进的文件分发技术。 从一方面讲， 由于向后兼容的限制 和 当前新模式的投入， 不断发展http web 的基础设施几乎是不可能的。但从一个角度看， 从http 出现以来， 已经有许多新协议出现并被广泛使用。升级http协议虽然能引入新功能和加强当前http协议，但会降低用户的体验。
有些行业已经摆脱使用HTTP 这么久， 因为移动小文件相对便宜，即使对拥有大流量的小组织也是如此。但是，随着新的挑战，我们正在进入数据分发的新纪元。

（a）托管和分发PB级数据集，

（b）跨组织的大数据计算，

（c）大批量的高清晰度按需或实时媒体流，

（d）大规模数据集的版本化和链接，

（e）防止意外丢失重要文件等。其中许多可以归结为“大量数据，无处不在”。由于关键功能和带宽问题，我们已经为不同的数据放弃了HTTP 分销协议。下一步是使它们成为web自己的一部分。

正交于有效的数据分发，版本控制系统，已经设法开发重要的数据协作工作流程。Git是分布式源代码版本控制系统，开发了许多有用的方法来建模和实现分布式数据操作。Git工具链提供了灵活的版本控制功能，这正是大量的文件分发系统所严重缺乏的。由Git启发的新解决方案正在出现，如Camlistore [？]，个人文件存储系统，Dat [？]数据协作工具链和数据集包管理器。Git已经影响了分布式文件系统设计[9]，因为其内容涉及到Merkle DAG数据模型，能够实现强大的文件分发策略。还有待探讨的是，这种数据结构如何影响面向高吞吐量的文件系统的设计，以及如何升级Web本身。

本文介绍了IPFS，一种新颖的对等版本控制的文件系统，旨在调和这些问题。 IPFS综合了许多以前成功的系统的优点。 IPFS产生了突出的效果， 甚至比参考的这些系统的总和还要好。IPFS的核心原则是将所有数据建模为同一Merkle DAG的一部分。



##2. 背景

本节回顾了IPFS所采用成功的点对点系统技术的重要属性。

### 2.1 分布式哈希表(DHT)

分布式散列表（DHT）被广泛用于协调和维护关于对等系统的元数据。比如，MainlineDHT 是一个去中心化哈希表，他可追踪查找所有的对等节点。

#### 2.1.1 KADEMLIA DHT

Kademlia[10] 是受欢迎的DHT, 它提供：

1. 通过大量网络进行高效查询：查询平均联系人O(log2N)节点。 （例如，20跳10万个节点的网络）
2. 低协调开销：优化数量的控制消息发送到其他节点。
3. 抵抗各种攻击，喜欢长寿节点。
4. 在对等应用中广泛使用，包括Gnutella和BitTorrent，形成了超过2000万个节点的网络[16]。

#### 2.1.2 CORAL DSHT

虽然一些对等文件系统直接在DHT中存储数据块，这种“数据存储在不需要的节点会浪费存储和带宽”[5]。Coral DSHT扩展了Kademlia三个特别重要的方式：

1. Kademlia在ids为“最近”（使用XOR-distance）的关键节点中存储值。这不考 虑应用程序数据的局部性，忽略“远”可能已经拥有数据的节点，并强制“最近”节点存储它，无论它们是否需要。这浪费了大量的存储和带宽。相反，Coral 存储了地址， 该地址的对等节点可以提供相应的数据块。
2. Coral将DHT API从get_value(key)换成了get_any_values(key)（DSHT中的“sloppy”）中。这仍然是因为Coral用户只需要一个（工作）的对等体，而不是完整的列表。作为回报，Coral可以仅将子集分配到“最近”的节点，避免热点（当密钥变得流行时，重载所有最近的节点）。
3. 另外，Coral根据区域和大小组织了一个称为群集的独立DSHT层次结构。这使得节点首先查询其区域中的对等体，“查找附近的数据而不查询远程节点”[5]并大大减少查找的延迟。

#### 2.1.3 S/KADEMLIA DHT

S/Kademlia[1] 扩展了Kademlia, 用于防止恶意的攻击。有如下两方面的方法：

1. S/Kad 提供了方案来保证NodeId的生成已经防止Sybill攻击。它需要节点产生PKI公私钥对。从中导出他们的身份，并彼此间签名。一个方案使用POW工作量证明，使得生成Sybills成本高昂。
2. S/Kad 节点在不相交的路径上查找值， 即使网络中存在大量的不诚实节点，也能确保诚实节点可以互相链接。即使网络中存在一半的不诚实节点，S/Kad 也能达到85%的成功率。

### 2.2 块交换 - BitTorrent

BitTorrent[3] 是一个广泛成功应用的点对点共享文件系统，它可以在存在不信任的对等节点（群集）的协作网络中分发各自的文件数据片。从BitTorrent和它的生态系统的关键特征， IPFS得到启示如下：

1. BitTorrent的数据交换协议使用了一种bit-for-tat的激励策略， 可以奖励对其他方面做贡献的节点，惩罚只榨取对方资源的节点。
2. BitTorrent对等体跟踪文件的可用性，优先发送稀有片段。这减轻了seeds节点的负担， 让non-seeds节点有能力互相交易。
3. 对于一些剥削带宽共享策略， BitTorrent的标准tit-for-tat策略是非常脆弱的。 然而，PropShare[8]是一种不同的对等带宽分配策略， 可以更好的抵制剥削战略， 提高群集的表现。

### 2.3. 版本控制系统 - Git

版本控制系统提供了对随时间变化的文件进行建模的设施，并有效地分发不同的版本。流行版本控制系统Git提供了强大的Merkle DAG对象模型，以分布式友好的方式捕获对文件系统树的更改。

1. 不可更改的对象表示文件（blob），目录（树）和更改（提交）。

2. 通过加密hash对象的内容，让对象可寻址。

3. 链接到其他对象是嵌入的，形成一个Merkle DAG。这提供了很多有用的完整和work-flow属性。

4. 很多版本元数据（分支，标示等等）都只是指针引用，因此创建和更新的代价都小。

5. 版本改变只是更新引用或者添加对象。

6. 分布式版本改变对其他用户而言只是转移对象和更新远程引用。



### 2.4 自我认证认文件系统-SFS

SFS [ 12，11 ]提出了两个引人注目的实现（a）分布式信任链，和（b）平等共享的全局命名空间。SFS引入了一种自我建构技术—注册文件：寻址远程文件系统使用以下格式：

```powershell
/sfs/<Location>:<HostID>
Location:代表的是服务网络地方
HostID = hash(public_key || Location)
```

因此SFS文件系统的名字认证了它的服务，用户可以通过服务提供的公钥来验证，协商一个共享的私钥，保证所有的通信。所有的SFS实例都共享了一个全局的命名空间，这个命名空间的名称分配是加密的，不被任何中心化的body控制。

## 3. IPFS设计

IPFS是一个分布式文件系统，它综合了以前的对等系统的成功想法，包括DHT，BitTorrent，Git和SFS。 IPFS的贡献是简化、发展和将成熟的技术连接成一个单一的内聚系统，大于其部分的总和。 IPFS提供了编写和部署应用程序的新平台，以及一个新的分发系统版本化大数据。 IPFS甚至可以演进网络本身。
IPFS是点对点的;没有节点是特权的。 IPFS节点将IPFS对象存储在本地存储中。节点彼此连接并传输对象。这些对象表示文件和其他数据结构。 IPFS协议分为一组负责不同功能的子协议：
**1. 身份** - 管理节点身份生成和验证。描述在3.1节。
**2.网络** - 管理与其他对等体的连接，使用各种底层网络协议。可配置的。详见3.2节。
**3.路由** - 维护信息以定位特定的对等体和对象。响应本地和远程查询。默认为DHT，但可更换。在3.3节描述。
**4.交换** - 一种支持有效块分配的新型块交换协议（BitSwap）。模拟市场，弱化数据复制。贸易策略可替换。描述在3.4节。
**5.对象** - 具有链接的内容寻址不可更改对象的Merkle DAG。用于表示任意数据结构，例如文件层次和通信系统。详见第3.5节。
**6.文件** - 由Git启发的版本化文件系统层次结构。详见3.6节。
**7.命名** - 自我认证的可变名称系统。详见3.7节。
这些子系统不是独立的;它们是集成在一起，互相利用各自的属性。但是，分开描述它们是有用的，从下到上构建协议栈。

符号：Go语言中指定了以下数据结构和功能

### 3.1 身份

节点由NodeId标识，这是使用S / Kademlia的静态加密难题[1]创建的公钥的密码散列。节点存储其公私钥（用密码加密）。用户可以在每次启动时自由地设置一个“新”节点身份，尽管这会损失积累的网络利益。激励节点保持不变。

```go
         type NodeId Multihash
         type Multihash []byte  // 自描述加密哈希摘要
         type PublicKey []byte
         type PrivateKey []byte // 自描述的私钥
         type Node struct {
             NodeId NodeID
             PubKey PublicKey
             PriKey PrivateKey
         }
基于S / Kademlia的IPFS身份生成：
        difficulty = <integer parameter>
        n = Node{}
        do {
            n.PubKey, n.PrivKey = PKI.genKeyPair()
            n.NodeId = hash(n.PubKey)
            p = count_preceding_zero_bits(hash(n.NodeId))
        } while (p < difficulty)
```

首次连接时，对等体交换公钥，并检查：hash（other.PublicKey）等于other.NodeId。如果没有，则连接被终止
关于加密函数的注意事项：
IPFS不是将系统锁定到一组特定的功能选择，而是支持自我描述的值。哈希摘要值以多重哈希格式存储，其包括指定使用的哈希函数的头和以字节为单位的摘要长度。例如：

```
<function code><digest length><digest bytes>
```

这允许系统

（a）选择最佳功能用例（例如，更强的安全性与更快的性能），

（b）随着功能选择的变化而演变。自描述值允许兼容使用不同的参数选择。

### 3.2 网络

IPFS节点与数百个其他节点进行定期通信网络中的节点，可能跨越广域网络。IPFS网络堆栈功能：

传输层： IPFS可以使用任何传输协议，并且最适合WebRTC DataChannels [？]（用于浏览器连接）或uTP（LEDBAT [14]）。

可靠性： 如果底层网络不提供可靠性，IPFS可使用uTP（LEDBAT [14]）或SCTP [15]来提供可靠性。

可连接性：IPFS还可以使用ICE NAT穿墙打洞技术[13]。

完整性：可以使用哈希校验和来检查邮件的完整性。

可验证性：可以使用发送者的公钥使用HMAC来检查消息的真实性。

#### 3.2.1对等节点寻址注意事项：

IPFS可以使用任何网络; 但它不承担对IP的获取以及不直接依赖于ip层。这允许在覆盖网络中使用IPFS。

IPFS将地址存储为多层地址 ~这个很有意思~，这个多层地址是由字节字符串组成的， 以便于给底层网络使用。多层地址提供了一种方式来表示地址及其协议，可以封装成好解析的格式。例如：

```powershell
# an SCTP/IPv4 connection
/ip4/10.20.30.40/sctp/1234/
# an SCTP/IPv4 connection proxied over TCP/IPv4
/ip4/5.6.7.8/tcp/5678/ip4/1.2.3.4/sctp/1234/
```


### 3.3 路由

IPFS节点需要一个路由系统， 这个路由系统可用于查找：

（a）其他同伴的网络地址，

（b）专门用于服务特定对象的对等节点。

IPFS使用基于S / Kademlia和Coral的DSHT，在2.1节中具体介绍过。在对象大小和使用模式方面， IPFS 类似于Coral[5] 和Mainline[16], 因此，IPFS DHT根据其大小对存储的值进行区分。小的值（等于或小于1KB）直接存储在DHT上。对于更大的值，DHT只存储值索引，这个索引就是一个对等节点的NodeId, 该对等节点可以提供對该类型的值的具体服务。

DSHT的接口如下：

```go
type IPFSRouting interface {
   FindPeer(node NodeId) // 获取特定NodeId的网络地址。
   SetValue(key []bytes, value []bytes) // 往DHT存储一个小的元数据。
   GetValue(key []bytes) // 从DHT获取元数据。
   ProvideValue(key Multihash) // 声明这个节点可一个提供一个大的数据。
   FindValuePeers(key Multihash, min int) // 获取服务于该大数据的节点。
}
```
注意：不同的用例将要求基本不同的路由系统（例如广域网中使用DHT，局域网中使用静态HT）。因此，IPFS路由系统可以根据用户的需求替换的。只要使用上面的接口就可以了，系统都能继续正常运行。

### 3.4块交换 - BitSwap协议

IPFS 中的BitSwap协议受到BitTorrent 的启发，通过对等节点间交换数据块来分发数据的。像BT一样， 每个对等节点在下载的同时不断向其他对等节点上传已下载的数据。和BT协议不同的是， BitSwap 不局限于一个torrent文件中的数据块。BitSwap 协议中存在一个永久的市场。 这个市场包括各个节点想要获取的所有块数据~这个市场怎么理解？~。而不管这些块是哪些如.torrent文件中的一部分。这些块数据可能来自文件系统中完全不相关的文件。 这个市场是由所有的节点组成的。
虽然易货系统的概念意味着可以创建虚拟货币，但这将需要一个全局分类账本来跟踪货币的所有权和转移。这可以实施为BitSwap策略，并将在未来的论文中探讨。
在基本情况下，BitSwap节点必须以块的形式彼此提供直接的值。只有当跨节点的块的分布是互补的时候，各取所需的时候，这才会工作的很好。 通常情况并非如此，在某些情况下，节点必须为自己的块而工作。 在节点没有其对等节点所需的（或根本没有的）情况下，它会更低的优先级去寻找对等节点想要的块。这会激励节点去缓存和传播稀有片段， 即使节点对这些片段不感兴趣。

> BitSwap中的永久市场怎么理解？



#### 3.4.1 - BITSWAP 信用

这个协议必须带有激励机制， 去激励节点seed 为其他节点提供所需要的块，而它们本身是不需要这些块的。 因此， BitSwap的节点很积极去给对端节点发送块，期待获得报酬。但必须防止水蛭攻击（空负载节点从不共享块），一个简单的类似信用的系统解决了这些问题：

1. 对等节点间会追踪他们的平衡（通过字节认证的方式）。

2. 随着债务增加而概率降低，对等者概率的向债务人发送块。

​

注意的是，如果节点决定不发送到对等体，节点随后忽略对等体的ignore_cooldown超时。 这样可以防止发送者尝试多次发送（洪水攻击） （BitSwap默认是10秒）。

#### 3.4.2 BITSWAP的策略

BitSwap 对等节点采用很多不同的策略，这些策略对整个数据块的交换执行力产生了不同的巨大影响。在BT 中， 标准策略是明确规定的（tit-for-tat），其他不同的策略也已经被实施，从BitTyrant [8]（尽可能分享）到BitThief [8]（利用一个漏洞，从不共享），到PropShare [8]（按比例分享）。BitSwap 对等体可以类似地实现一系列的策略（良好和恶意）。对于功能的选择，应该瞄准：

1. 为整个交易和节点最大化交易能力。
2. 为了防止空负载节点利用和损害交易。
3. 高效抵制未知策略。
4. 对可信任的对等节点更宽容。

探索这些策略的空白是未来的事情。在实践中使用的一个选择性功能是sigmoid，根据负债比例进行缩放：

让负债比例在一个节点和它对等节点之间：

```
r =  bytes_sent  / bytes_recv + 1
```
根据r，发送到负债节点的概率为：

```
P(send | r ) = 1 − ( 1/  ( 1 + exp(6 − 3r) ) )
```

正如你看到的图片1，当节点负债比例超过节点已建立信贷的两倍，发送到负债节点的概率就会急速下降。

![WX20180522-135812](../PIC/WX20180522-135812.png)

```
图片1  当r增加时发送的概率
```

负债比是信任的衡量标准：对于之前成功的互换过很多数据的节点会宽容债务，而对不信任不了解的节点会严格很多。这个(a)给与那些创造很多节点的攻击者（sybill 攻击）一个障碍。(b)保护了之前成功交易节点之间的关系，即使这个节点暂时无法提供数据。(c)最终阻塞那些关系已经恶化的节点之间的通信，直到他们被再次证明。

#### 3.4.3 BITSWAP 账本

BitSwap节点保存了一个记录与所有其他节点之间交易的账本。这个可以让节点追踪历史记录以及避免被篡改。当激活了一个链接，BitSwap节点就会互换它们账本信息。如果这些账本信息并不完全相同，分类账本将会重新初始化， 那些应计信贷和债务会丢失。 恶意节点会有意去失去“这些“账本， 从而期望清除自己的债务。节点是不太可能在失去了应计信托的情况下还能累积足够的债务去授权认证。伙伴节点可以自由的将其视为不当行为， 拒绝交易。

```go
 type Ledger struct {
    owner NodeId
    partner NodeId
    bytes_sent int
    bytes_recv int
    timestamp Timestamp
}
```

节点可以自由的保留分布式账本历史，这不需要正确的操作，因为只有当前的分类账本条目是有用的。节点也可以根据需要自由收集分布式帐本，从不太有用的分布式帐开始：老（其他对等节点可能不存在）和小。

#### 3.4.4 BITSWAP 详解

BitSwap 节点有以下简单的协议。

```go
// Additional state kept
  type BitSwap struct {
     ledgers map[NodeId]Ledger // Ledgers known to this node, inc inactive
     active map[NodeId]Peer // currently open connections to other nodes
     need_list []Multihash // checksums of blocks this node needs
     have_list []Multihash // checksums of blocks this node has
  }
  type Peer struct {
     nodeid NodeId
     ledger Ledger // Ledger between the node and this peer
     last_seen Timestamp // timestamp of last received message
     want_list []Multihash // checksums of all blocks wanted by peer
     // includes blocks wanted by peer's peers
}
 // Protocol interface:
 interface Peer {
    open (nodeid : NodeId, ledger : Ledger);
    send_want_list (want_list : WantList);
    send_block(block: Block) -> (complete:Bool);
    close(final: Bool);
}
```

对等连接的生命周期草图：

1. Open: 对等节点间发送ledgers 直到他们同意。
2. Sending: 对等节点间交换want_lists 和blocks。
3. Close: 对等节点断开链接。
4. Ignored: （特殊）对等体被忽略（等待时间的超时）如果节点采用防止发送策略。

**Peer.open(NodeId, Ledger).**
当发生链接的时候，节点会初始化链接的账本，要么保存一个份链接过去的账本，要么创建一个新的被清零的账本。然后，发送一个携带账本的open信息给对等节点。
接收到一个open信息之后，对等节点可以选择是否接受此链接。如果，根据接收者的账本，发送者是一个不可信的代理（传输低于零或者有很大的未偿还的债务），接收者可能会选择忽略这个请求。忽略请求是ignore_cooldown超时来概率性实现的，为了让错误能够有时间改正和攻击者被挫败。
如果链接成功，接收者用本地账本来初始化一个Peer对象以及设置last_seen时间戳。然后，它会将接受到的账本与自己的账本进行比较。如果两个账本完全一样，那么这个链接就被Open，如果账本并不完全一致，那么此节点会创建一个新的被清零的账本并且会发送此账本。
**Peer.send_want_list(WantList)**
当链接已经Open的时候，节点会广发它们的want_list给所有已经链接的对等节点。这个是在(a)open链接后(b)随机间歇超时后(c)want_list改变后(d)接收到一个新的块之后完成的。
当接收到一个want_list之后，节点会存储它。然后，会检查自己是否拥有任何它想要的块。如果有，会根据上面提到的BitSwap策略来将want_list所需要的块发送出去。
**Peer.send_block(Block)**
发送一个块是直接了当的。节点只是传输数据块。当接收到了所有数据的时候，接收者会计算多重hash校验和来验证它是否是自己所需数据，然后发送确认信息。
在完成一个正确的块传输之后，接受者会将此块从need_list移到have_list,最后接收者和发送者都会更新它们的账本来反映出传输的额外数据字节数。
如果一个传输验证失败了，发送者要么会出故障要么会攻击接收者，接收者可以选择拒绝后面的交易。注意，BitSwap是期望能够在一个可靠的传输通道上进行操作的，所以传输错误（可能会引起一个对诚实发送者错误的惩罚）是期望在数据发送给BitSwap之前能够被捕捉到。
**Peer.close(Bool)**
传给close最后的一个参数，代表close链接是否是发送者的意愿。如果参数值为false,接收者可能会立即重新open链接，这避免链过早的close链接。
一个对等节点close链接发生在下面两种情况下：

silence_wait超时已经过期，并且没有接收到来自于对等节点的任何信息（BitSwap默认使用30秒），节点会发送Peer.close(false)。

在节点退出和BitSwap关闭的时候，节点会发送Peer.close(true).

接收到close消息之后，接收者和发送者会断开链接，清除所有被存储的状态。账本可能会被保存下来为了以后的便利，当然，只有在被认为账本以后会有用时才会被保存下来。

注意点：

非open信息在一个不活跃的连接上应该是被忽略的。在发送send_block信息时，接收者应该检查这个块，看它是否是自己所需的，并且是否是正确的，如果是，就使用此块。总之，所有不规则的信息都会让接收者触发一个close(false)信息并且强制性的重初始化此链接。

### 3.5 Merkle DAG对象

DHT和BitSwap允许IPFS构造一个庞大的点对点系统用来快速稳定的分发和存储。最主要的是，IPFS建造了一个Merkle DAG,一个无回路有向图，对象之间的links都是hash加密嵌入在源目标中。这是Git数据结构的一种推广。Merkle DAGS给IPFS提供了很多有用的属性，包括：

1. 内容可寻址：所有内容都是被多重hash校验和来唯一识别的，包括links。
2. 防止篡改：所有的内容都用它的校验和来验证。如果数据被篡改或损坏，IPFS会检测到。
3. 重复数据删除：所有的对象都拥有相同的内容并只存储一次。这对于索引对象非常有用，比如git的tree和commits，或者数据的公共部分。

IPFS对象的格式是：

```go
  type IPFSLink struct {
        Name string      // 此link的别名
        Hash Multihash // 目标的加密hash
        Size int             // 目标总大小
  }

type IPFSObject struct {
      links []IPFSLink   //links数组
      data []byte         //不透明内容数据
}
```

IPFS Merkle DAG是存储数据非常灵活的一种方式。只要求对象引用是(a）内容可寻址的，(b)用上面的格式编码。IPFS允许应用完全的掌控数据域；应用可以使用任何自定义格式的数据，即使数据IPFS都无法理解。单独的内部对象link表允许IPFS做：

- 用对象的形式列出所有对象引用，例如：

  ```powershell
    > ipfs ls /XLZ1625Jjn7SubMDgEyeaynFuR84ginqvzb
  XLYkgq61DYaQ8NhkcqyU7rLcnSa7dSHQ16x 189458 less
  XLHBNmRQ5sJJrdMPuu48pzeyTtRo39tNDR5 19441 script
  XLF4hwVHsVuZ78FZK6fozf8Jj9WEURMbCX4 5286 template

     <object multihash> <object size> <link name>
  ```


- 解决字符串路经查找，例如foo/bar/baz。给出一个对象，IPFS会解析第一个路经成分进行hash放入到对象的link表中，再获取路径的第二个组成部分，一直如此重复下去。因此，任何数据格式的字符串路经都可以在Merkle DAG中使用。



  *递归性的解决所有对象引用：

  ```powershell
    > ipfs refs --recursive \
  /XLZ1625Jjn7SubMDgEyeaynFuR84ginqvzb
  XLLxhdgJcXzLbtsLRL1twCHA2NrURp4H38s
  XLYkgq61DYaQ8NhkcqyU7rLcnSa7dSHQ16x
  XLHBNmRQ5sJJrdMPuu48pzeyTtRo39tNDR5
  XLWVQDqxo9Km9zLyquoC9gAP8CL1gWnHZ7z
  ```

原始数据结构公共link结构是IPFS构建任意数据结构的必要组成部分。可以很容易看出Git的对象模型是如何套用DAG的。一些其他潜在的数据结构：

- (a)键值存储
- (b)传统关系型数据
- (c)数据三倍存储
- (d) 文档发布系统
- (e)通信平台
- (f)加密货币区块。
  这些系统都可以套用IPFS Merkle DAG，这使这些系统更复杂的应用可以使用IPFS作为传输协议。

#### 3.5.1 路经

IPFS对象可以遍历一个字符串路经。路经格式与传统UNIX文件系统以及Web一致。Merkle DAG的links使遍历变得很容易。全称路经在IPFS中的格式是：

```powershell
*# 格式
/ipfs/<hash-of-object>/<name-path-to-object>
*# 例子
/ipfs/XLYkgq61DYaQ8NhkcqyU7rLcnSa7dSHQ16x/foo.txt
```

/ipfs前缀允许只要在挂载点不冲突(挂载点名称当然是可配置的)的情况下挂载到一个已存在的系统上。第二个路经组成部分(第一个是IPFS)是一个对象的hash。通常都是这种情况，因为没有全局的根。一个根对象可能会有一个不可能完成的任务，就是在分布式环境(可能还断开链接)中处理百万对象的一致性。因此，我们用地址可寻址来模拟根。通过的hash所有的对象都是可访问的。这意思是说，给一个路经对象/bar/baz，最后一个对象可以可以被所有的访问的：

```powershell
/ipfs/<hash-of-foo>/bar/baz
/ipfs/<hash-of-bar>/baz
/ipfs/<hash-of-baz>
```

#### 3.5.2 本地对象

IPFS客户端需要一个本地存储器，一个外部系统可以为IPFS管理的对象存储以及检索本地原始数据。存储器的类型根据节点使用案例不同而不同。在大多数情况下，这个存储器只是硬盘空间的一部分（不是被本地的文件系统使用键值存储如leveldb来管理，就是直接被IPFS客户端管理），在其他的情况下，例如非持久性缓存，存储器就是RAM的一部分。
最终，所有的块在IPFS中都是能够获取的到的，块都存储在了一些节点的本地存储器中。当用户请求一个对象时，这个对象会被查找到并下载下来存储到本地，至少也是暂时的存储在本地。这为一些可配置时间量提供了快速的查找。

#### 3.5.3 对象锁定

希望确保特定对象生存的节点可以锁定此对象。这保证此特定对象被保存在了节点的本地存储器上。也可以递归的进行锁定所有相关的派生对象。这使所有被指定的对象都保存在本地存储器上。这对长久保存文件特别有用，包括引用。这也同样让IPFS成为一个links是永久的Web，且对象可以确保其他被指定对象的生存。

#### 3.5.4 发布对象

IPFS是全球分布的。它设计为允许成千上万的用户文件可以共同的存在的。DHT使用内容哈希寻址技术，使发布对象是公平的，安全的，完全分布式的。任何人都可以发布对象，只需要将对象的key加入到DHT中，并且以对象是对等节点的方式加入进去，然后把路径给其他的用户。要注意的是，对象本质上是不可改变的，就像在Git中一样。新版本的哈希值不同，因此是新对象。跟踪版本则是额外版本对象的工作。

#### 3.5.5 对象级别的加密

`IPFS`是具备可以处理对象级别加密操作的。一个已加密的或者已签名的对象包装在一个特殊的框架里，此框架允许加密和验证原始字节。

```go
type EncryptedObject struct {
	Object []bytes // 已加密的原始对象数据
	Tag []bytes    // 可选择的加密标识
	type SignedObject struct {
	Object []bytes  // 已签名的原始对象数据
	Signature []bytes // HMAC签名
	PublicKey []multihash // 多重哈希身份键值
}
```

加密操作改变了对象的哈希值，定义一个不同的新的对象。IPFS自动的验证签名以及使用用户指定的钥匙链解密数据。加密数据的links也同样的被保护着，没有解密秘钥就无法遍历对象。也存在着一种现象，可能父对象使用了一个秘钥进行了加密，而子对象使用了另一个秘钥进行加密或者根本没有加密。这可以保证links共享对象安全。

### 3.6 文件

IPFS在Merkle DAG上还为模型化版本文件系统定义了一组对象。这个对象模型与Git比较相似：
Block：一个可变大小的数据块
List：块或者其他链表的集合
Tree：块，链表，或者其他树的集合
Commit：树在版本历史记录中的一个快照
我原本希望使用与Git对象格式一致的模型，但那就必须要分开来引进在分布式文件系统中有用的某些特征，如

(a)快速大小查找(总字节大小已经加入到对象中)

(b)大文件的重复删除(添加到list对象)

(c)commits嵌入到trees中。不过，IPFS文件对象与Git还是非常相近的，两者之间进行交流都是有可能的。而且，Git的一个系列的对象可以被引进过来转换都不会丢失任何的信息。（UNIX文件权限等等）。

​

标记：下面的文件对象格式使用JSON。注意，虽然IPFS包含了JSON的互相转换，但是文件对象的结构体还是使用protobufs的二进制编码。

#### 3.6.1 文件对象：BLOB

blob对象代表一个文件且包含一个可寻址的数据单元，IPFS的blobs就像Git的blobs或者文件系统数据块。它们存储用户的数据。需要留意的是IPFS文件可以使用lists或者blobs来表示。Blobs没有links。

```json
{
"data": "some data here",  // blobs无links
}
```
#### 3.6.2 文件对象: LIST

List对象代表着由几个IPFS的blobs连接成的大文件或者重复数据删除文件。Lists包含着有序的blob序列或list对象。从某种程度上而言，IPFS的list函数就像一个间接块的文件系统。由于lists可以包含其他的lists，那么包含linked的链表和平衡树的拓扑结构是有可能的。有向图中相同的节点出现在多个不同地方允许在文件中重复数据删除。当然，循环是不可以能的，因为是被哈希寻址强制实行的。

```json
{
"data": ["blob", "list", "blob"], //lists有一个对象类型的数组作为数据
"links": [
{ "hash": "XLYkgq61DYaQ8NhkcqyU7rLcnSa7dSHQ16x",
"size": 189458 },
{ "hash": "XLHBNmRQ5sJJrdMPuu48pzeyTtRo39tNDR5",
"size": 19441 },
{ "hash": "XLWVQDqxo9Km9zLyquoC9gAP8CL1gWnHZ7z",
"size": 5286 } //在links中lists是没有名字的
]
}
```

#### 3.6.3 文件对象：TREE

IPFS中的tree对象与Git中相似，它代表着一个目录，一个名字到哈希值的映射。哈希值则表示着blobs，lists，其他的trees，或者commits。注意，传统路径的命名早已经被Merkle DAG实现了。

```json
{
"data": ["blob", "list", "blob"],//trees有一个对象类型的数组作为数据
"links": [
{ "hash": "XLYkgq61DYaQ8NhkcqyU7rLcnSa7dSHQ16x",
"name": "less", "size": 189458 },
{ "hash": "XLHBNmRQ5sJJrdMPuu48pzeyTtRo39tNDR5",
"name": "script", "size": 19441 },
{ "hash": "XLWVQDqxo9Km9zLyquoC9gAP8CL1gWnHZ7z",
"name": "template", "size": 5286 }//trees是有名字的
]
}
```

#### 3.6.4 文件对象：COMMIT

IPFS中的commit对象代表任何对象在版本历史记录中的一个快照。与Git中类似，但是它能够表示任何类型的对象。它同样link着发起对象。
![img](https://gguoss.github.io/img/ipfs_figure2.png)
![img](https://gguoss.github.io/img/ipfs_figure3.png)

#### 3.6.5 版本控制

Commit对象代表着一个对象在历史版本中的一个特定快照。在两个不同的commit中比较对象（和子对象）可以揭露出两个不同版本文件系统的区别。只要commit和它所有子对象的引用是能够被访问的，所有前版本是可获取的，所有文件系统改变的全部历史是可访问的，这就与Merkle DAG对象模型脱离开来了。

Git版本控制工具的所有功能对于IPFS的用户是可用的。对象模型不完全一致，但也是可兼容的。这可能

(a)构建一个Git工具版本改造成使用IPFS对象图，

(b)构建一个挂载FUSE文件系统，挂载一个IPFS的tree作为Git的仓库，把Git文件系统的读/写转换为IPFS的格式。

#### 3.6.6 文件系统路径

如我们在Merkle DAG中看到的一样，IPFS对象可以使用字符串路径API来遍历。IPFS文件对象是特意设计的，为了让挂载IPFS到UNIX文件系统更加简单。文件对象限制trees没有数据，为了使它们可以表示目录。Commits可以以代表目录的形式出现，也可以完全的隐藏在文件系统中。

#### 3.6.7 将文件分隔成LISTS和BLOBS

版本控制和分发大文件其中一个最主要的挑战是：找到一个正确的方法来将它们分隔成独立的块。与其认为IPFS可以为每个不同类型的文件提供正确的分隔方法，不如说IPFS提供了以下的几个可选选择：
就像在LIBFS[?]中一样使用Rabin Fingerprints [?]来选择一个比较合适的块边界。
使用rsync[?] rolling-checksum算法，来检测块在版本之间的改变。
允许用户指定专为特定文件而调整的’快分隔’函数。

#### 3.6.8 路径查找性能

基于路径的访问需要遍历对象图。获取每个对象要求在DHT中查找它们的key，连接到对等节点，然后获取它的块。这造成相当大的开销，特别是查找的路径由很多子路径组成时。下面的方法可以减缓开销：

- tree缓存：由于所有的对象都是哈希寻址的，它们可以被无限的缓存。另外，trees一般比较小，所以比起blobs，IPFS会优先缓存trees。

- flattened trees：对于任何tree，一个特殊的 flattened tree可以构建一个链表，所有对象都可以从这个tree中访问得到。在flattened tree中名字就是一个从原始tree分离的路径，用斜线分隔。

  ​

  例如，对于上面的ttt111的flattened tree如下：

  ```json
  {
  "data":
  ["tree", "blob", "tree", "list", "blob" "blob"],
  "links": [
  { "hash": "<ttt222-hash>", "size": 1234
  "name": "ttt222-name" },
  { "hash": "<bbb111-hash>", "size": 123,
  "name": "ttt222-name/bbb111-name" },
  { "hash": "<ttt333-hash>", "size": 3456,
  "name": "ttt333-name" },
  { "hash": "<lll111-hash>", "size": 587,
  "name": "ttt333-name/lll111-name"},
  { "hash": "<bbb222-hash>", "size": 22,
  "name": "ttt333-name/lll111-name/bbb222-name" },
  { "hash": "<bbb222-hash>", "size": 22
  "name": "bbb222-name" }
  ] }
  ```

### 3.7 IPNS：命名以及易变状态

 目前为止，IPFS桟形成了一个对等块交换组成一个内容可寻址的DAG对象。这提供了发布和获取不可改变的对象。这甚至可以跟踪这些对象的版本历史记录。但是，这里有一个关键成分遗漏了：易变的命名。没有这个，发送IPFS的links，所有新内容的通信肯定都会有所偏差。现在所需就是能有某些方法可以获取相同路径的的易变状态。
这值得详述原因—如果最终易变数据是必须的—我们费了很大的力气构建了一个不可改变的Merkle DAG。就当做IPFS脱离了Merkle DAG的特征：对象可以

- (a)通过哈希值可以获取
- (b)完整性的检查
- (c)link其他的对象
- (d)无限缓存。从某种意义上说：
  对象就是永恒的
  这些就是一个高性能分布式系统的关键特征，在此系统上跨网络links之间移动文件是非常昂贵的。对象内容可寻址构建了一个具有以下特点的Web，(a)优秀的宽带优化(b)不受信任的内容服务(c)永恒的links(d)能够永久备任何对象以及它的引用。

不可变的内容可寻址对象和命名的Merkle DAG， 可变指针指向Merkle DAG，实例化了一个出现在很多成功分布式系统中的二分法。这些系统包括Git的版本控制系统，使用不可变的对象和可变的引用；还有UNIX分布式的继承者Plan9[?]文件系统，使用可变的Fossil和不可变的Venti[?]。LBFS[?]同样使用可变的索引以及不可变的块。

#### 3.7.1 自我认证名称

使用SFS[12,11]中的命名方案，给我们提供了一个种可以构建自我认证名称的方法，
在一个加密指定的全局命名空间中，这是可变的。IPFS的方案如下：

- 1.回想一下在IPFS中：NodeId = hash(node.PubKey)
- 2.我们给每个用户分配一个可变的命名空间，在此路径下：/ipns/
- 3.一个用户可以在此路径下发布一个用自己私钥签名的对象，比如说：/ipns/XLF2ipQ4jD3UdeX5xp1KBgeHRhemUtaA8Vm/
- 4.当其他用户获取对象时，他们可以检测签名是否与公钥和NodeId匹配。这个验证了用户发布对象的真实性，达到了可变状态的获取。

注意下面的细节：

- IPNS(InterPlanetary的命名空间)分开前缀是在可变和不可变的路径之间建立一个很容易辨认的区别，为了程序也为了人类阅读的便利。

- 因为这不是一个内容可寻址的对象，所以发布它就要依靠IPFS中的唯一的可变状态分配制度，路由系统。过程是(a)首先把此对象做一个常规的不可变IPFS的对象来发布(b)将此对象的哈希值作为元数据的值发布到路由系统上：

  ```
  routing.setValue(NodeId, <ns-object-hash>)
  ```

- 发布的对象中任何links在命令空间中充当子名称：

  ```
  /ipns/XLF2ipQ4jD3UdeX5xp1KBgeHRhemUtaA8Vm/
  /ipns/XLF2ipQ4jD3UdeX5xp1KBgeHRhemUtaA8Vm/docs
  /ipns/XLF2ipQ4jD3UdeX5xp1KBgeHRhemUtaA8Vm/docs/ipfs
  ```

- 一般建议发布一个commit对象或者其他对象的时候，要使用历史版本记录，因为这样就用户就可以找到之前使用过的名字。不过由于这并不总是需要的，所以留个用户自己选择。
  注意当用户发布一个对象的时候，他不能使用相同的方式来发布对象。

#### 3.7.2人类友好名称

IPNS的确是一个分配和在分配名称的好方法，但是对用户却不是十分友好的，因为它使用很长的哈希值作为名称，众所周知这样的名称很难被记住。IPNS足够应付URLs，但对于很多线下的传输工作就没有这么好用了。因此，IPFS使用下面的技术来增加IPNS的用户友好度。
对等节点Links
被SFS所鼓舞，用户可以直接将其他用户的对象link到自己的对象上（命令空间，家目录等等）。这有一个好处就是创建了一个可信任的Web（也支持老的真实性认证模型）：

```
# Alice links 到Bob上
ipfs link /<alice-pk-hash>/friends/bob /<bob-pk-hash>
# Eve links 到Alice上
ipfs link /<eve-pk-hash/friends/alice /<alice-pk-hash>
# Eve 也可以访问Bob
/<eve-pk-hash/friends/alice/friends/bob
# 访问Verisign 认证域
/<verisign-pk-hash>/foo.com
```

DNS TXT IPNS 记录
如果/ipns/是一个有效的域名称，IPFS会在DNS TXT记录中查找关键的ipns。IPFS会将查找到的值翻译为一个对象的哈希值或者另一个ipns的路径：

```
# DNS TXT 记录
ipfs.benet.ai. TXT "ipfs=XLF2ipQ4jD3U ..."
# 表现为符号链接
ln -s /ipns/XLF2ipQ4jD3U /ipns/fs.benet.ai
```

Proquint 可读的标识符
总是会有将二进制编码翻译成可读文件的方法。IPNS则支持Proquint[?].。如下：

```
# proquint语句
/ipns/dahih-dolij-sozuk-vosah-luvar-fuluh
# 分解为相应的下面形式
/ipns/KhAwNprxYVxKqpDZ
```

缩短名称服务
会涌现出很多服务器提供缩短名称的服务，向用户提供他们的命名空间。就像我们现在看到的DNS和Web的URLs：

```
# 用户可以从下面获取一个link
/ipns/shorten.er/foobar
# 然后放到自己的命名空间
/ipns/XLF2ipQ4jD3UdeX5xp1KBgeHRhemUtaA8Vm
```

### 3.8使用IPFS

IPFS设计为可以使用多种不同的方法来使用的，下面就是一些我将会继续追求的使用方式：

1. 作为一个挂载的全局文件系统，挂载在/ipfs和/ipns下
2. 作为一个挂载的个人同步文件夹，自动的进行版本管理，发布，以及备份任何的写入
3. 作为一个加密的文件或者数据共享系统
4. 作为所有软件的版本包管理者
5. 作为虚拟机器的根文件系统
6. 作为VM的启动文件系统 (在管理程序下)
7. 作为一个数据库：应用可以直接将数据写入Merkle DAG数据模型中，获取所有的版本，缓冲，以及IPFS提供的分配
8. 作为一个linked（和加密的）通信平台
9. 作为一个为大文件的完整性检查CDN（不使用SSL的情况下）
10. 作为一个加密的CDN
11. 在网页上，作为一个web CDN
12. 作为一个links永远存在新的永恒的Web

IPFS实现的目标：

(a)一个IPFS库可以导出到你自己应用中使用

(b)命令行工具可以直接操作对象

(c)使用FUSE[?]或者内核的模型挂载文件系统

## 4. 未来

IPFS的思想是几十年成功的分布式系统的探索和开源的产物。IPFS综合了很多迄今为止很成功的系统中优秀的思想。除了BitSwap新协议之外，IPFS最大的特色就是系统的耦合以及设计的综合性。

IPFS是去中心化网络基础设施的一个野心设想，很多不同类型的应用都可以建立在IPFS上。最低限度，它可以用来作为一个全局的，挂载性，版本控制文件系统和命名空间，或者作为下一代的文件共享系统。而最好的情况是，IPFS可以让Web升级一个层次，当发布一个有价值的信息时，任何感兴趣的人都可以进行发布而不会强迫性的必须只允许发布机构进行发布，用户可以信任信息的内容，信不信任信息的发送者都是无关紧要的，还有一个特点就是，一些重要但很老的文件也不会丢失。IPFS期待着带我们进入到一个永恒Wdb的世界。

## 5. 感谢

IPFS是一个很多很棒的主意以及系统的综合体。没有站在巨人的肩膀上，IPFS也不可能敢于有一个这么有野心的目标。个人感谢参与这些主意长期讨论的人：David Dalrymple, Joe Zimmerman, and Ali Yahya，特别是：揭开Merkle DAG的总体架构(David, Joe),滚动哈希阻塞(David), s/kademlia sybill 保护(David, Ali)，特别感谢David Mazieres,为他之前非常聪明的主意。



## 6. 引用备忘录



[1].I. Baumgart and S. Mies. S/kademlia:一个安全的基于秘钥路由的可行方法。2007年国际会议，第2卷，1-8页，在《并发和分布式系统》中。IEEE，2007年。

​

[2].I. BitTorrent.Bittorrent和Attorrent软件超过1亿5000万用户里程碑，Jan。2012



[3].B. Cohen.激励机制在bittorrent中建立了健壮性。在《对等系统经济研讨会》中，第6卷，68-72页，2003年。

​

[4].J. Dean and S. Ghemawat. Leveldb - 一个快速和轻量级键值存储数据库，谷歌提供，2011年。

​

[5].M. J. Freedman, E. Freudenthal, and D. Mazieres. Coral民主内容发布。在NSDI中，第4卷，18-18页，2004年。

​

[6].J. H. Howard, M. L. Kazar, S. G. Menees, D. A,Nichols, M. Satyanarayanan, R. N. Sidebotham, 以及M. J. West.分布式文件系统的规模和性能。“ACM 电脑系统上的交易 （TOCS）” 6(1):51-81, 1988年